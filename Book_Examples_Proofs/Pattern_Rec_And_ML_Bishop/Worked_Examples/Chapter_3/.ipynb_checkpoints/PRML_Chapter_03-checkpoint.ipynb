{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "#from numpy.random import randn, seed, uniform\n",
    "#from numpy.linalg import inv, norm, det, eigvals\n",
    "\n",
    "#from branca.colormap import LinearColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Evidence Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234) # Set random seed\n",
    "\n",
    "# Underlying relationship between input and output [t = sin(2 * pi * x)] without any noise\n",
    "num_steps = 200 # Number of samples to generate\n",
    "x_orig = np.linspace(0, 1, num_steps) # Generate input\n",
    "t_true = np.sin(2 * np.pi * x) # Generate output\n",
    "\n",
    "# Generate training set\n",
    "N = 25 # Number of training set samples to generate\n",
    "X_train = np.linspace(0, 1, N) + (1 / 7) * np.random.uniform(low = 0.0, high = 1.0, size = N)\n",
    "t_train = np.sin(2 * np.pi * X_train) # Noiseless output\n",
    "# Generate gaussian random noise with mean = 0, std = 0.3, var = 0.09, precision = beta = 1/0.09 = 11.11\n",
    "noise = np.random.normal(scale = 0.3, size = N)\n",
    "t_train = t_train + noise # Noisy output\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.plot(x, t, 'b-', label = 'Noiseless_Data')\n",
    "plt.scatter(X_train, t_train, facecolor = 'None', edgecolor = \"r\", s = 50, label = 'Noisy_Training_Data')\n",
    "plt.grid(b = True)\n",
    "plt.title(\"Training Data\", fontsize = 25)\n",
    "plt.xlabel(\"Input\", fontsize = 20)\n",
    "plt.ylabel(\"Output\", fontsize = 20)\n",
    "plt.legend(fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: gen_synth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_synth_data(func, sample_size, std, domain = [0, 1]):\n",
    "    \n",
    "    '''\n",
    "    Function to generate synthetic data \n",
    "    Ref: PRML, Appendix A, Synthetic Data, Pg: 682, 683\n",
    "    \n",
    "    Arguments:\n",
    "        func: Ground-truth function defining the relationship between input and output\n",
    "        sample_size: Number of samples to generate\n",
    "        std: standard-deviation of Gaussion noise on the output\n",
    "        domain: Range of input variable x\n",
    "        \n",
    "    Returns:\n",
    "        x: Input values\n",
    "        t: Output values\n",
    "    '''\n",
    "    x = np.linspace(domain[0], domain[1], sample_size) # Generate input samples\n",
    "    #np.random.shuffle(x) # Shuffle input samples\n",
    "    t = func(x) + np.random.normal(scale = std, size = x.shape) # Generate output samples\n",
    "    \n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal(x):\n",
    "    return np.sin(2 * np.pi * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class: GaussianFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianFeature(object):\n",
    "    \"\"\"\n",
    "    Defines Gaussian basis function object\n",
    "\n",
    "    gaussian function = exp(-0.5 * (x - m) / v)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, var):\n",
    "        \"\"\"\n",
    "        construct gaussian features\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mean : (n_features, ndim) or (n_features,) ndarray\n",
    "               places to locate gaussian function at\n",
    "        var : float\n",
    "              variance of the gaussian function\n",
    "        \"\"\"\n",
    "        if mean.ndim == 1:\n",
    "            mean = np.expand_dims(mean, 1)\n",
    "        else:\n",
    "            assert mean.ndim == 2\n",
    "        assert isinstance(var, float) or isinstance(var, int)\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "\n",
    "    def _gauss(self, x, mean):\n",
    "        return np.exp(-0.5 * np.sum(np.square(x - mean), axis=-1) / self.var)\n",
    "\n",
    "    def transform(self, x):\n",
    "        \"\"\"\n",
    "        transform input array with gaussian features\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : (sample_size, ndim) or (sample_size,)\n",
    "            input array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        output : (sample_size, n_features)\n",
    "            gaussian features\n",
    "        \"\"\"\n",
    "        if x.ndim == 1:\n",
    "            x = np.expand_dims(x, 1)\n",
    "        else:\n",
    "            assert x.ndim == 2\n",
    "        assert np.size(x, 1) == np.size(self.mean, 1)\n",
    "        basis = [np.ones(len(x))]\n",
    "        for m in self.mean:\n",
    "            basis.append(self._gauss(x, m))\n",
    "        return np.asarray(basis).transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RidgeRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression(object):\n",
    "    \"\"\"\n",
    "    Ridge regression model\n",
    "\n",
    "    w* = argmin |t - X @ w| + alpha * |w|_2^2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha:float=1.):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X:np.ndarray, t:np.ndarray):\n",
    "        \"\"\"\n",
    "        maximum a posteriori estimation of parameter\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (N, D) np.ndarray\n",
    "            training data independent variable\n",
    "        t : (N,) np.ndarray\n",
    "            training data dependent variable\n",
    "        \"\"\"\n",
    "\n",
    "        eye = np.eye(np.size(X, 1))\n",
    "        self.w = np.linalg.solve(self.alpha * eye + X.T @ X, X.T @ t)\n",
    "\n",
    "    def predict(self, X:np.ndarray):\n",
    "        \"\"\"\n",
    "        make prediction given input\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (N, D) np.ndarray\n",
    "            samples to predict their output\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (N,) np.ndarray\n",
    "            prediction of each input\n",
    "        \"\"\"\n",
    "        return X @ self.w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_mat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of targets and number of penalties do not correspond: 3 != 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9272f44bf57d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mphi_mat_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Gaussian basis functions corresponding to current training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Define ridge regression model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi_mat_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Fit model to current training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi_mat_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Make predictions on test set based on current model fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0my_pred_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \"\"\"\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             self.coef_, self.n_iter_ = _ridge_regression(\n\u001b[0m\u001b[0;32m    594\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m                 \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36m_ridge_regression\u001b[1;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_targets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m         raise ValueError(\"Number of targets and number of penalties \"\n\u001b[0m\u001b[0;32m    441\u001b[0m                          \u001b[1;34m\"do not correspond: %d != %d\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                          % (alpha.size, n_targets))\n",
      "\u001b[1;31mValueError\u001b[0m: Number of targets and number of penalties do not correspond: 3 != 1"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_basis = 24\n",
    "mu_j = np.linspace(0, 1, num_basis) # Mean of Gaussian basis functions\n",
    "var = (1/num_basis) ** 2 # Variance of Gaussian basis functions\n",
    "feature = GaussianFeature(mu_j, var) # Define Gaussian Feature object\n",
    "num_data_sets = 100 # Number of independent data sets to generate\n",
    "x_test, y_test  = gen_synth_data(sinusoidal, 200, 0) # Test data set for evaluation \n",
    "                                                     # Ideal sine wave with no noise\n",
    "phi_mat_test = feature.transform(x_test) # Gaussian basis functions corresponding to x_test    \n",
    "\n",
    "ln_lmbda = [2.6, -0.31, -2.4]\n",
    "for val in ln_lmbda:\n",
    "    alpha = np.exp(val)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    y_pred_list = []\n",
    "    for dset in range(num_data_sets):\n",
    "        x_train, y_train = gen_synth_data(sinusoidal, 25, 0.3) # Generate training data set with 25 points\n",
    "        phi_mat_train = feature.transform(x_train) # Gaussian basis functions corresponding to current training set\n",
    "        model = Ridge(alpha = alpha) # Define ridge regression model \n",
    "        model.fit(phi_mat_train, y_train) # Fit model to current training set\n",
    "        y_pred = model.predict(phi_mat_test) # Make predictions on test set based on current model fit\n",
    "        y_pred_list.append(y_pred)\n",
    "        if (dset <= 20):\n",
    "            plt.plot(x_test, y_pred, color = 'red')\n",
    "    y_pred_avg = np.asarray(y_pred_list).mean(axis = 0)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x_test, y_test, color = 'b')\n",
    "    plt.plot(x_test, y_pred_avg, color = 'r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.04166667, 0.08333333, 0.125     , 0.16666667,\n",
       "       0.20833333, 0.25      , 0.29166667, 0.33333333, 0.375     ,\n",
       "       0.41666667, 0.45833333, 0.5       , 0.54166667, 0.58333333,\n",
       "       0.625     , 0.66666667, 0.70833333, 0.75      , 0.79166667,\n",
       "       0.83333333, 0.875     , 0.91666667, 0.95833333, 1.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = phi_mat @ model.w\n",
    "plt.plot(x_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(phi_mat.T @ phi_mat) @ (phi_mat.T @ y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = PolynomialFeature(24)\n",
    "feature = GaussianFeature(np.linspace(0, 1, 24), 0.1)\n",
    "# feature = SigmoidalFeature(np.linspace(0, 1, 24), 10)\n",
    "\n",
    "for a in [1e2, 1., 1e-9]:\n",
    "    y_list = []\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i in range(100):\n",
    "        x_train, y_train = create_toy_data(sinusoidal, 25, 0.25)\n",
    "        X_train = feature.transform(x_train)\n",
    "        X_test = feature.transform(x_test)\n",
    "        model = BayesianRegression(alpha=a, beta=1.)\n",
    "        model.fit(X_train, y_train)\n",
    "        y = model.predict(X_test)\n",
    "        y_list.append(y)\n",
    "        if i < 20:\n",
    "            plt.plot(x_test, y, c=\"orange\")\n",
    "    plt.ylim(-1.5, 1.5)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x_test, y_test)\n",
    "    plt.plot(x_test, np.asarray(y_list).mean(axis=0))\n",
    "    plt.ylim(-1.5, 1.5)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
