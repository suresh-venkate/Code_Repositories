{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDP Policy Evaluation - Gridworld\n",
    "\n",
    "* **Description:** Perform iterative policy evaluation for the gridworld example\n",
    "* **Reference:** Reinforcement Learning, An Introduction, Second Edition by Sutton, Barto\n",
    "* **Section:** Section 4.1, Example 4.1, Pg. 76 to 77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class: Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    '''\n",
    "    Defines the agent class for the gridworld problem\n",
    "    Arguments:\n",
    "        policy_init: Initial policy to use for the agent class\n",
    "        actions: List of actions that the agent can take\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, policy_init, actions):\n",
    "        self.policy = policy_init\n",
    "        self.actions = actions\n",
    "        \n",
    "    def step(self, state):\n",
    "        # Execute one step of agent based on current state\n",
    "        if isinstance(self.policy, str):\n",
    "            if(self.policy == 'random'):\n",
    "                return np.random.choice(self.actions)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class: Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    '''\n",
    "    Defines the environment class for a n x n gridworld problem\n",
    "    Arguments:\n",
    "        n: Defines the size of the gridworld. n x n gridworld is generated\n",
    "        reward: Reward value for each transition\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n, reward):\n",
    "        self.n = n\n",
    "        self.state_list = list(range(n ** 2))\n",
    "        self.reward = reward\n",
    "        self.state = 1\n",
    "        \n",
    "    def set_state(self, state):\n",
    "        self.state = state\n",
    "        \n",
    "    def respond(self, action): # Respond to a particular action\n",
    "        if (action == 'up'): # Execute up action\n",
    "            if (self.state < self.n):\n",
    "                self.state = self.state\n",
    "            else:\n",
    "                self.state = self.state - 4\n",
    "        if (action == 'down'): # Execute down action\n",
    "            if (self.state >= (self.n * (self.n - 1))):\n",
    "                self.state = self.state\n",
    "            else:\n",
    "                self.state = self.state + 4\n",
    "        if (action == 'right'): # Execute right action\n",
    "            if ((self.state + 1) % self.n == 0):\n",
    "                self.state = self.state\n",
    "            else:\n",
    "                self.state = self.state + 1\n",
    "        if (action == 'left'): # Execute left action\n",
    "            if (self.state % self.n == 0):\n",
    "                self.state = self.state\n",
    "            else:\n",
    "                self.state = self.state - 1\n",
    "        return self.state, self.reward    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Iterative Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_init = 'random' # Set initial policy to equiprobable random policy\n",
    "actions_list = ['up', 'down', 'right', 'left']\n",
    "gw_size = 4 # 4 x 4 gridworld\n",
    "\n",
    "gw_agent = Agent(policy_init, actions_list)\n",
    "gw_envir = Environment(gw_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 4213.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0. -14. -20. -22.]\n",
      "[-14. -18. -20. -20.]\n",
      "[-20. -20. -18. -14.]\n",
      "[-22. -20. -14.   0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "v_init = np.zeros(gw_size ** 2) # v_0: Initialize value function array to all zeros.\n",
    "num_iter = 500\n",
    "\n",
    "for ind in tqdm(range(num_iter)):\n",
    "    if (ind == 0):\n",
    "        v_curr = v_init\n",
    "    else:\n",
    "        v_curr = v_next\n",
    "    v_next = np.zeros(gw_size ** 2) # v_(k+1): Placeholder for next value function array.        \n",
    "    for s in range(1, (gw_size ** 2 - 1)): # Loop through states (leave out terminal states)\n",
    "        for act in actions_list:\n",
    "            gw_envir.set_state(s)\n",
    "            s_pr, r = gw_envir.respond(act)\n",
    "            v_next[s] += r + v_curr[s_pr]\n",
    "        v_next[s] = v_next[s] / len(actions_list)\n",
    "\n",
    "print(v_next[0:4])\n",
    "print(v_next[4:8])\n",
    "print(v_next[8:12])\n",
    "print(v_next[12:16])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
