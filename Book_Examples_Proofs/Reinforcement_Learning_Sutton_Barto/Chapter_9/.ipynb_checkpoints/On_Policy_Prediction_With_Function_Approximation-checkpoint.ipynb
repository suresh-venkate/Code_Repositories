{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STATES = 1000 # Num states except for terminal states\n",
    "trueStateValues = np.arange(-1001, 1003, 2) / 1001.0 # true state values, just a promising guess\n",
    "states = np.arange(1, N_STATES + 1) # all states\n",
    "START_STATE = 500 # start from a central state\n",
    "END_STATES = [0, N_STATES + 1] # terminal states\n",
    "\n",
    "# possible actions\n",
    "ACTION_LEFT = -1\n",
    "ACTION_RIGHT = 1\n",
    "ACTIONS = [ACTION_LEFT, ACTION_RIGHT]\n",
    "\n",
    "# maximum stride for an action\n",
    "STEP_RANGE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classes and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class: ValueFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A wrapper class for aggregation value function\n",
    "class ValueFunction:\n",
    "    def __init__(self, numOfGroups):\n",
    "        self.numOfGroups = numOfGroups # Number of aggregated groups\n",
    "        self.groupSize = N_STATES // numOfGroups\n",
    "        self.params = np.zeros(numOfGroups) # Value functions for each aggregated group\n",
    "\n",
    "    # get the value of @state\n",
    "    def value(self, state):\n",
    "        if state in END_STATES:\n",
    "            return 0\n",
    "        groupIndex = (state - 1) // self.groupSize\n",
    "        return self.params[groupIndex]\n",
    "\n",
    "    # update parameters\n",
    "    # @delta: step size * (target - old estimation)\n",
    "    # @state: state of current sample\n",
    "    def update(self, delta, state):\n",
    "        groupIndex = (state - 1) // self.groupSize\n",
    "        self.params[groupIndex] += delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: getAction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an action, following random policy\n",
    "def getAction():\n",
    "    if np.random.binomial(1, 0.5) == 1:\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: takeAction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeAction(state, action):\n",
    "    step = np.random.randint(1, STEP_RANGE + 1)\n",
    "    step *= action\n",
    "    state += step\n",
    "    state = max(min(state, N_STATES + 1), 0)\n",
    "    if state == 0:\n",
    "        reward = -1\n",
    "    elif state == N_STATES + 1:\n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = 0\n",
    "    return state, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: gen_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_episode():\n",
    "    \n",
    "    '''\n",
    "    Generate one episode of agent-environment interaction\n",
    "    Returns:\n",
    "        states_list: List of states encountered in the episode (includes init_state but not term_state)\n",
    "        actions_list: List of actions take by agent at each time step\n",
    "        rewards_list: List of rewards received by agent at each time step\n",
    "    '''\n",
    "    \n",
    "    states_list = [] # Placeholder to store list of all states encountered in episode\n",
    "    actions_list = [] # Placeholder to store list of all actions taken by agent\n",
    "    rewards_list = [] # Placeholder to store list of rewards received at each step\n",
    "\n",
    "    s_t =  START_STATE # Initialize environment state\n",
    "    states_list.append(s_t) # Update states_list with initial state\n",
    "    while(1): # Run agent till terminal states are reached\n",
    "        a_t = getAction() # Action taken by agent at time t\n",
    "        s_tplus1, rew_tplus1 = takeAction(s_t, a_t) # Environment reponds to action a_t and moves\n",
    "                                                    # to state s_tplus1 and returns a reward rew_tplus1\n",
    "        actions_list.append(a_t) # Update actions_list\n",
    "        rewards_list.append(rew_tplus1) # Update rewards list\n",
    "        # Stop episode if terminal state has been reached\n",
    "        if (s_tplus1 in END_STATES): \n",
    "            break\n",
    "        s_t = s_tplus1 # Update current state\n",
    "        states_list.append(s_t) # Update states_list\n",
    "\n",
    "    return states_list, actions_list, rewards_list  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain true state values using DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dynamic programming to find the true state values, based on the promising guess above\n",
    "# Assume all rewards are 0, given that we have already given value -1 and 1 to terminal states\n",
    "while True:\n",
    "    oldTrueStateValues = np.copy(trueStateValues)\n",
    "    for state in states:\n",
    "        trueStateValues[state] = 0\n",
    "        for action in ACTIONS:\n",
    "            for step in range(1, STEP_RANGE + 1):\n",
    "                step *= action\n",
    "                newState = state + step\n",
    "                newState = max(min(newState, N_STATES + 1), 0)\n",
    "                # asynchronous update for faster convergence\n",
    "                trueStateValues[state] += 1.0 / (2 * STEP_RANGE) * trueStateValues[newState]\n",
    "    error = np.sum(np.abs(oldTrueStateValues - trueStateValues))\n",
    "    # print(\"%0.2f\" %error, end = ', ')\n",
    "    if error < 1e-2:\n",
    "        break\n",
    "# correct the state value for terminal states to 0\n",
    "trueStateValues[0] = trueStateValues[-1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: Gradient MC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_MC(num_ep, alpha, gamma, visit_type):\n",
    "    \n",
    "    '''\n",
    "    Function to run prediction using gradient MC algorithm and estimate state value function\n",
    "    Arguments:\n",
    "        num_ep: Number of episodes to use for MC prediction algorithm\n",
    "        gamma: Discounting factor for reward computation\n",
    "        visit_type: 'first' for first-visit MC prediction,\n",
    "                    'every' for every-visit MC prediction.\n",
    "        \n",
    "    Returns:\n",
    "        svpi: State value function for policy with which agent has been initialized\n",
    "        state_count: Number of times each state is encountered during MC prediction\n",
    "    '''\n",
    "    \n",
    "    state_count = np.zeros(N_STATES + 2) # Initialize state count to zero\n",
    "    # Loop through 'num_ep' episodes\n",
    "    for ep in tqdm(range(num_ep)):\n",
    "        ep_states, ep_actions, ep_rewards = gen_episode() # Generate one episode\n",
    "        num_timesteps = len(ep_rewards) # Number of timesteps in current episode\n",
    "        G = 0 # Initialize return to 0\n",
    "\n",
    "        # Loop through each timestep of current episode\n",
    "        for ind in range((num_timesteps - 1), -1, -1): \n",
    "            G = gamma * G + ep_rewards[ind] # Update return of current timestep\n",
    "            curr_state = ep_states[ind] # Retrieve state of current timestep\n",
    "            if (visit_type == 'first'): # For first-visit MC prediction\n",
    "                if (curr_state not in ep_states[0:ind]):\n",
    "                    delta = alpha * (G - valueFunction.value(curr_state)) \n",
    "                    valueFunction.update(delta, curr_state) # Perform gradient MC update\n",
    "            elif (visit_type == 'every'): # For every-visit MC prediction\n",
    "                delta = alpha * (G - valueFunction.value(curr_state)) \n",
    "                valueFunction.update(delta, curr_state) # Perform gradient MC update\n",
    "            state_count[curr_state] += 1 # Update state_count for current state\n",
    "        \n",
    "    return state_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valueFunction = ValueFunction(10)\n",
    "state_count = grad_MC(num_ep = 100000, alpha = 2e-5, gamma = 1, visit_type = 'every')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28b5535baf0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stateValues = [valueFunction.value(i) for i in states]\n",
    "plt.figure(0)\n",
    "plt.plot(states, stateValues, label='Approximate MC value')\n",
    "plt.plot(states, trueStateValues[1: -1], label='True value')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Copyright (C)                                                       #\n",
    "# 2016 Shangtong Zhang(zhangshangtong.cpp@gmail.com)                  #\n",
    "# 2016 Kenta Shimada(hyperkentakun@gmail.com)                         #\n",
    "# Permission given to modify the code as long as you keep this        #\n",
    "# declaration at the top                                              #\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a wrapper class for tile coding value function\n",
    "class TilingsValueFunction:\n",
    "    # @numOfTilings: # of tilings\n",
    "    # @tileWidth: each tiling has several tiles, this parameter specifies the width of each tile\n",
    "    # @tilingOffset: specifies how tilings are put together\n",
    "    def __init__(self, numOfTilings, tileWidth, tilingOffset):\n",
    "        self.numOfTilings = numOfTilings\n",
    "        self.tileWidth = tileWidth\n",
    "        self.tilingOffset = tilingOffset\n",
    "\n",
    "        # To make sure that each sate is covered by same number of tiles,\n",
    "        # we need one more tile for each tiling\n",
    "        self.tilingSize = N_STATES // tileWidth + 1\n",
    "\n",
    "        # weight for each tile\n",
    "        self.params = np.zeros((self.numOfTilings, self.tilingSize))\n",
    "\n",
    "        # For performance, only track the starting position for each tiling\n",
    "        # As we have one more tile for each tiling, the starting position will be negative\n",
    "        self.tilings = np.arange(-tileWidth + 1, 0, tilingOffset)\n",
    "\n",
    "    # get the value of @state\n",
    "    def value(self, state):\n",
    "        stateValue = 0.0\n",
    "        # go through all the tilings\n",
    "        for tilingIndex in range(0, len(self.tilings)):\n",
    "            # find the active tile in current tiling\n",
    "            tileIndex = (state - self.tilings[tilingIndex]) // self.tileWidth\n",
    "            stateValue += self.params[tilingIndex, tileIndex]\n",
    "        return stateValue\n",
    "\n",
    "    # update parameters\n",
    "    # @delta: step size * (target - old estimation)\n",
    "    # @state: state of current sample\n",
    "    def update(self, delta, state):\n",
    "\n",
    "        # each state is covered by same number of tilings\n",
    "        # so the delta should be divided equally into each tiling (tile)\n",
    "        delta /= self.numOfTilings\n",
    "\n",
    "        # go through all the tilings\n",
    "        for tilingIndex in range(0, len(self.tilings)):\n",
    "            # find the active tile in current tiling\n",
    "            tileIndex = (state - self.tilings[tilingIndex]) // self.tileWidth\n",
    "            self.params[tilingIndex, tileIndex] += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a wrapper class for polynomial / Fourier -based value function\n",
    "POLYNOMIAL_BASES = 0\n",
    "FOURIER_BASES = 1\n",
    "class BasesValueFunction:\n",
    "    # @order: # of bases, each function also has one more constant parameter (called bias in machine learning)\n",
    "    # @type: polynomial bases or Fourier bases\n",
    "    def __init__(self, order, type):\n",
    "        self.order = order\n",
    "        self.weights = np.zeros(order + 1)\n",
    "\n",
    "        # set up bases function\n",
    "        self.bases = []\n",
    "        if type == POLYNOMIAL_BASES:\n",
    "            for i in range(0, order + 1):\n",
    "                self.bases.append(lambda s, i=i: pow(s, i))\n",
    "        elif type == FOURIER_BASES:\n",
    "            for i in range(0, order + 1):\n",
    "                self.bases.append(lambda s, i=i: np.cos(i * np.pi * s))\n",
    "\n",
    "    # get the value of @state\n",
    "    def value(self, state):\n",
    "        # map the state space into [0, 1]\n",
    "        state /= float(N_STATES)\n",
    "        # get the feature vector\n",
    "        feature = np.asarray([func(state) for func in self.bases])\n",
    "        return np.dot(self.weights, feature)\n",
    "\n",
    "    def update(self, delta, state):\n",
    "        # map the state space into [0, 1]\n",
    "        state /= float(N_STATES)\n",
    "        # get derivative value\n",
    "        derivativeValue = np.asarray([func(state) for func in self.bases])\n",
    "        self.weights += delta * derivativeValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient Monte Carlo algorithm\n",
    "# @valueFunction: an instance of class ValueFunction\n",
    "# @alpha: step size\n",
    "# @distribution: array to store the distribution statistics\n",
    "def gradientMonteCarlo(valueFunction, alpha, distribution=None):\n",
    "    currentState = START_STATE\n",
    "    trajectory = [currentState]\n",
    "\n",
    "    # We assume gamma = 1, so return is just the same as the latest reward\n",
    "    reward = 0.0\n",
    "    while currentState not in END_STATES:\n",
    "        action = getAction()\n",
    "        newState, reward = takeAction(currentState, action)\n",
    "        trajectory.append(newState)\n",
    "        currentState = newState\n",
    "\n",
    "    # Gradient update for each state in this trajectory\n",
    "    for state in trajectory[:-1]:\n",
    "        delta = alpha * (reward - valueFunction.value(state))\n",
    "        valueFunction.update(delta, state)\n",
    "        if distribution is not None:\n",
    "            distribution[state] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi-gradient n-step TD algorithm\n",
    "# @valueFunction: an instance of class ValueFunction\n",
    "# @n: # of steps\n",
    "# @alpha: step size\n",
    "def semiGradientTemporalDifference(valueFunction, n, alpha):\n",
    "    # initial starting state\n",
    "    currentState = START_STATE\n",
    "\n",
    "    # arrays to store states and rewards for an episode\n",
    "    # space isn't a major consideration, so I didn't use the mod trick\n",
    "    states = [currentState]\n",
    "    rewards = [0]\n",
    "\n",
    "    # track the time\n",
    "    time = 0\n",
    "\n",
    "    # the length of this episode\n",
    "    T = float('inf')\n",
    "    while True:\n",
    "        # go to next time step\n",
    "        time += 1\n",
    "\n",
    "        if time < T:\n",
    "            # choose an action randomly\n",
    "            action = getAction()\n",
    "            newState, reward = takeAction(currentState, action)\n",
    "\n",
    "            # store new state and new reward\n",
    "            states.append(newState)\n",
    "            rewards.append(reward)\n",
    "\n",
    "            if newState in END_STATES:\n",
    "                T = time\n",
    "\n",
    "        # get the time of the state to update\n",
    "        updateTime = time - n\n",
    "        if updateTime >= 0:\n",
    "            returns = 0.0\n",
    "            # calculate corresponding rewards\n",
    "            for t in range(updateTime + 1, min(T, updateTime + n) + 1):\n",
    "                returns += rewards[t]\n",
    "            # add state value to the return\n",
    "            if updateTime + n <= T:\n",
    "                returns += valueFunction.value(states[updateTime + n])\n",
    "            stateToUpdate = states[updateTime]\n",
    "            # update the value function\n",
    "            if not stateToUpdate in END_STATES:\n",
    "                delta = alpha * (returns - valueFunction.value(stateToUpdate))\n",
    "                valueFunction.update(delta, stateToUpdate)\n",
    "        if updateTime == T - 1:\n",
    "            break\n",
    "        currentState = newState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9.1, gradient Monte Carlo algorithm\n",
    "def figure9_1():\n",
    "    nEpisodes = int(1e5)\n",
    "    alpha = 2e-5\n",
    "\n",
    "    # we have 10 aggregations in this example, each has 100 states\n",
    "    valueFunction = ValueFunction(10)\n",
    "    distribution = np.zeros(N_STATES + 2)\n",
    "    for episode in tqdm(range(0, nEpisodes)):\n",
    "#         if(episode % 1000 == 0):\n",
    "#             print('episode:', episode)\n",
    "        gradientMonteCarlo(valueFunction, alpha, distribution)\n",
    "\n",
    "    distribution /= np.sum(distribution)\n",
    "    stateValues = [valueFunction.value(i) for i in states]\n",
    "\n",
    "    plt.figure(0)\n",
    "    plt.plot(states, stateValues, label='Approximate MC value')\n",
    "    plt.plot(states, trueStateValues[1: -1], label='True value')\n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(states, distribution[1: -1], label='State distribution')\n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Distribution')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi-gradient TD on 1000-state random walk\n",
    "def figure9_2Left():\n",
    "    nEpisodes = int(1e5)\n",
    "    alpha = 2e-4\n",
    "    valueFunction = ValueFunction(10)\n",
    "    for episode in range(0, nEpisodes):\n",
    "        print('episode:', episode)\n",
    "        semiGradientTemporalDifference(valueFunction, 1, alpha)\n",
    "\n",
    "    stateValues = [valueFunction.value(i) for i in states]\n",
    "    plt.figure(2)\n",
    "    plt.plot(states, stateValues, label='Approximate TD value')\n",
    "    plt.plot(states, trueStateValues[1: -1], label='True value')\n",
    "    plt.xlabel('State')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different alphas and steps for semi-gradient TD\n",
    "def figure9_2Right():\n",
    "    # truncate value for better display\n",
    "    truncateValue = 0.55\n",
    "\n",
    "    # all possible steps\n",
    "    steps = np.power(2, np.arange(0, 10))\n",
    "\n",
    "    # all possible alphas\n",
    "    alphas = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "    # each run has 10 episodes\n",
    "    episodes = 10\n",
    "\n",
    "    # perform 100 independent runs\n",
    "    runs = 100\n",
    "\n",
    "    # track the errors for each (step, alpha) combination\n",
    "    errors = np.zeros((len(steps), len(alphas)))\n",
    "    for run in range(0, runs):\n",
    "        for stepInd, step in zip(range(len(steps)), steps):\n",
    "            for alphaInd, alpha in zip(range(len(alphas)), alphas):\n",
    "                print('run:', run, 'step:', step, 'alpha:', alpha)\n",
    "                # we have 20 aggregations in this example\n",
    "                valueFunction = ValueFunction(20)\n",
    "                for ep in range(0, episodes):\n",
    "                    semiGradientTemporalDifference(valueFunction, step, alpha)\n",
    "                    # calculate the RMS error\n",
    "                    currentStateValues = np.asarray([valueFunction.value(i) for i in states])\n",
    "                    errors[stepInd, alphaInd] += np.sqrt(np.sum(np.power(currentStateValues - trueStateValues[1: -1], 2)) / N_STATES)\n",
    "    # take average\n",
    "    errors /= episodes * runs\n",
    "    # truncate the error\n",
    "    errors[errors > truncateValue] = truncateValue\n",
    "    plt.figure(3)\n",
    "    for i in range(0, len(steps)):\n",
    "        plt.plot(alphas, errors[i, :], label='n = ' + str(steps[i]))\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('RMS error')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9.2, it will take quite a while\n",
    "def figure9_2():\n",
    "    figure9_2Left()\n",
    "    figure9_2Right()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9.5, Fourier basis and polynomials\n",
    "def figure9_5():\n",
    "    # my machine can only afford 1 run\n",
    "    runs = 1\n",
    "\n",
    "    episodes = 5000\n",
    "\n",
    "    # # of bases\n",
    "    orders = [5, 10, 20]\n",
    "\n",
    "    alphas = [1e-4, 5e-5]\n",
    "    labels = [['polynomial basis'] * 3, ['fourier basis'] * 3]\n",
    "\n",
    "    # track errors for each episode\n",
    "    errors = np.zeros((len(alphas), len(orders), episodes))\n",
    "    for run in range(0, runs):\n",
    "        for i in range(0, len(orders)):\n",
    "            valueFunctions = [BasesValueFunction(orders[i], POLYNOMIAL_BASES), BasesValueFunction(orders[i], FOURIER_BASES)]\n",
    "            for j in range(0, len(valueFunctions)):\n",
    "                for episode in range(0, episodes):\n",
    "                    print('run:', run, 'order:', orders[i], labels[j][i], 'episode:', episode)\n",
    "\n",
    "                    # gradient Monte Carlo algorithm\n",
    "                    gradientMonteCarlo(valueFunctions[j], alphas[j])\n",
    "\n",
    "                    # get state values under current value function\n",
    "                    stateValues = [valueFunctions[j].value(state) for state in states]\n",
    "\n",
    "                    # get the root-mean-squared error\n",
    "                    errors[j, i, episode] += np.sqrt(np.mean(np.power(trueStateValues[1: -1] - stateValues, 2)))\n",
    "\n",
    "    # average over independent runs\n",
    "    errors /= runs\n",
    "\n",
    "    plt.figure(5)\n",
    "    for i in range(0, len(alphas)):\n",
    "        for j in range(0, len(orders)):\n",
    "            plt.plot(errors[i, j, :], label=labels[i][j]+' order = ' + str(orders[j]))\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('RMSVE')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9.10, it will take quite a while\n",
    "def figure9_10():\n",
    "\n",
    "    # My machine can only afford one run, thus the curve isn't so smooth\n",
    "    runs = 1\n",
    "\n",
    "    # number of episodes\n",
    "    episodes = 5000\n",
    "\n",
    "    numOfTilings = 50\n",
    "\n",
    "    # each tile will cover 200 states\n",
    "    tileWidth = 200\n",
    "\n",
    "    # how to put so many tilings\n",
    "    tilingOffset = 4\n",
    "\n",
    "    labels = ['tile coding (50 tilings)', 'state aggregation (one tiling)']\n",
    "\n",
    "    # track errors for each episode\n",
    "    errors = np.zeros((len(labels), episodes))\n",
    "    for run in range(0, runs):\n",
    "        # initialize value functions for multiple tilings and single tiling\n",
    "        valueFunctions = [TilingsValueFunction(numOfTilings, tileWidth, tilingOffset),\n",
    "                         ValueFunction(N_STATES // tileWidth)]\n",
    "        for i in range(0, len(valueFunctions)):\n",
    "            for episode in range(0, episodes):\n",
    "                print('run:', run, 'episode:', episode)\n",
    "\n",
    "                # I use a changing alpha according to the episode instead of a small fixed alpha\n",
    "                # With a small fixed alpha, I don't think 5000 episodes is enough for so many\n",
    "                # parameters in multiple tilings.\n",
    "                # The asymptotic performance for single tiling stays unchanged under a changing alpha,\n",
    "                # however the asymptotic performance for multiple tilings improves significantly\n",
    "                alpha = 1.0 / (episode + 1)\n",
    "\n",
    "                # gradient Monte Carlo algorithm\n",
    "                gradientMonteCarlo(valueFunctions[i], alpha)\n",
    "\n",
    "                # get state values under current value function\n",
    "                stateValues = [valueFunctions[i].value(state) for state in states]\n",
    "\n",
    "                # get the root-mean-squared error\n",
    "                errors[i][episode] += np.sqrt(np.mean(np.power(trueStateValues[1: -1] - stateValues, 2)))\n",
    "\n",
    "    # average over independent runs\n",
    "    errors /= runs\n",
    "\n",
    "    plt.figure(4)\n",
    "    for i in range(0, len(labels)):\n",
    "        plt.plot(errors[i], label=labels[i])\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('RMSVE')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure9_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure9_2()\n",
    "figure9_5()\n",
    "figure9_10()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 % 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
