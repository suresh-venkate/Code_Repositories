{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Dataset_Eval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "256px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suresh-venkate/Code_Repositories/blob/main/Deep_Learning/Computer_Vision/Image_Classification/Stanford_Cars_Dataset/Stanford_Cars_Dataset_Classification_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urg0J7uoSwE1"
      },
      "source": [
        "# Stanford Car Dataset Classification - TF2-Keras version\n",
        "\n",
        "**Author:** Suresh Venkatesan\n",
        "\n",
        "* Problem statement: Classify images of cars into their respective classes.\n",
        "* Dataset to be used: Stanford Car Dataset ([Main Link](https://ai.stanford.edu/~jkrause/cars/car_dataset.html)    [Kaggle Link](https://www.kaggle.com/jutrera/stanford-car-dataset-by-classes-folder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8x5K9y_BHgY"
      },
      "source": [
        "# Complete preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O0lJuOACzOb"
      },
      "source": [
        "## Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA_w3sQsdvoM"
      },
      "source": [
        "### Use this for Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAuH2G7GBEQa"
      },
      "source": [
        "## Install Keras Tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypwSTc20BDYe"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U64TT4QGSwE3"
      },
      "source": [
        "## Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZPHTpD_SwE6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import shutil\n",
        "import pytz\n",
        "import math\n",
        "import cv2\n",
        "import pprint\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers, models, Model\n",
        "from tensorflow.keras import optimizers, losses, metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers.schedules import InverseTimeDecay \n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import apply_affine_transform\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.applications import resnet50\n",
        "from tensorflow.keras.applications import mobilenet\n",
        "from tensorflow.keras.applications import inception_v3\n",
        "\n",
        "import kerastuner as kt\n",
        "from kerastuner import HyperModel\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP5VBxNPzlVH"
      },
      "source": [
        "## Define directory paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8awMYjozlVH"
      },
      "source": [
        "# Define base path for TensorBoard Logs directory\n",
        "tb_logs_base_path = \"/content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Stanford_Car_Dataset/TB_Logs/\"\n",
        "os.makedirs(tb_logs_base_path, exist_ok = True) # Don't raise any exception if directory exists\n",
        "# Define base path for Keras Tuner Logs directory\n",
        "kt_logs_base_path = \"/content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Stanford_Car_Dataset/KT_Logs/\"\n",
        "os.makedirs(kt_logs_base_path, exist_ok = True) # Don't raise any exception if directory exists\n",
        "# Define base path for storing all outputs related to model / training\n",
        "out_base_path = \"/content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Stanford_Car_Dataset/Training_Outputs/\"\n",
        "os.makedirs(out_base_path, exist_ok = True) # Don't raise any exception if directory exists\n",
        "# Define base path of dataset\n",
        "dataset_path = \"/content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Datasets/Image_Datasets/Stanford_Car_Dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75YVNRaDOufs"
      },
      "source": [
        "# Dataset - Import, EDA and pre-process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMm3JCgLSwFD"
      },
      "source": [
        "## Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edezwt5xSwFE"
      },
      "source": [
        "# Copy dataset from Google Drive\n",
        "img_zip_file_name = \"Consolidated_Dataset.zip\"\n",
        "img_zip_file_path = os.path.join(dataset_path, img_zip_file_name)\n",
        "\n",
        "# Get start time of run and display it\n",
        "start_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
        "print(\"Started dataset copy at %s...\" %(start_time.strftime(\"%H:%M:%S\")), end = ' ')\n",
        "!cp {img_zip_file_path} .\n",
        "\n",
        "# Unzip dataset file\n",
        "print(\"Unzipping dataset...\")\n",
        "!unzip -q Consolidated_Dataset.zip\n",
        "# Delete zip file\n",
        "!rm Consolidated_Dataset.zip\n",
        "\n",
        "# Get end time of run and display elapsed time\n",
        "end_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
        "elap_time = ((end_time - start_time).total_seconds())/60\n",
        "print(\"Completed at %s. Elapsed time = %0.2f minutes.\" %(end_time.strftime(\"%H:%M:%S\"), elap_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZEG6yY0n0ZW"
      },
      "source": [
        "## Load annotation files to Pandas Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84PT6X4Gn61x"
      },
      "source": [
        "# Load train annotation file in a DataFrame\n",
        "ann_train_csv_path = './annot_train_cons.csv'\n",
        "train_df = pd.read_csv(ann_train_csv_path)\n",
        "display(train_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "427_0JemoCFN"
      },
      "source": [
        "# Load test annotation file in a DataFrame\n",
        "ann_test_csv_path = './annot_test_cons.csv'\n",
        "test_orig_df = pd.read_csv(ann_test_csv_path)\n",
        "display(test_orig_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T57yqdHieH4e"
      },
      "source": [
        "## Split test_orig_df into test_df and val_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK2PuR1-D6QG"
      },
      "source": [
        "num_val_img_per_class = 6 # Number of images per class to use in validation set\n",
        "class_list = test_orig_df['class'].unique()\n",
        "\n",
        "# Create place holder for test_df and val_df\n",
        "val_df = pd.DataFrame(columns = test_orig_df.columns)\n",
        "test_df = pd.DataFrame(columns = test_orig_df.columns)\n",
        "\n",
        "for class_val in class_list:\n",
        "  temp_test_df = test_orig_df[test_orig_df['class'] == class_val]    \n",
        "  val_df = val_df.append(temp_test_df[0:num_val_img_per_class])\n",
        "  test_df = test_df.append(temp_test_df[num_val_img_per_class:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HStLBAnw_bmE"
      },
      "source": [
        "## Get information about train, val and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxgIEihtzlVK"
      },
      "source": [
        "print(\"Training_Set_Information:\")\n",
        "print(\"-------------------------\")\n",
        "print(f\"Number of images is {train_df.shape[0]}\")\n",
        "print(f\"Smallest height of images is {train_df['img_h'].min()}\")\n",
        "print(f\"Largest height of images is {train_df['img_h'].max()}\")\n",
        "print(f\"Smallest width of images is {train_df['img_w'].min()}\")\n",
        "print(f\"Largest width of images is {train_df['img_w'].max()}\")\n",
        "print(\"Lowest aspect ratio of images is %0.2f\"\\\n",
        "      %((train_df['img_w']/train_df['img_h']).min()))\n",
        "print(\"Highest aspect ratio of images is %0.2f\"\\\n",
        "      %((train_df['img_w']/train_df['img_h']).max()))\n",
        "print()\n",
        "\n",
        "print(\"Validation_Set_Information:\")\n",
        "print(\"---------------------------\")\n",
        "print(f\"Number of images is {val_df.shape[0]}\")\n",
        "print(f\"Smallest height of images is {val_df['img_h'].min()}\")\n",
        "print(f\"Largest height of images is {val_df['img_h'].max()}\")\n",
        "print(f\"Smallest width of images is {val_df['img_w'].min()}\")\n",
        "print(f\"Largest width of images is {val_df['img_w'].max()}\")\n",
        "print(\"Lowest aspect ratio of images is %0.2f\"\\\n",
        "      %((val_df['img_w']/val_df['img_h']).min()))\n",
        "print(\"Highest aspect ratio of images is %0.2f\"\\\n",
        "      %((val_df['img_w']/val_df['img_h']).max()))\n",
        "print()\n",
        "\n",
        "print(\"Test_Set_Information:\")\n",
        "print(\"---------------------\")\n",
        "print(f\"Number of images is {test_df.shape[0]}\")\n",
        "print(f\"Smallest height of images is {test_df['img_h'].min()}\")\n",
        "print(f\"Largest height of images is {test_df['img_h'].max()}\")\n",
        "print(f\"Smallest width of images is {test_df['img_w'].min()}\")\n",
        "print(f\"Largest width of images is {test_df['img_w'].max()}\")\n",
        "print(\"Lowest aspect ratio of images is %0.2f\"\\\n",
        "      %((test_df['img_w']/test_df['img_h']).min()))\n",
        "print(\"Highest aspect ratio of images is %0.2f\"\\\n",
        "      %((test_df['img_w']/test_df['img_h']).max()))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boCnhuze5Vo8"
      },
      "source": [
        "## Get class distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uT0aLzFQRlu"
      },
      "source": [
        "### Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isanSdTVQDME"
      },
      "source": [
        "# Class distribution of Training set\n",
        "plt.figure(figsize = (15, 8))\n",
        "plot_ = sns.countplot(x = train_df['class'])\n",
        "plt.title('Class Distrubution of Training_Set', fontsize = 20)\n",
        "plt.xlabel('Class Values', fontsize = 20)\n",
        "plt.ylabel('Class Count', fontsize = 20)\n",
        "plt.xticks(rotation = 90, fontsize = 12)\n",
        "for ind, label in enumerate(plot_.get_xticklabels()):\n",
        "  if (ind % 10) == 0:\n",
        "    label.set_visible(True)\n",
        "  else:\n",
        "    label.set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAe7kpVPQUEI"
      },
      "source": [
        "### Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED89MUY_QWkZ"
      },
      "source": [
        "# Class distribution of Validation set\n",
        "plt.figure(figsize = (15, 8))\n",
        "plot_ = sns.countplot(x = val_df['class'])\n",
        "plt.title('Class Distrubution of Validation_Set', fontsize = 20)\n",
        "plt.xlabel('Class Values', fontsize = 20)\n",
        "plt.ylabel('Class Count', fontsize = 20)\n",
        "plt.xticks(rotation = 90, fontsize = 12)\n",
        "for ind, label in enumerate(plot_.get_xticklabels()):\n",
        "  if (ind % 10) == 0:\n",
        "    label.set_visible(True)\n",
        "  else:\n",
        "    label.set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P_7JrPeQmR1"
      },
      "source": [
        "### Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRKNI2xBQn3t"
      },
      "source": [
        "# Class distribution of Test set\n",
        "plt.figure(figsize = (15, 8))\n",
        "plot_ = sns.countplot(x = test_df['class'])\n",
        "plt.title('Class Distrubution of Test_Set', fontsize = 20)\n",
        "plt.xlabel('Class Values', fontsize = 20)\n",
        "plt.ylabel('Class Count', fontsize = 20)\n",
        "plt.xticks(rotation = 90, fontsize = 12)\n",
        "for ind, label in enumerate(plot_.get_xticklabels()):\n",
        "  if (ind % 10) == 0:\n",
        "    label.set_visible(True)\n",
        "  else:\n",
        "    label.set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmGjqK3JTDFp"
      },
      "source": [
        "# Collate class frequency counts into a dataframe\n",
        "train_class_df = train_df['class'].value_counts().to_frame(name = 'Training_Set')\n",
        "val_class_df = val_df['class'].value_counts().to_frame(name = 'Validation_Set')\n",
        "test_class_df = test_df['class'].value_counts().to_frame(name = 'Test_Set')\n",
        "class_df = train_class_df.merge(val_class_df, how = 'left', left_index = True, right_index = True)\n",
        "class_df = class_df.merge(test_class_df, how = 'left', left_index = True, right_index = True)\n",
        "class_df.index.set_names(names = 'Car_Class', inplace = True)\n",
        "display(class_df.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpoBpPbFp_N4"
      },
      "source": [
        "## Define image folder paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rEdtuX_qBjc"
      },
      "source": [
        "train_img_path = '/content/train_images/'\n",
        "val_img_path = '/content/test_images/'\n",
        "test_img_path = '/content/test_images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVf9aZGALLN6"
      },
      "source": [
        "## Define Function: Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlRTqLgBLNFE"
      },
      "source": [
        "def viz_data(name, X, y, X_dtype, mode, num_images, num_cols, col_size, row_size, bm_name = None):\n",
        "\n",
        "  '''\n",
        "  Function to plot random images from an input array along with corresponding labels\n",
        "\n",
        "  Arguments:\n",
        "    name: Name to print in title (Training_Set, Test_Set etc.)\n",
        "    X: Image array (should be in (batch, height, width, channel)) format\n",
        "    y: label array (Raw labels - should not be One-Hot encoded)\n",
        "    X_dtype: Data Type of image array. One of 'Int' or 'Float'\n",
        "    mode: One of 'grayscale' or 'color'\n",
        "    num_images: Number of images to plot from input array\n",
        "    num_cols: Number of columns to use for plotting\n",
        "    col_size: Size of columns to use for plotting\n",
        "    row_size: Size of rows to use for plotting\n",
        "    bm_name: Name of base model that will be used to undo pre-processing (if required)\n",
        "\n",
        "  '''\n",
        "\n",
        "  num_rows = math.ceil(num_images / num_cols) # Number of rows to use for plotting\n",
        "\n",
        "  fig = plt.figure(figsize = ((num_cols * col_size), (num_rows * row_size)))\n",
        "  fig.suptitle('Random sample images from ' + name, fontsize = 40)\n",
        "\n",
        "  # Generate random sample indices\n",
        "  samp_index = np.random.randint(low = 0, high = X.shape[0], size = num_images).tolist()\n",
        "\n",
        "  for ind, value in enumerate(samp_index): # Loop through samp_index\n",
        "    if (bm_name == None): # bm_name = None => No preprocessing used.\n",
        "      if (X_dtype == 'int'): # If dtype = 'int', force image dtype to 'uint8'\n",
        "        img = (X[value].squeeze()).astype('uint8') # Extract image and force type to uint8\n",
        "      elif (X_dtype == 'float') : # If dtype = 'float', force image dtype to 'float'\n",
        "        img = (X[value].squeeze()).astype('float32') # Extract image and force type to float32\n",
        "    else: # bm_name != None => pre-processing has to be removed\n",
        "        img = (X[value].squeeze()).astype('float32') # Extract image and force type to float32        \n",
        "        img = undo_preprocess_data(img, bm_name) # Undo any pre-processing done on image\n",
        "        img = img.astype('uint8') # Force image dtype to 'uint8'\n",
        "\n",
        "    label = y[value] # Extract label\n",
        "    \n",
        "    ax = plt.subplot(num_rows, num_cols, (ind + 1))\n",
        "    if (mode == 'grayscale'):\n",
        "      ax.imshow(img, cmap = 'gray') # Plot image in grayscale\n",
        "    elif (mode == 'color'):\n",
        "      ax.imshow(img) # Plot image in color\n",
        "\n",
        "    ax.set_title(f\"{label}\", fontsize = 17)\n",
        "    ax.grid(False)  \n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44-5vtXe00mb"
      },
      "source": [
        "## Define Function: Visualize Images from DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtu_--i302u-"
      },
      "source": [
        "def viz_img_df(name, df, x_col, y_col, img_root_path, img_cons, plot_bbox,\\\n",
        "               num_images, num_cols, col_size, row_size):\n",
        "\n",
        "  '''\n",
        "  Function to plot random images from an input array along with corresponding labels\n",
        "\n",
        "  Arguments:\n",
        "    name: Name to print in title (Training_Set, Test_Set etc.)\n",
        "    df: Name of dataframe to read image details from\n",
        "    x_col: Name of column in dataframe that contains file names\n",
        "    y_col: Name of column in dataframe that contains the class names\n",
        "    img_root_path: Root directory path where images are stored\n",
        "    img_cons: Boolean: If True, then all images are assumed to consolidated in img_path (no sub-directories).\n",
        "                       If False, then the images are assumed to be present inside sub-directories in img_path\n",
        "                       named with the class name.\n",
        "    plot_bbox: Boolean: If True, plot bounding-boxes on top of image\n",
        "                        Should be set to True only if Dataframe has BBOX co-ords                       \n",
        "    num_images: Number of images to plot from input array\n",
        "    num_cols: Number of columns to use for plotting\n",
        "    col_size: Size of columns to use for plotting\n",
        "    row_size: Size of rows to use for plotting\n",
        "\n",
        "  '''\n",
        "\n",
        "  num_rows = math.ceil(num_images / num_cols) # Number of rows to use for plotting\n",
        "\n",
        "  fig = plt.figure(figsize = ((num_cols * col_size), (num_rows * row_size)))\n",
        "  fig.suptitle('Random sample images from ' + name, fontsize = 40)\n",
        "\n",
        "  # Generate random sample indices\n",
        "  samp_indices = np.random.randint(low = 0, high = df.shape[0], size = num_images).tolist()\n",
        "\n",
        "  for ind, value in enumerate(samp_indices): # Loop through samp_index\n",
        "    img_file_name = df.iloc[value][x_col] # Extract file name of image\n",
        "    img_class = df.iloc[value][y_col] # Extract class of image\n",
        "    if (img_cons): # img_cons = True -> All images consolidated in img_root_path\n",
        "      img_file_path = os.path.join(img_root_path, img_file_name) # Obtain full path of image\n",
        "    else: # img_cons = False -> Each image is present in a sub-directory inside img_root_path\n",
        "      img_file_path = os.path.join(img_root,path, img_class, img_file_path)\n",
        "    img = cv2.imread(img_file_path, cv2.IMREAD_COLOR) # Load image using cv2 as a 3-channel RGB image\n",
        "\n",
        "    if (plot_bbox): # plot_bbox = True => Plot Bounding-Box on top of image\n",
        "      img_h, img_w = df.iloc[value]['img_h'], df.iloc[value]['img_w'] # Extract image dimensions\n",
        "      xmin, ymin, xmax, ymax = df.iloc[value]['xmin'], df.iloc[value]['ymin'],\\\n",
        "                               df.iloc[value]['xmax'], df.iloc[value]['ymax'] # Get ground-truth \n",
        "                                                                              # BBOX co-ords\n",
        "      # Set box_thickness based on image area  \n",
        "      box_thickness = int(np.ceil(((img_h) * (img_w)) / (100000)))\n",
        "      # Draw ground-truth BBOX in green\n",
        "      cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), box_thickness)\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert image to RGB format\n",
        "    ax = plt.subplot(num_rows, num_cols, (ind + 1)) # Define plotting axes\n",
        "    ax.imshow(img) # Plot image in color\n",
        "    ax.set_title(f\"{img_class}\", fontsize = 20) # Set title\n",
        "    ax.grid(False)  \n",
        "\n",
        "  plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJywg4mN4joc"
      },
      "source": [
        "## Visualize Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XcisGNRFLC0"
      },
      "source": [
        "### Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS59zZaw4McX"
      },
      "source": [
        "# Plot random images from training set\n",
        "viz_img_df('Training_Set', train_df, 'filename', 'class', train_img_path, True, True, 8, 2, 8, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trwMPcEnFO6_"
      },
      "source": [
        "### Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCJA7llwFWXN"
      },
      "source": [
        "# Plot random images from validation set\n",
        "viz_img_df('Validation_Set', val_df, 'filename', 'class', val_img_path, True, True, 8, 2, 8, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0Bt5vN5FQTV"
      },
      "source": [
        "### Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnd6p_XuKcgw"
      },
      "source": [
        "# Plot random images from test set\n",
        "viz_img_df('Test_Set', test_df, 'filename', 'class', test_img_path, True, True, 8, 2, 8, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCKDWMaqZqbA"
      },
      "source": [
        "# Define Batch Data Generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpU3pa_gQhxR"
      },
      "source": [
        "## Define Function: plot_img_transf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J06bmCdZQl4j"
      },
      "source": [
        "def plot_img_transf(df, x_col, y_col, img_root_path, img_cons, rot, wid_shift, hgt_shift, shear, zx, zy,\\\n",
        "                    num_cols, col_size, row_size):\n",
        "\n",
        "  '''\n",
        "  Function to plot various image transformations on an image before applying these transformations\n",
        "  for data augmentation\n",
        "\n",
        "  Arguments:\n",
        "    df: Name of dataframe to read image details from\n",
        "    x_col: Name of column in dataframe that contains file names\n",
        "    y_col: Name of column in dataframe that contains the class names\n",
        "    img_root_path: Root directory path where images are stored\n",
        "    img_cons: Boolean: If True, then all images are assumed to consolidated in img_path (no sub-directories).\n",
        "                       If False, then the images are assumed to be present inside sub-directories in img_path\n",
        "                       named with the class name.        \n",
        "\n",
        "    rot: Extent of clockwise-rotation in degrees\n",
        "    wid_shift: Extent of wid_shift\n",
        "    hgt_shift: Extent of height shift\n",
        "    shear: Shear angle in degrees\n",
        "    zx: Extent of zoom in x-direction\n",
        "    zy: Extent of zoom in y-direction\n",
        "    num_cols: Number of columns to use for plotting\n",
        "    col_size: Size of columns to use for plotting\n",
        "    row_size: Size of rows to use for plotting\n",
        "\n",
        "  '''\n",
        "\n",
        "  # Generate random sample index\n",
        "  samp_index = np.random.randint(low = 0, high = df.shape[0], size = 1)[0] \n",
        "  img_transf = {} # Dict place-holder to store original and transformed images\n",
        "  img_file_name = df.iloc[samp_index][x_col] # Extract file name of image\n",
        "  img_class = df.iloc[samp_index][y_col] # Extract class of image\n",
        "  if (img_cons): # img_cons = True -> All images consolidated in img_root_path\n",
        "    img_file_path = os.path.join(img_root_path, img_file_name) # Obtain full path of image\n",
        "  else: # img_cons = False -> Each image is present in a sub-directory inside img_root_path\n",
        "    img_file_path = os.path.join(img_root,path, img_class, img_file_path)\n",
        "  img = cv2.imread(img_file_path, cv2.IMREAD_COLOR) # Load image using cv2 as a 3-channel RGB image\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert image to RGB format\n",
        "\n",
        "  img_transf['Original_Image'] = img # Append original image to img_transf dict\n",
        "  img_transf['Clockwise_Rotation'] = apply_affine_transform(img, theta = rot) # Clockwise rotn\n",
        "  img_transf['Anti-clockwise Rotation'] = apply_affine_transform(img, theta = -rot) # Anti-clockwise rotn\n",
        "  img_transf['Left_Shift'] = apply_affine_transform(img, ty = wid_shift) # Left Shift\n",
        "  img_transf['Right_Shift'] = apply_affine_transform(img, ty = -wid_shift) # Right Shift\n",
        "  img_transf['Upward_Shift'] = apply_affine_transform(img, tx = hgt_shift) # Upward Shift\n",
        "  img_transf['Downward_Shift'] = apply_affine_transform(img, tx = -hgt_shift) # Downward Shift\n",
        "  img_transf['Shear_Left'] = apply_affine_transform(img, shear = shear) # Left shear\n",
        "  img_transf['Shear_Right'] = apply_affine_transform(img, shear = -shear) # Righ shear  \n",
        "  img_transf['Zoom_Y'] = apply_affine_transform(img, zx = zx) # Zoom in x-direction  \n",
        "  img_transf['Zoom_X'] = apply_affine_transform(img, zy = zy) # Zoom in y-direction    \n",
        "\n",
        "  num_images = len(img_transf) # Total number of images to plot\n",
        "  num_rows = math.ceil(num_images / num_cols) # Number of rows to use for plotting\n",
        "  \n",
        "  fig = plt.figure(figsize = ((num_cols * col_size), (num_rows * row_size)))\n",
        "  fig.suptitle('Original image along with some affine transformations', fontsize = 40)\n",
        "\n",
        "  for ind, dict_entry in enumerate(img_transf.items()): # Loop through dictionary items\n",
        "    key, image = dict_entry[0], dict_entry[1]\n",
        "    ax = plt.subplot(num_rows, num_cols, (ind + 1))\n",
        "    ax.imshow(image) # Plot image in color\n",
        "    ax.set_title(key, fontsize = 25) # Set key as title\n",
        "    #ax.grid(False) # Turn off grid\n",
        "\n",
        "  plt.show()    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUaLpjWJ4lVC"
      },
      "source": [
        "## Visualize some image transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf-bKsQnZTsT"
      },
      "source": [
        "plot_img_transf(train_df, 'filename', 'class', train_img_path, True, rot = 30, wid_shift = 5,\\\n",
        "                hgt_shift = 5, shear = 30, zx = 0.8, zy = 0.8, num_cols = 2, col_size = 8, row_size = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXYYTbHxLYOk"
      },
      "source": [
        "## Define base model, target image shape and model batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cYnxiHJLaMb"
      },
      "source": [
        "### The base model defined here (bm_name) will be used to choose the appropriate pre-processing function\n",
        "### to apply to the input images in the Image Data Generators\n",
        "\n",
        "### If bm_name = 'VGG16' or 'ResNet50':\n",
        "###    Only mean shift is applied\n",
        "###    img_preprocessed = img - [103.939, 116.779, 123.68]\n",
        "### If bm_name = 'MobileNet' or 'InceptionV3'\n",
        "###    Image scaled to lie between -1 and +1\n",
        "###    img_preprocessed = (img / 127.5) - 1\n",
        "### If bm_name = 'grayscale_model'\n",
        "###    Image scaled to lie between 0 and +1\n",
        "###    img_preprocessed = (img / 225.)\n",
        "\n",
        "# bm_name = 'VGG16'\n",
        "bm_name = 'ResNet50'\n",
        "# bm_name = 'MobileNet'\n",
        "# bm_name = 'InceptionV3'\\\n",
        "# bm_name = 'grayscale_model'\n",
        "\n",
        "# Define target image size and batch size \n",
        "mod_inp_shape = (224, 224, 3) # Define target image size for model input\n",
        "mod_bat_size = 64 # Batch size to use while model fitting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM-gStAoK1ZD"
      },
      "source": [
        "## Define pre-processing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4dSOfKaLepq"
      },
      "source": [
        "# Define pre-processing and undo pre-processing function\n",
        "# Appropriate pre-processing functions from Keras are used.\n",
        "\n",
        "def preprocess_data(img):\n",
        "\n",
        "  if (bm_name == 'VGG16'):\n",
        "    return vgg16.preprocess_input(img)\n",
        "  elif (bm_name == 'ResNet50'):\n",
        "    return resnet50.preprocess_input(img)\n",
        "  elif (bm_name == 'MobileNet'):\n",
        "    return mobilenet.preprocess_input(img)\n",
        "  elif (bm_name == 'InceptionV3'):\n",
        "    return inception_v3.preprocess_input(img)\n",
        "  elif (bm_name == 'grayscale_model'):\n",
        "    return img/255.\n",
        "\n",
        "def undo_preprocess_data(img, bm_name):\n",
        "\n",
        "  if ((bm_name == 'VGG16') or (bm_name == 'ResNet50')):\n",
        "    mean = [103.939, 116.779, 123.68]\n",
        "    img[..., 0] += mean[0]\n",
        "    img[..., 1] += mean[1]\n",
        "    img[..., 2] += mean[2]\n",
        "    img = img[..., ::-1].astype('uint8')\n",
        "  elif ((bm_name == 'MobileNet') or (bm_name == 'InceptionV3')):\n",
        "    img = ((img + 1) * 127.5).astype('uint8')\n",
        "  elif (bm_name == 'grayscale_model'):\n",
        "    img = (img * 255.0).astype('uint8')\n",
        "\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbgrVFip563g"
      },
      "source": [
        "## Classes: Define batch generator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBwEshj45-dP"
      },
      "source": [
        "class batch_generator_from_df(Sequence):\n",
        "    \n",
        "    def  __init__(self, df, directory, x_col, y_col, batch_size, target_size, shuffle = False, seed = 1234,\\\n",
        "                  preprocessing_function = None):\n",
        "      self.df = df\n",
        "      self.samples = df.shape[0]\n",
        "      self.directory = directory\n",
        "      self.x_col = x_col\n",
        "      self.y_col = y_col\n",
        "      self.batch_size = batch_size\n",
        "      self.target_size = target_size\n",
        "      self.image_shape = (self.target_size[0], self.target_size[1], 3)\n",
        "      self.shuffle = shuffle\n",
        "      self.seed = seed\n",
        "      self.preprocessing_function = preprocessing_function\n",
        "      self.class_list = sorted(df[y_col].unique())\n",
        "      self.num_classes = len(self.class_list)\n",
        "      self.class_indices = {value:ind for ind, value in enumerate(self.class_list)}\n",
        "      self.on_epoch_end()\n",
        "      print(f\"Found {self.samples} images belonging to {self.num_classes} classes\")\n",
        "\n",
        "    def __len__(self):\n",
        "      return int(np.ceil(float(self.df.shape[0] / self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      start_ind = index * self.batch_size # Start index of current batch\n",
        "      end_ind = min((index + 1) * self.batch_size, self.df.shape[0]) # End index of current batch\n",
        "      sub_df = self.df[start_ind:end_ind] # Create sub dataframe using start and end indices\n",
        "      X_batch = []\n",
        "      y_batch = []\n",
        "      for _, row in sub_df.iterrows():\n",
        "        img_file_name = row[self.x_col]\n",
        "        img_file_path = os.path.join(self.directory, img_file_name)\n",
        "        img = cv2.imread(img_file_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (self.target_size[0], self.target_size[1]), interpolation = cv2.INTER_CUBIC)\n",
        "        if (self.preprocessing_function != None):\n",
        "          img = self.preprocessing_function(img)\n",
        "        X_batch.append(img)\n",
        "        label = row[self.y_col]\n",
        "        label_index = self.class_indices[label]\n",
        "        label_ohe = to_categorical(label_index, num_classes = self.num_classes)\n",
        "        y_batch.append(label_ohe)\n",
        "      X_batch = np.array(X_batch, dtype = np.float32)\n",
        "      y_batch = np.array(y_batch, dtype = np.int)\n",
        "      \n",
        "      return X_batch, y_batch\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "      if (self.shuffle): # If 'shuffle' = True, random shuffle the dataframe at the end of the epoch\n",
        "        self.df = self.df.sample(frac = 1, random_state = self.seed).reset_index(drop = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUtkaDMwUVel"
      },
      "source": [
        "## Define Image Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67xmE0koq0Lm"
      },
      "source": [
        "# Define train, val and test ImageDataGenerator objects\n",
        "# Train ImageDataGenerator includes image augmentation\n",
        "# Val and Test ImageDataGenerators don't have any image augmentation\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_data)\n",
        "# train_datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.2,\\\n",
        "#                                    height_shift_range = 0.2, shear_range = 15, zoom_range = 0.2,\\\n",
        "#                                    channel_shift_range = 20.0, preprocessing_function = preprocess_data)\n",
        "val_datagen = ImageDataGenerator(preprocessing_function = preprocess_data)\n",
        "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bi2-xvGYCLR"
      },
      "source": [
        "## Define Generator Objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um1rq2ZvYE0y"
      },
      "source": [
        "# Define train, val and test generator objects\n",
        "# train_generator = train_datagen.flow(X_train, y_train_ohe, batch_size = mod_bat_size,\\\n",
        "#                                      shuffle = True, seed = 1234)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(train_df, directory = train_img_path,\\\n",
        "                                                    x_col = \"filename\", y_col = \"class\",\\\n",
        "                                                    target_size = mod_inp_shape[0:2],\\\n",
        "                                                    class_mode = 'categorical', batch_size = mod_bat_size,\\\n",
        "                                                    shuffle = False, seed = 1234, interpolation = \"bicubic\")\n",
        "val_generator = val_datagen.flow_from_dataframe(val_df, directory = test_img_path,\\\n",
        "                                                x_col = \"filename\", y_col = \"class\",\\\n",
        "                                                target_size = mod_inp_shape[0:2],\\\n",
        "                                                class_mode = 'categorical', batch_size = mod_bat_size,\\\n",
        "                                                shuffle = False, seed = 1234, interpolation = \"bicubic\")\n",
        "test_generator = test_datagen.flow_from_dataframe(test_df, directory = test_img_path,\\\n",
        "                                                  x_col = \"filename\", y_col = \"class\",\\\n",
        "                                                  target_size = mod_inp_shape[0:2],\\\n",
        "                                                  class_mode = 'categorical', batch_size = mod_bat_size,\\\n",
        "                                                  shuffle = False, seed = 1234, interpolation = \"bicubic\")\n",
        "# train_generator = batch_generator_from_df(train_df, train_img_path, 'filename', 'class', mod_bat_size,\\\n",
        "#                                           mod_inp_shape[0:2], preprocessing_function = preprocess_data)\n",
        "# val_generator = batch_generator_from_df(val_df, test_img_path, 'filename', 'class', mod_bat_size,\\\n",
        "#                                         mod_inp_shape[0:2], preprocessing_function = preprocess_data)\n",
        "# test_generator = batch_generator_from_df(test_df, test_img_path, 'filename', 'class', mod_bat_size,\\\n",
        "#                                         mod_inp_shape[0:2], preprocessing_function = preprocess_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNx9acQy_bV_"
      },
      "source": [
        "## Verify generator objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOXrp-5wvCqt"
      },
      "source": [
        "# Print some details of train, val and test generators\n",
        "num_classes = len(train_generator.class_indices)\n",
        "num_batches_train = len(train_generator)\n",
        "num_batches_val = len(val_generator)\n",
        "num_batches_test = len(test_generator)\n",
        "\n",
        "print(\"Train_Generator_Information:\")\n",
        "print(\"----------------------------\")\n",
        "print(f\"Total number of samples: {train_generator.samples}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Size of each batch: {train_generator.batch_size}\")\n",
        "print(f\"Shape of images: {train_generator.image_shape}\")\n",
        "print(f\"Number of batches: {num_batches_train}\")\n",
        "print()\n",
        "\n",
        "print(\"Val_Generator_Information:\")\n",
        "print(\"----------------------------\")\n",
        "print(f\"Total number of samples: {val_generator.samples}\")\n",
        "print(f\"Size of each batch: {val_generator.batch_size}\")\n",
        "print(f\"Shape of images: {val_generator.image_shape}\")\n",
        "print(f\"Number of batches: {num_batches_val}\")\n",
        "print()\n",
        "\n",
        "print(\"Test_Generator_Information:\")\n",
        "print(\"----------------------------\")\n",
        "print(f\"Total number of samples: {test_generator.samples}\")\n",
        "print(f\"Size of each batch: {test_generator.batch_size}\")\n",
        "print(f\"Shape of images: {test_generator.image_shape}\")\n",
        "print(f\"Number of batches: {num_batches_test}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv5bem8eykdq"
      },
      "source": [
        "# Extract class-index mapping from train generator\n",
        "class_ind_dict = train_generator.class_indices\n",
        "# Create index-class mapping from class-index mapping\n",
        "ind_class_dict = {value:ind for ind, value in class_ind_dict.items()}\n",
        "\n",
        "for ind, class_val in ind_class_dict.items():\n",
        "  if (ind < 10):\n",
        "    print(f\"Index: {ind}, Class: {class_val}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RdCo1kgVBPq"
      },
      "source": [
        "## Visualize the data from generator objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmwy-DEYA99X"
      },
      "source": [
        "# Generate a batch of data from train_generator\n",
        "X_batch, y_batch = train_generator.__getitem__(0)\n",
        "y_batch = np.argmax(y_batch, axis = 1)\n",
        "label = [ind_class_dict[y] for y in y_batch]\n",
        "viz_data('Train_Generator', X_batch, label, 'int', 'color', num_images = 9, num_cols = 3,\\\n",
        "         col_size = 6, row_size = 6, bm_name = bm_name)\n",
        "print(\"\\n\\n\")\n",
        "# Generate a batch of data from validation_generator\n",
        "X_batch, y_batch = val_generator.__getitem__(0)\n",
        "y_batch = np.argmax(y_batch, axis = 1)\n",
        "label = [ind_class_dict[y] for y in y_batch]\n",
        "viz_data('Val_Generator', X_batch, label, 'int', 'color', num_images = 9, num_cols = 3,\\\n",
        "         col_size = 6, row_size = 6, bm_name = bm_name)\n",
        "print(\"\\n\\n\")\n",
        "# Generate a batch of data from test_generator\n",
        "X_batch, y_batch = test_generator.__getitem__(0)\n",
        "y_batch = np.argmax(y_batch, axis = 1)\n",
        "label = [ind_class_dict[y] for y in y_batch]\n",
        "viz_data('Test_Generator', X_batch, label, 'int', 'color', num_images = 9, num_cols = 3,\\\n",
        "         col_size = 6, row_size = 6, bm_name = bm_name)\n",
        "print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzjNXDrrbSAh"
      },
      "source": [
        "# Models - Build, Train, Tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP4SXajyoTkW"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwXZtqIEpBbq"
      },
      "source": [
        "### Define Model Core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CowJ1IHpGKz"
      },
      "source": [
        "def model_core(model_dict):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function to define the model core.\n",
        "    \n",
        "    Arguments:\n",
        "      model_dict - Dictionary with list of keys / values needed to build the model\n",
        "\n",
        "    Returns:\n",
        "      model - Model with all layers instantiated\n",
        " \n",
        "    \"\"\"    \n",
        "    # Retrieve model dict parameters\n",
        "    model_arch = model_dict['model_arch'] # Model Architecture\n",
        "\n",
        "    ##### Start Model Architecture A (VGG16 Base)\n",
        "    if (model_arch == 'A'):\n",
        "        # Retrieve arch. specific model dict parameters\n",
        "        mod_inp_shape = model_dict['mod_inp_shape'] # Shape of input tensor to model\n",
        "        weights = model_dict['weights'] \n",
        "        trainable = model_dict['trainable']\n",
        "        dropout_rate = model_dict['dropout_rate']\n",
        "        num_classes = model_dict['num_classes']\n",
        "        \n",
        "        base_model = resnet50.ResNet50(input_shape = mod_inp_shape, weights = weights,\\\n",
        "                                 include_top = False, pooling = 'avg')\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = trainable\n",
        "            \n",
        "        X = base_model.output\n",
        "        X = Flatten()(X)\n",
        "        X = Dropout(rate = dropout_rate[0], name = 'DR0')(X)        \n",
        "        X = Dense(1024, activation = 'relu')(X)        \n",
        "        X = Dropout(rate = dropout_rate[1], name = 'DR1')(X)\n",
        "        X = Dense(512, activation = 'relu')(X)        \n",
        "        X = Dropout(rate = dropout_rate[2], name = 'DR2')(X)\n",
        "        label_output = Dense(num_classes, activation = 'softmax', name = 'class_op')(X) \n",
        "\n",
        "        # # # Add output layer for bounding box regression\n",
        "        # bbox_output = Dense(4, activation = 'sigmoid', name = 'reg_op')(X)        \n",
        "        \n",
        "        # model = Model(inputs = base_model.input, outputs = [label_output, bbox_output])\n",
        "        model = Model(inputs = base_model.input, outputs = label_output)\n",
        "        \n",
        "    ##### End Model Architecture A \n",
        "\n",
        "    ##### Start Model Architecture C (Inception Base)\n",
        "    if (model_arch == 'C'):\n",
        "        # Retrieve arch. specific model dict parameters\n",
        "        mod_inp_shape = model_dict['mod_inp_shape'] # Shape of input tensor to model\n",
        "        weights = model_dict['weights'] \n",
        "        trainable = model_dict['trainable']\n",
        "        dropout_rate = model_dict['dropout_rate']\n",
        "        num_classes = model_dict['num_classes']\n",
        "        \n",
        "        base_model = inception_v3.InceptionV3(input_shape = mod_inp_shape, weights = weights,\\\n",
        "                                 include_top = False, pooling = 'avg')\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = trainable\n",
        "            \n",
        "        X = base_model.output\n",
        "        X = Flatten()(X)\n",
        "        X = Dropout(rate = dropout_rate[0], name = 'DR0')(X)        \n",
        "        X = Dense(1024, activation = 'relu')(X)        \n",
        "        X = Dropout(rate = dropout_rate[1], name = 'DR1')(X)\n",
        "        X = Dense(512, activation = 'relu')(X)        \n",
        "        X = Dropout(rate = dropout_rate[2], name = 'DR2')(X)\n",
        "        label_output = Dense(num_classes, activation = 'softmax', name = 'class_op')(X) \n",
        "\n",
        "        # # # Add output layer for bounding box regression\n",
        "        # bbox_output = Dense(4, activation = 'sigmoid', name = 'reg_op')(X)        \n",
        "        \n",
        "        # model = Model(inputs = base_model.input, outputs = [label_output, bbox_output])\n",
        "        model = Model(inputs = base_model.input, outputs = label_output)\n",
        "        \n",
        "    ##### End Model Architecture C        \n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93zleWqKvQ0q"
      },
      "source": [
        "### Verify Model Core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zQilif0vXsm"
      },
      "source": [
        "# Verify model defined above\n",
        "model_dict = {'model_arch': 'A',\n",
        "              'mod_inp_shape': mod_inp_shape,\n",
        "              'weights': 'imagenet',\n",
        "              'trainable': True,\n",
        "              'dropout_rate': [0.2, 0.2, 0.1],\n",
        "              'num_classes': num_classes\n",
        "              }\n",
        "temp_model = model_core(model_dict)\n",
        "temp_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBITB1rJIlsB"
      },
      "source": [
        "### Define Model_Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pusIvvIKIzNC"
      },
      "source": [
        "def model_compile(model, compile_dict):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function to compile the model\n",
        "    \n",
        "    Arguments:\n",
        "      model - Model instance that needs to be compiled\n",
        "      compile_dict - Dictionary with list of keys / values needed to compile the model\n",
        " \n",
        "    \"\"\"    \n",
        "    # Retrieve compile_dict parameters\n",
        "    ilr = compile_dict['ilr'] # Initial learning rate to use for learning rate decay scheduler    \n",
        "    dr = compile_dict['dr'] # Decay rate to use for learning rate decay scheduler    \n",
        "    ds = compile_dict['ds'] # Decay step to use for learning rate decay scheduler\n",
        "    redlr_plat = compile_dict['redlr_plat'] # Boolean: If True, implement reduce LR on plateau     \n",
        "\n",
        "    lr_sch = InverseTimeDecay(ilr, ds, dr) # Inverse Time Decay LR scheduler\n",
        "    # Define Optimizer\n",
        "    if (redlr_plat):\n",
        "      opt = optimizers.Adam(learning_rate = ilr) \n",
        "    else:\n",
        "      opt = optimizers.Adam(learning_rate = lr_sch)\n",
        "    loss = losses.CategoricalCrossentropy() # Define loss\n",
        "    met = [metrics.CategoricalAccuracy()] # Define metric\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer = opt, loss = loss, metrics = met)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tAuBzjiI125"
      },
      "source": [
        "### Define Model_Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6dVbZawL7fm"
      },
      "source": [
        "def model_fit(model, train_dict):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function to fit the model\n",
        "    \n",
        "    Arguments:\n",
        "      model - Model instance that needs to be trained\n",
        "      train_dict - Dictionary with list of keys / values needed to fit the model      \n",
        "\n",
        "    Returns:\n",
        "      model - Final trained model\n",
        "      hist - Model training history\n",
        "    \"\"\"   \n",
        "\n",
        "    # Retrieve path parameters\n",
        "    tb_path = train_dict['tb_path'] # Path to store Tensorboard callback information\n",
        "    mc_path = train_dict['mc_path'] # File name to use for storing model checkpoints\n",
        "    \n",
        "    # Retrieve callback parameters\n",
        "    mcp_freq = train_dict['mcp_freq'] # Number of batches after which model will be checkpointed    \n",
        "    early_stop = train_dict['early_stop'] # Boolean: If True, implement early stop\n",
        "    redlr_plat = train_dict['redlr_plat'] # Boolean: If True, implement reduce LR on plateau  \n",
        "    lrpl_fac = train_dict['lrpl_fac'] # Factor to use for Reduce LR on Plateau callback\n",
        "    lrpl_pat = train_dict['lrpl_pat'] # Patience to use for Reduce LR on Plateau callback    \n",
        "\n",
        "    # Retrieve training parameters\n",
        "    train_gen = train_dict['train_gen'] # Train Generator to use while fitting\n",
        "    val_data = train_dict['val_gen'] # Validation Generator to use while fitting\n",
        "    epochs = train_dict['epochs'] # Number of epochs to train for\n",
        "    initial_epoch = train_dict['initial_epoch'] # Initial epoch to re-start training from\n",
        "    train_steps_per_epoch = train_dict['train_steps_per_epoch'] # Number of steps per training epoch\n",
        "    val_steps = train_dict['val_steps'] # Number of steps before stopping validation\n",
        "    val_freq = train_dict['val_freq'] # Number of epochs to run before performing a validation run\n",
        "    verb = train_dict['verb'] # Controls verbosity level of model fit.\n",
        "\n",
        "    #### Start -  Define callbacks\n",
        "    # Define path for tensorboard logs\n",
        "    logdir = os.path.join(tb_path,\\\n",
        "                          datetime.datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\"%d%m_%H%M\"))\n",
        "    # Define Tensorboard callback\n",
        "    tensorboard_callback = TensorBoard(logdir, histogram_freq = 0)\n",
        "    # Define Model Checkpoint callback\n",
        "    mcp_callback = ModelCheckpoint(filepath = mc_path, monitor = \"val_loss\", save_freq = mcp_freq,\\\n",
        "                                   verbose = 0, save_best_only = True)\n",
        "    # Define Early Stopping callback\n",
        "    earlystopping_callback = EarlyStopping(monitor = \"val_loss\", min_delta = 0, patience = 15,\\\n",
        "                                           mode = \"min\", verbose = 1)\n",
        "    # Define 'Reduce learning rate on plateau' callback\n",
        "    redlr_plat_callback = ReduceLROnPlateau(monitor = \"val_loss\", factor = lrpl_fac, patience = lrpl_pat,\\\n",
        "                                            verbose = 1, mode = \"min\", min_delta = 0.0001)\n",
        "    # Define list of all callbacks\n",
        "    callback_list = []\n",
        "    if (tb_path != None): callback_list.append(tensorboard_callback)\n",
        "    if (mc_path != None): callback_list.append(mcp_callback)\n",
        "    if (early_stop): callback_list.append(earlystopping_callback)    \n",
        "    if (redlr_plat): callback_list.append(redlr_plat_callback)\n",
        "    #### End -  Define callbacks \n",
        "    \n",
        "    #### Start - Model Fit\n",
        "    hist = model.fit(x = train_gen, validation_data = val_data, epochs = epochs,\\\n",
        "                     initial_epoch = initial_epoch, steps_per_epoch = train_steps_per_epoch,\\\n",
        "                     validation_steps = val_steps, validation_freq = val_freq,\n",
        "                     callbacks = callback_list, verbose = verb)\n",
        "    #### End - Model Fit   \n",
        "\n",
        "    return model, hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3Kvqg5fL9QZ"
      },
      "source": [
        "### Define Model_Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68U0fp7zMBEY"
      },
      "source": [
        "def model_train(model_dict, compile_dict, train_dict, model = None):\n",
        "  \"\"\"\n",
        "  Function to instantiate (or load) model, compile and fit model.\n",
        "    \n",
        "  Arguments:\n",
        "    model_dict - Dictionary with list of keys / values needed to build the model\n",
        "    compile_dict - Dictionary with list of keys / values needed to compile the model\n",
        "    train_dict - Dictionary with list of keys / values needed to train the model\n",
        "    model - Pre-trained model (Pass this as input only if fit_resume = True and load_model = False)\n",
        "    \n",
        "  Returns:\n",
        "    model - Final trained model\n",
        "    hist - Model training history\n",
        " \n",
        "  \"\"\"   \n",
        "  # Retrieve train_dict parameters\n",
        "  fit_resume = train_dict['fit_resume'] # Boolean: If True, resume fit from initial epoch\n",
        "  load_model = train_dict['load_model'] # Boolean: If True, load model from 'fm_path' and resume fit  \n",
        "  recompile = train_dict['recompile'] # Boolean: If True, recompile model before resuming fit  \n",
        "  fm_path = train_dict['fm_path'] # File name to use for storing final trained model\n",
        "  hi_path = train_dict['hi_path'] # File name to use for storing training history\n",
        "\n",
        "  if (not(fit_resume)): # fit_resume = False => instantiating new model\n",
        "    print(\"Instantiating new model...\", end = ', ')\n",
        "    model = model_core(model_dict) # Instantiate new model\n",
        "    print(\"Compiling model...\", end = ', ')\n",
        "    model_compile(model, compile_dict) # Compile model\n",
        "    print(\"Model Fit started....\", end = ', ')    \n",
        "    model, hist = model_fit(model, train_dict) # Fit model\n",
        "  else: # fit_resume = True => Proceed with existing model in memory or load model from disk\n",
        "    if (load_model): # load_model = True => Load model from disk\n",
        "      print(\"Loading model from disk...\", end = ', ')\n",
        "      model = models.load_model(fm_path) # Reload model from disk\n",
        "      if (recompile): # Re-compile model if \"recompile\" = True\n",
        "        print(\"Re-Compiling model...\", end = ', ')\n",
        "        model_compile(model, compile_dict) \n",
        "      print(\"Resuming model fit....\", end = ', ')\n",
        "      model, hist = model_fit(model, train_dict) # Resume model fit\n",
        "    else: # load_model = False => Proceed with existing model in memory\n",
        "      if (recompile): # Re-compile model if \"recompile\" = True\n",
        "        print(\"Re-compiling model...\", end = ', ')\n",
        "        model_compile(model, compile_dict)\n",
        "      print(\"Resuming model fit....\", end = ', ')\n",
        "      model, hist = model_fit(model, train_dict) # Resume model fit\n",
        "\n",
        "  # Save final trained model and history to file\n",
        "  if (fm_path != None): model.save(fm_path, overwrite = True, save_format = 'h5') \n",
        "  if (hi_path != None): np.save(hi_path, hist.history)\n",
        "\n",
        "  return model, hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WSVV99eJAZ6"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RFWakvXIZ6l"
      },
      "source": [
        "### Define HyperModel Class (For Hyperparameter Tuning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekCnKh7eBsgJ"
      },
      "source": [
        "class MyHyperModel(HyperModel):\n",
        "\n",
        "  def __init__(self, model_dict, compile_dict, hp_dict):\n",
        "    self.model_dict_tune = model_dict.copy() # Dictionary of default model parameters\n",
        "    self.compile_dict_tune = compile_dict.copy() # Dictionary of default compilation parameters\n",
        "    self.hp_dict = hp_dict # Dictionary of hyperparameters to tune\n",
        "\n",
        "  def build(self, hp):\n",
        "    hp_list = [] # List placeholder to define all hyperparameters\n",
        "    for ind in range(len(hp_dict)): # Update hp_list based on hp_dict\n",
        "      if (hp_dict[ind][0] == 'choice'): hp_list.append(hp.Choice(name = hp_dict[ind][1],\\\n",
        "                                                                 values = hp_dict[ind][2],\\\n",
        "                                                                 ordered = hp_dict[ind][3]))    \n",
        "    # Set hyperparameters in model_dict_tune\n",
        "    self.model_dict_tune['dropout_rate'] = [hp_list[0], hp_list[1]]\n",
        "\n",
        "    model = model_core(self.model_dict_tune) # Instantiate model\n",
        "    model_compile(model, self.compile_dict_tune) # Compile model    \n",
        "   \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTNB3C8zI7rP"
      },
      "source": [
        "## Set model_core, model_compile, model_train parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXFkcpkFlG78"
      },
      "source": [
        "### Define file paths\n",
        "mod_file_pref = \"MA_9\" # Prefix to use for naming files and paths\n",
        "tb_path = os.path.join(tb_logs_base_path, mod_file_pref) # Tensorboard base path\n",
        "fm_path = os.path.join(out_base_path, mod_file_pref + \"_finalmodel.h5\") # Final trained model path\n",
        "#mc_path = os.path.join(out_base_path, mod_file_pref + \"_EP{epoch:04d}.h5\") # Model checkpoints path\n",
        "mc_path = os.path.join(\"/content\", mod_file_pref + \".h5\") # Model checkpoints path\n",
        "hi_path = os.path.join(out_base_path, mod_file_pref + \"_hist.npy\") # Training history path\n",
        "\n",
        "# Set model_dict values\n",
        "model_dict = {'model_arch': 'A',\n",
        "              'mod_inp_shape': mod_inp_shape,\n",
        "              'weights': 'imagenet',\n",
        "              'trainable': True,\n",
        "              'dropout_rate': [0.0, 0.0, 0.0],\n",
        "              'num_classes': num_classes\n",
        "              }\n",
        "# Set compile_dict values\n",
        "compile_dict = {'ilr': 5e-4, # Initial learning rate to use for learning rate decay scheduler    \n",
        "                'dr': 0, # Decay rate to use for learning rate decay scheduler\n",
        "                'ds': (len(train_generator) * 10), # Decay rate to use for learning rate decay scheduler\n",
        "                'redlr_plat': False, # Boolean: If True, implement reduce LR on plateau  \n",
        "               }\n",
        "# Set train_dict values               \n",
        "train_dict = {'fit_resume': False, # Boolean: If True, resume fit from initial epoch\n",
        "              'load_model': False, # Boolean: If True, load model from 'fm_path' and resume fit\n",
        "              'recompile': False, # Boolean: If True, recompile model before resuming fit\n",
        "              'train_gen': train_generator, # Train generator to use while fitting\n",
        "              'val_gen': val_generator, # Validation generator to use while fitting\n",
        "              'epochs': 25, # Number of epochs to train for              \n",
        "              'initial_epoch': 0, # Initial epoch to start from              \n",
        "              'train_steps_per_epoch': len(train_generator), # No. of steps per epoch\n",
        "              'val_steps': len(val_generator), # No. of steps before stopping eval of val set\n",
        "              'val_freq': 1, # Number of epochs to run before performing a validation run\n",
        "              'verb': 1, # Controls verbosity level of model fit.\n",
        "              'mcp_freq': \"epoch\", # Checkpoint model after mcp_freq batches\n",
        "              'early_stop': True, # Boolean: If True, implement early stop\n",
        "              'redlr_plat': compile_dict['redlr_plat'], # Boolean: If True, implement reduce LR on plateau\n",
        "              'lrpl_fac': 0.5, # Factor to use for Reduce LR on Plateau callback\n",
        "              'lrpl_pat': 10, # Patience to use for Reduce LR on Plateau callback              \n",
        "              'tb_path': tb_path, # Path to store Tensorboard callback information\n",
        "              'mc_path': mc_path, # File name to use for storing model checkpoints\n",
        "              'fm_path': fm_path, # File name to use for storing final trained model\n",
        "              'hi_path': hi_path, # File name to use for storing training history\n",
        "              }\n",
        "\n",
        "print(tb_path)\n",
        "print(mc_path)\n",
        "print(fm_path)\n",
        "print(hi_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szj1Zm_A_96z"
      },
      "source": [
        "## Launch Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgDf2PM3__xC"
      },
      "source": [
        "%tensorboard --logdir {tb_logs_base_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHx2QAnCJHA7"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZVDA5n7MFdq"
      },
      "source": [
        "# Get start time of run and display it\n",
        "start_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
        "print(\"Started at %s\" %(start_time.strftime(\"%H:%M:%S\")), end = '; ')\n",
        "\n",
        "# Instantiate, compile and fit model\n",
        "if (train_dict['fit_resume'] and not(train_dict['load_model'])):\n",
        "  model, hist = model_train(model_dict, compile_dict, train_dict, model)\n",
        "else:\n",
        "  model, hist = model_train(model_dict, compile_dict, train_dict)\n",
        "\n",
        "# Get end time of run and display elapsed time\n",
        "end_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
        "elap_time = ((end_time - start_time).total_seconds())/60\n",
        "print(\"\\nCompleted at %s. Elapsed time = %0.2f minutes.\" %(end_time.strftime(\"%H:%M:%S\"), elap_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3su63TDX_pYp"
      },
      "source": [
        "# Copy best model to drive\n",
        "model_path = os.path.join(out_base_path, mod_file_pref + \"_bestmodel.h5\")\n",
        "!cp /content/MA_9.h5 {model_path}\n",
        "!rm /content/MA_9.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmVh2Trkw2Yc"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrhhtKJKw5uA"
      },
      "source": [
        "project_name = \"MA_DR_Tune\" # Directory to store results of hyperparameter tuning\n",
        "\n",
        "# Define hyperparameters in hp_dict\n",
        "hp_dict = {0: ['choice', 'Dropout_0', [0.2, 0.3, 0.4, 0.5], True],\n",
        "           1: ['choice', 'Dropout_1', [0.2, 0.3, 0.4, 0.5], True],\n",
        "           }\n",
        "\n",
        "# Instantiate hypermodel           \n",
        "hypermodel = MyHyperModel(model_dict, compile_dict, hp_dict) \n",
        "\n",
        "# Instantiate Tuner\n",
        "tuner = kt.RandomSearch(hypermodel, objective = 'val_categorical_accuracy', max_trials = 2,\\\n",
        "                        seed = 1234, directory = kt_logs_base_path, project_name = project_name)\n",
        "\n",
        "# Display Hyperparameter Search Space\n",
        "tuner.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-LH0cQt2W75"
      },
      "source": [
        "# Run hyperparameter search\n",
        "tuner.search(x = train_dict['train_gen'], validation_data = train_dict['val_gen'],\\\n",
        "             epochs = 2, steps_per_epoch = train_dict['train_steps_per_epoch'],\\\n",
        "             validation_steps = train_dict['val_steps'], verbose = 1)\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0].get_config()['values']\n",
        "print()\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(\"---------------------\")\n",
        "print(best_hps)\n",
        "\n",
        "# best_hps_dict = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "# best_model = tuner.hypermodel.build(best_hps_dict)\n",
        "# best_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQZt9YRQo3p2"
      },
      "source": [
        "# Results Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_iswhhUZF0q"
      },
      "source": [
        "## Define Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMBiXqvTZKQ9"
      },
      "source": [
        "### Function: get_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0mvSDZIZOV-"
      },
      "source": [
        "def get_model(mod_file_prefix, best_model, print_summary = False):\n",
        "  '''\n",
        "  Function to return required paths, loaded model and print model summary\n",
        "\n",
        "  Arguments:\n",
        "    mod_file_prefix: # Prefix of model file name\n",
        "    best_model: Boolean. If True, load best_model, else load final model\n",
        "    print_summary: Boolean. If True, print model summary\n",
        "  '''\n",
        "  fm_path = os.path.join(out_base_path, mod_file_pref + \"_finalmodel.h5\") # Final model path\n",
        "  bm_path = os.path.join(out_base_path, mod_file_pref + \"_bestmodel.h5\")\n",
        "  hi_path = os.path.join(out_base_path, mod_file_pref + \"_hist.npy\") # History file path\n",
        "  \n",
        "  # Load model with final trained weights\n",
        "  if (best_model): # best_model = True => Load best model\n",
        "    model = models.load_model(bm_path) \n",
        "  else: # best_model = False => Load final model\n",
        "    model = models.load_model(fm_path) \n",
        "\n",
        "  # Print model summary\n",
        "  if (print_summary):\n",
        "    display(model.summary())\n",
        "\n",
        "  return fm_path, hi_path, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxPHQr8glq3H"
      },
      "source": [
        "### Function: plot_lc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgYAGz1qjzrA"
      },
      "source": [
        "def plot_lc(mod_file_pref, hi_path, hist_plot_dict, num_cols, col_size, row_size):\n",
        "  '''\n",
        "  Function to plot learning curves \n",
        "\n",
        "  Arguments:\n",
        "    hi_path: path of history file\n",
        "    hist_plot_dict: Dictionary containing items to plot\n",
        "    num_cols: Number of columns to use for plotting\n",
        "    col_size: Column width to use while plotting\n",
        "    row_size: Row width to use while plotting\n",
        "  '''\n",
        "  hist_model = np.load(hi_path, allow_pickle = 'TRUE').item()\n",
        "  \n",
        "  num_plots = len(hist_plot_dict)\n",
        "  num_rows = math.ceil(num_plots / num_cols) # Number of rows to use for plotting\n",
        "\n",
        "  fig = plt.figure(figsize = ((num_cols * col_size), (num_rows * row_size)))\n",
        "  fig.suptitle(mod_file_pref + \" Learning Curves\", fontsize = 20)\n",
        "\n",
        "  for ind, value in enumerate(hist_plot_dict.items()):\n",
        "    ax = plt.subplot(num_rows, num_cols, (ind + 1))\n",
        "    for key in value[1][0].keys():\n",
        "      ax.plot(hist_model[key], value[1][0][key][0], label = value[1][0][key][1])     \n",
        "      ax.set_title(value[1][1], fontsize = 20)\n",
        "      ax.set_ylabel(value[1][2], fontsize = 20)\n",
        "      ax.set_xlabel(value[1][3], fontsize = 20)\n",
        "      ax.grid(b = True)\n",
        "      ax.legend(fontsize = 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SniyJYtXjJ5"
      },
      "source": [
        "### Function: plot_cm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZxI4S_u02yr"
      },
      "source": [
        "def plot_cm(train_gen, val_gen, test_gen, y_train, y_val, y_test, row_size, col_size):\n",
        "\n",
        "  '''\n",
        "  Function to plot confusion matrices for train, val and test sets\n",
        "\n",
        "  Arguments:\n",
        "    train_gen: Train generator without augmentation and shuffling\n",
        "    val_gen: Validation generator without augmentation and shuffling\n",
        "    test_gen: Test generator without augmentation and shuffling\n",
        "    y_train: Ground-truth training set labels\n",
        "    y_val: Ground-truth validation set labels\n",
        "    y_test: Ground-truth testing set labels\n",
        "    row_size: Row size to use for plotting\n",
        "    col_size: Column size to use for plotting\n",
        "  '''\n",
        "\n",
        "  # Obtain predicted labels for training, validation and testing sets\n",
        "  y_train_pred = np.argmax(model.predict(x = train_gen, steps = len(train_gen), verbose = 0), axis = 1)\n",
        "  y_val_pred = np.argmax(model.predict(x = val_gen, steps = len(val_gen), verbose = 0), axis = 1)\n",
        "  y_test_pred = np.argmax(model.predict(x = test_gen, steps = len(test_gen), verbose = 0), axis = 1)    \n",
        "\n",
        "  # Generate confusion matrices\n",
        "  cm_train = tf.math.confusion_matrix(y_train, y_train_pred).numpy()\n",
        "  cm_val = tf.math.confusion_matrix(y_val, y_val_pred).numpy()  \n",
        "  cm_test = tf.math.confusion_matrix(y_test, y_test_pred).numpy()\n",
        "\n",
        "  # Convert confusion matrices to pandas DF\n",
        "  index = [('A' + str(a)) for a in list(np.unique(y_train).astype(np.int))]\n",
        "  columns = [('P' + str(a)) for a in list(np.unique(y_train).astype(np.int))]\n",
        "  cm_train_df = pd.DataFrame(cm_train, index = index, columns = columns)\n",
        "  cm_val_df = pd.DataFrame(cm_val, index = index, columns = columns)  \n",
        "  cm_test_df = pd.DataFrame(cm_test, index = index, columns = columns)\n",
        "\n",
        "  # Plot confusion matrices\n",
        "  fig = plt.figure(figsize = (col_size, (3 * row_size)))\n",
        "\n",
        "  ax1 = plt.subplot(3, 1, 1)\n",
        "  sns.heatmap(cm_train_df, annot_kws = {\"fontsize\": 15}, linewidths = 1,\\\n",
        "              linecolor = 'black', cmap = 'Blues', annot = True ,fmt = 'g',\\\n",
        "              cbar = False, ax = ax1)\n",
        "  ax1.set_title(\"Confusion Matrix for Training set\", fontsize = 25)\n",
        "  ax1.tick_params(labelsize = 20)\n",
        "\n",
        "  ax2 = plt.subplot(3, 1, 2)\n",
        "  sns.heatmap(cm_val_df, annot_kws = {\"fontsize\": 15}, linewidths = 1,\\\n",
        "              linecolor = 'black', cmap = 'Blues', annot = True ,fmt = 'g',\\\n",
        "              cbar = False, ax = ax2)\n",
        "  ax2.set_title(\"Confusion Matrix for Validation set\", fontsize = 25)\n",
        "  ax2.tick_params(labelsize = 20)\n",
        "\n",
        "  ax3 = plt.subplot(3, 1, 3)\n",
        "  sns.heatmap(cm_test_df, annot_kws = {\"fontsize\": 15}, linewidths = 1,\\\n",
        "              linecolor = 'black', cmap = 'Blues', annot = True ,fmt = 'g',\\\n",
        "              cbar = False, ax = ax3)\n",
        "  ax3.set_title(\"Confusion Matrix for Test set\", fontsize = 25)\n",
        "  ax3.tick_params(labelsize = 20)  \n",
        "\n",
        "  plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxGjt-5MwOsV"
      },
      "source": [
        "### Function: predict_and_plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78dEw14XnhUj"
      },
      "source": [
        "def predict_and_plot(X, y, samp_indices, model, num_cols, col_size, row_size, fig_title):\n",
        "\n",
        "  '''\n",
        "  Function to make predictions on a subset of data and plot images with actual\n",
        "  and predicted labels\n",
        "\n",
        "  Arguments:\n",
        "    X: Input image array\n",
        "    y: Input label array\n",
        "    samp_indices: Indices from X to be plotted\n",
        "    model: Model instance to use for making predictions\n",
        "    num_cols: Number of columns to use for plotting\n",
        "    col_size: Size of columns to use for plotting\n",
        "    row_size: Size of rows to use for plotting\n",
        "    fig_title: Title to use for overall figure\n",
        "  ''' \n",
        "\n",
        "  num_rows = math.ceil(len(samp_indices) / num_cols) # Number of rows to use for plotting\n",
        "  fig = plt.figure(figsize = ((num_cols * col_size), (num_rows * row_size)))\n",
        "  fig.suptitle(fig_title, fontsize = 40)\n",
        "\n",
        "  for ind, samp_ind in enumerate(samp_indices):\n",
        "    img = np.expand_dims(X[samp_ind].copy(), axis = 0)\n",
        "    img = preprocess_data(img)\n",
        "    y_pred = np.argmax(model.predict(img), axis = 1)[0]\n",
        "    ax = plt.subplot(num_rows, num_cols, (ind + 1))\n",
        "    ax.text(0.5, 1.35, f\"Sample index is {samp_ind}\", transform = ax.transAxes,\\\n",
        "            horizontalalignment = 'center', verticalalignment = 'center',\\\n",
        "            color = 'black', fontfamily = 'sans-serif', fontsize = '22')    \n",
        "    ax.text(0.5, 1.20, f\"Actual label is {y[samp_ind]}\", transform = ax.transAxes,\\\n",
        "            horizontalalignment = 'center', verticalalignment = 'center',\\\n",
        "            color = 'black', fontfamily = 'sans-serif', fontsize = '22')    \n",
        "    ax.text(0.5, 1.05, f\"Predicted label is {y_pred}\", transform = ax.transAxes,\\\n",
        "            horizontalalignment = 'center', verticalalignment = 'center',\\\n",
        "            color = 'black', fontfamily = 'sans-serif', fontsize = '22')    \n",
        "    ax.imshow(img[0].squeeze(), cmap = 'gray')\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccXOB8IpbSAu"
      },
      "source": [
        "## Model_1: \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnfMDTb_Y5tD"
      },
      "source": [
        "### Define file paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQN2p3yZY6_6"
      },
      "source": [
        "mod_file_pref = \"MA_9\"\n",
        "fm_path, hi_path, model = get_model(mod_file_pref, best_model = False, print_summary = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3kZGuqDwjH1"
      },
      "source": [
        "### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJHVf5aeds8o"
      },
      "source": [
        "hist_plot_dict = {0: [{'loss': ['r-', 'Training_Set_Loss'],\n",
        "                       'val_loss': ['b-', 'Validation_Set_Loss']},\n",
        "                      'Loss vs. #Epoch', 'Loss', '# Epochs'],\n",
        "                  1: [{'categorical_accuracy': ['r-', 'Training_Set_Accuracy'],\n",
        "                      'val_categorical_accuracy': ['b-', 'Validation_Set_Accuracy']},\n",
        "                      'Accuracy vs. #Epoch', 'Accuracy', '# Epochs']\n",
        "                  }\n",
        "plot_lc(mod_file_pref, hi_path, hist_plot_dict, 2, 7, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwaPm5YwtVt"
      },
      "source": [
        "### Evaluate model on training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmpQYEW3wtVx"
      },
      "source": [
        "# Evaluate model on training set\n",
        "res = model.evaluate(x = train_generator, steps = len(train_generator), verbose = 1, return_dict = True)\n",
        "print(\"Training set loss is %0.4f\" % res['loss'])\n",
        "print(\"Training set accuracy is %0.2f %%\" % (100 * res['categorical_accuracy']))\n",
        "print()\n",
        "# # Evaluate model on validation set\n",
        "# res = model.evaluate(x = val_generator, steps = len(val_generator), verbose = 1, return_dict = True)\n",
        "# print(\"Validation set loss is %0.4f\" % res['loss'])\n",
        "# print(\"Validation set accuracy is %0.2f %%\" % (100 * res['categorical_accuracy']))\n",
        "# print()\n",
        "# # Evaluate model on test set\n",
        "# res = model.evaluate(x = test_generator, steps = len(test_generator), verbose = 1, return_dict = True)\n",
        "# print(\"Test set loss is %0.4f\" % res['loss'])\n",
        "# print(\"Test set accuracy is %0.2f %%\" % (100 * res['categorical_accuracy']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsN8doP3x2lG"
      },
      "source": [
        "### Plot Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pykY1SdXqFj"
      },
      "source": [
        "# Regenerate train, val and test generators without augmentation and shuffling\n",
        "train_datagen_cm = ImageDataGenerator(preprocessing_function = preprocess_data)\n",
        "val_datagen_cm = ImageDataGenerator(preprocessing_function = preprocess_data)\n",
        "test_datagen_cm = ImageDataGenerator(preprocessing_function = preprocess_data)\n",
        "\n",
        "train_gen_cm = train_datagen_cm.flow(X_train, y_train_ohe, batch_size = mod_bat_size,\\\n",
        "                                           shuffle = False)\n",
        "val_gen_cm = val_datagen_cm.flow(X_val, y_val_ohe, batch_size = mod_bat_size,\\\n",
        "                                           shuffle = False)\n",
        "test_gen_cm = test_datagen_cm.flow(X_test, y_test_ohe, batch_size = mod_bat_size,\\\n",
        "                                           shuffle = False)\n",
        "\n",
        "plot_cm(train_gen_cm, val_gen_cm, test_gen_cm, y_train, y_val, y_test, 8, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEKS2o2UKuWS"
      },
      "source": [
        "### Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyYPi_x0iRBJ"
      },
      "source": [
        "### Use this to plot random images from a particular set\n",
        "# samp_indices = np.random.randint(low = 0, high = X_train.shape[0], size = 10)\n",
        "# fig_title = 'Random Images from training set'\n",
        "\n",
        "### Use this to plot random images corresponding to a particular label\n",
        "# label = 5\n",
        "# full_indices = np.nonzero(y_train == label)[0]\n",
        "# samp_indices = list(np.random.choice(full_indices, size = 10))\n",
        "# fig_title = f'Images from training set with actual label = {label}'\n",
        "\n",
        "### Use this to plot random images corresponding to incorrect predictions from a particular set\n",
        "# y_train_pred = np.argmax(model.predict(x = train_gen_cm, steps = len(train_gen_cm), verbose = 0),\\\n",
        "#                          axis = 1)\n",
        "# full_indices = np.nonzero(y_train != y_train_pred)[0]\n",
        "# samp_indices = list(np.random.choice(full_indices, size = 10))\n",
        "# fig_title = 'Images from training set corresponding to incorrect predictions'\n",
        "\n",
        "### Use this to plot random images corresponding to incorrect predictions of a particular label\n",
        "y_train_pred = np.argmax(model.predict(x = train_gen_cm, steps = len(train_gen_cm), verbose = 0),\\\n",
        "                         axis = 1)\n",
        "label = 8\n",
        "full_indices = np.nonzero(y_train == label)[0]\n",
        "full_indices = full_indices[np.nonzero(y_train[full_indices] != y_train_pred[full_indices])]\n",
        "samp_indices = list(np.random.choice(full_indices, size = 10))\n",
        "fig_title = f'Images from training set with incorrect predictions of label = {label}'\n",
        "\n",
        "# Predict and plot\n",
        "predict_and_plot(X_train, y_train, samp_indices, model, 5, 5, 7, fig_title)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}