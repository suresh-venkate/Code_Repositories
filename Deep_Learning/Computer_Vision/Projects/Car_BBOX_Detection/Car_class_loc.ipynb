{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Object Localization - Oxford IIIT Pet Dataset.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "rDL5UxUs0nUu",
        "KIN4CgX185lH"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "256px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suresh-venkate/Code_Repositories/blob/main/Deep_Learning/Computer_Vision/Projects/Car_BBOX_Detection/Car_class_loc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3O4hpWuaxld"
      },
      "source": [
        "# Car model classification and BBOX generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEns07Jmaz-j"
      },
      "source": [
        "# Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5b5pJF20r3k"
      },
      "source": [
        "### Use this for Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKxFOKUUo_0e"
      },
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N5VK89Taxlg"
      },
      "source": [
        "import pandas as pd # Pandas\n",
        "import numpy as np # Numpy\n",
        "import tensorflow as tf # Tensorflow\n",
        "import matplotlib.pyplot as plt # Matplotlib\n",
        "import matplotlib.image as mpimg # Import image module from matplotlib\n",
        "import seaborn as sns # Seaborn\n",
        "import time # Time library\n",
        "import math # Math library\n",
        "import datetime, os # Required for tensorboard\n",
        "import pytz\n",
        "import shutil # For killing tensorboard instance\n",
        "import cv2 # OpenCV Library \n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow import keras # Import keras\n",
        "from tensorflow.keras import layers # Import layers from keras\n",
        "from tensorflow.keras import regularizers # Import regularizers from keras\n",
        "from tensorflow.keras import models # Import models from keras\n",
        "from tensorflow.keras import Model # Import Model class from keras\n",
        "from tensorflow.keras import optimizers # Import optimizers from keras\n",
        "from tensorflow.keras import losses # Import losses from keras\n",
        "from tensorflow.keras import metrics # Import metrics from keras\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img # Import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array # Import img_to_array\n",
        "\n",
        "# Import Sequential model\n",
        "from tensorflow.keras.models import Sequential \n",
        "# Import Input, Flatten, Dense, Activation, Conv2D and MaxPooling2D layers\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPooling2D\n",
        "# Import BatchNormalization and Dropout layers\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "\n",
        "from tensorflow.keras.initializers import HeNormal # He Normal initializer\n",
        "\n",
        "# Import InverseTimeDecay learning rate scheduler\n",
        "from tensorflow.keras.optimizers.schedules import InverseTimeDecay \n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard # Import Tensorboard callback\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint # Import model checkpoint callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Import early stopping callback\n",
        "from tensorflow.keras.callbacks import CSVLogger # Import CSV Logger callback\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau # Import ReduceLROnPlateau callback\n",
        "\n",
        "# Load pre-trained models from keras\n",
        "from tensorflow.keras.applications import Xception # Import Xception model\n",
        "from tensorflow.keras.applications import ResNet50 # Import ResNet50 model\n",
        "from tensorflow.keras.applications import resnet50 # To use for preprocessing function\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical # Import One-hot encoding function\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PniDauYzaxli"
      },
      "source": [
        "# Define directory paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suearJBuaxli"
      },
      "source": [
        "### Use this for Google Colab\n",
        "\n",
        "# Define base path for TensorBoard Logs directory\n",
        "tb_logs_base_dir = \"/content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Car_class_loc/TB_Logs/\"\n",
        "os.makedirs(tb_logs_base_dir, exist_ok = True) # Don't raise any exception if directory exists\n",
        "\n",
        "# Define base path for storing all outputs related to model / training\n",
        "out_base_path = \"/content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Car_class_loc/Training_Info/\"\n",
        "\n",
        "# Define base path of dataset\n",
        "dataset_path = \"/content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Datasets/Image_Datasets/Stanford_Car_Dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIN4CgX185lH"
      },
      "source": [
        "# Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8917QeUAf1lz"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Copy dataset from Google Drive\n",
        "!cp /content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Datasets/Image_Datasets/Stanford_Car_Dataset/Reduced_Dataset.zip .\n",
        "# Unzip dataset file\n",
        "!unzip Reduced_Dataset.zip\n",
        "# Delete zip file\n",
        "!rm Reduced_Dataset.zip\n",
        "\n",
        "# Re-define dataset path\n",
        "dataset_path = \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCyipZzYZr_"
      },
      "source": [
        "# Create Label Mapping File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4mftPmnVhgA"
      },
      "source": [
        "# Create a dictionary mapping from Label to Class. \n",
        "classes_path = os.path.join(dataset_path, 'class_names.csv')\n",
        "classes = pd.read_csv(classes_path, header = None, names = ['class'])\n",
        "\n",
        "label_class_dict = {}\n",
        "for row in classes.iterrows():\n",
        "    label_class_dict[row[0] + 1] = row[1]['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98RE4JSU2bdF",
        "scrolled": false
      },
      "source": [
        "# Define paths of train and test annotation files\n",
        "annot_train_red_csv_path = os.path.join(dataset_path, \"annot_train_red.csv\")\n",
        "annot_test_red_csv_path = os.path.join(dataset_path, \"annot_test_red.csv\")\n",
        "\n",
        "# Read train and test annotation csv files as pandas dataframes, csv file has no header\n",
        "train_df = pd.read_csv(annot_train_red_csv_path, index_col = False)\n",
        "#test_df = pd.read_csv(ann_test_csv_path, header = None, names = col_names, index_col = False)\n",
        "test_df = pd.read_csv(annot_test_red_csv_path, index_col = False)\n",
        "\n",
        "# # Add class value to train and test dataframes\n",
        "# for ind, row in train_df.iterrows():\n",
        "#     train_df.loc[ind, 'class'] = label_class_dict[row['label']]\n",
        "# for ind, row in test_df.iterrows():\n",
        "#     test_df.loc[ind, 'class'] = label_class_dict[row['label']]\n",
        "\n",
        "print(\"Training Set:\")\n",
        "print(\"-------------\")\n",
        "display(train_df.head())\n",
        "print()\n",
        "print(\"Test Set:\")\n",
        "print(\"---------\")\n",
        "display(test_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBQRF_RC4Pzc"
      },
      "source": [
        "num_classes_train = len(train_df['label'].unique()) # Compute number of unique classes in training dataset\n",
        "num_classes_test = len(test_df['label'].unique()) # Compute number of unique classes in test dataset\n",
        "print(\"Number of unique classes in training dataset is %d\" % num_classes_train)\n",
        "print(\"Number of unique classes in test dataset is %d\" % num_classes_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV5dELnxaxlq"
      },
      "source": [
        "## Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LOgFtL_axlq"
      },
      "source": [
        "# Plot four random images from training data set along with their class labels and bounding boxes\n",
        "fig = plt.figure(1, figsize = (12, 12))\n",
        "fig.suptitle('Random images in the training dataset', fontsize = 30)\n",
        "\n",
        "# Generate four random sample indices from the training dataset.\n",
        "samp_index = np.random.randint(low = 0, high = train_df.shape[0], size = 4).tolist()\n",
        "\n",
        "for ind, value in enumerate(samp_index):\n",
        "    ax = plt.subplot(2, 2, (ind + 1))\n",
        "    file_path = os.path.join(dataset_path, \"train_images/\", train_df.loc[value,'filename'])\n",
        "    img = mpimg.imread(file_path) # Read the image file\n",
        "    xmin = train_df.loc[value, 'xmin'] # xmin co-ordinate of BBOX\n",
        "    ymin = train_df.loc[value, 'ymin'] # ymin co-ordinate of BBOX\n",
        "    xmax = train_df.loc[value, 'xmax'] # xmax co-ordinate of BBOX\n",
        "    ymax = train_df.loc[value, 'ymax'] # ymax co-ordinate of BBOX    \n",
        "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (255, 0, 0), 4) # Add BBOX around image\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(\"Class label is %d; Class is %s\"\\\n",
        "                 %(train_df.loc[value, 'label'], train_df.loc[value, 'class']), fontsize = 14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aEwo3Peaxlr"
      },
      "source": [
        "# Plot four random images from test data set along with their class labels and bounding boxes\n",
        "fig = plt.figure(1, figsize = (12, 12))\n",
        "fig.suptitle('Random images in the test dataset', fontsize = 30)\n",
        "\n",
        "# Generate four random sample indices from the test dataset.\n",
        "samp_index = np.random.randint(low = 0, high = 100, size = 4).tolist()\n",
        "\n",
        "for ind, value in enumerate(samp_index):\n",
        "    ax = plt.subplot(2, 2, (ind + 1))\n",
        "    file_path = os.path.join(dataset_path, \"test_images/\", test_df.loc[value,'filename'])\n",
        "    img = mpimg.imread(file_path) # Read the image file\n",
        "    xmin = test_df.loc[value, 'xmin'] # xmin co-ordinate of BBOX\n",
        "    ymin = test_df.loc[value, 'ymin'] # ymin co-ordinate of BBOX\n",
        "    xmax = test_df.loc[value, 'xmax'] # xmax co-ordinate of BBOX\n",
        "    ymax = test_df.loc[value, 'ymax'] # ymax co-ordinate of BBOX    \n",
        "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (255, 0, 0), 4) # Add BBOX around image\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(\"Class label is %d; Class is %s\"\\\n",
        "                 %(test_df.loc[value, 'label'], test_df.loc[value, 'class']), fontsize = 14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbePE8pDUap"
      },
      "source": [
        "# Function: Define a Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaaQMAyLaxls"
      },
      "source": [
        "def batch_generator(df, batch_size = 32, img_size_targ = (224, 224), num_classes_train = 196):\n",
        "    \n",
        "    while (True):\n",
        "\n",
        "        # Create indexes\n",
        "        image_indexes = np.random.randint(0, df.shape[0], size = batch_size).tolist()\n",
        "\n",
        "        # Initialize array to store a batch of images\n",
        "        batch_images = np.zeros(shape = (batch_size, img_size_targ[0], img_size_targ[1], 3))\n",
        "\n",
        "        # Initialize array to store classification Labels for the above batch of images\n",
        "        batch_labels = np.zeros(shape = (batch_size, num_classes_train))\n",
        "\n",
        "        # Initialize array to store bbox co-ordinates for the above batch of images\n",
        "        # 4 values per image\n",
        "        batch_bboxes = np.zeros(shape = (batch_size, 4))\n",
        "\n",
        "        for ind, val in enumerate(image_indexes):\n",
        "\n",
        "            # Read image, resize and convert to array\n",
        "            file_path = os.path.join(dataset_path, \"train_images\", df.loc[val, 'filename'])\n",
        "            img = load_img(file_path, target_size = img_size_targ)\n",
        "            img_array = img_to_array(img)\n",
        "            \n",
        "            # Pre-process image using resnet50.preprocess_input\n",
        "            img_array = resnet50.preprocess_input(img_array)\n",
        "\n",
        "            # Read image classification label & convert to one hot vector\n",
        "            cl_label = (df.loc[val, 'label'] - 1)\n",
        "            cl_label = to_categorical(cl_label, num_classes = num_classes_train)\n",
        "\n",
        "            # Get size and BBOX co-ordinates of original image\n",
        "            img_width_orig = df.loc[val, 'img_w'] # Width of original image\n",
        "            img_height_orig = df.loc[val, 'img_h'] # Height of original image\n",
        "            xmin_orig = df.loc[val, 'xmin'] # xmin co-ordinate of BBOX in original image\n",
        "            ymin_orig = df.loc[val, 'ymin'] # ymin co-ordinate of BBOX in original image\n",
        "            xmax_orig = df.loc[val, 'xmax'] # xmax co-ordinate of BBOX in original image\n",
        "            ymax_orig = df.loc[val, 'ymax'] # ymax co-ordinate of BBOX in original image\n",
        "\n",
        "            # Scale BBOX co-ordinates to an image of size (1, 1)\n",
        "            xmin_norm = (xmin_orig / img_width_orig)\n",
        "            ymin_norm = (ymin_orig / img_height_orig)\n",
        "            xmax_norm = (xmax_orig / img_width_orig)\n",
        "            ymax_norm = (ymax_orig / img_height_orig)\n",
        "            width_bbox_norm = xmax_norm - xmin_norm\n",
        "            height_bbox_norm = ymax_norm - ymin_norm\n",
        "            bbox_sc = [xmin_norm, ymin_norm, width_bbox_norm, height_bbox_norm]\n",
        "\n",
        "            # Add above image, OHE label and BBOX co-ords to current batch\n",
        "            batch_images[ind] = img_array\n",
        "            batch_labels[ind] = cl_label\n",
        "            batch_bboxes[ind] = bbox_sc\n",
        "\n",
        "        # Return batch - use yield function to make it a python generator\n",
        "        #yield batch_images, [batch_labels, batch_bboxes]\n",
        "        yield batch_images, batch_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdYc0w_2axlt"
      },
      "source": [
        "## Define target image size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP7ksj-taxlu"
      },
      "source": [
        "img_height_targ, img_width_targ, img_chan_targ = (224, 224, 3)\n",
        "img_size_targ = (img_height_targ, img_width_targ, img_chan_targ)\n",
        "img_size_targ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGJ_pEAKaxlu"
      },
      "source": [
        "## Verify batch generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY0bkpiCaxlv"
      },
      "source": [
        "batch_size = 32\n",
        "gen = batch_generator(train_df, batch_size = batch_size, img_size_targ = img_size_targ[:2],\\\n",
        "                      num_classes_train = num_classes_train)\n",
        "print(gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlePDSjQaxlw"
      },
      "source": [
        "#batch_images, [batch_labels, batch_bboxes] = next(gen)\n",
        "batch_images, batch_labels = next(gen)\n",
        "print(\"Shape of batch_images is {}\" .format(batch_images.shape))\n",
        "print(\"Shape of batch_labels is {}\" .format(batch_labels.shape))\n",
        "#print(\"Shape of batch_bboxes is {}\" .format(batch_bboxes.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VKXcO06axlw"
      },
      "source": [
        "## Visualize a few images from the batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ6X6Bwpaxlw"
      },
      "source": [
        "# Plot four random images from the batch along with their class labels and bounding boxes\n",
        "fig = plt.figure(1, figsize = (12, 12))\n",
        "fig.suptitle('Random images in the batch', fontsize = 30)\n",
        "\n",
        "# Generate four random sample indices from the batch.\n",
        "samp_index = np.random.randint(low = 0, high = batch_size, size = 4).tolist()\n",
        "\n",
        "for ind, value in enumerate(samp_index):\n",
        "    ax = plt.subplot(2, 2, (ind + 1))\n",
        "\n",
        "    # Extract image from batch\n",
        "    img = batch_images[value].copy()\n",
        "    # Undo Resnet50 pre-processing\n",
        "    mean = [103.939, 116.779, 123.68]\n",
        "    img[..., 0] += mean[0]\n",
        "    img[..., 1] += mean[1]\n",
        "    img[..., 2] += mean[2]\n",
        "    img = img[..., ::-1].astype('uint8')\n",
        "    \n",
        "    # Extract image label\n",
        "    label = np.argmax(batch_labels[value]) + 1\n",
        "    \n",
        "    # Extract bbox co-ordinates\n",
        "    # bbox = batch_bboxes[value]\n",
        "    # xmin_sc = int(bbox[0] * img_size_targ[1])\n",
        "    # ymin_sc = int(bbox[1] * img_size_targ[0])\n",
        "    # xmax_sc = int((bbox[0] + bbox[2]) * img_size_targ[1])\n",
        "    # ymax_sc = int((bbox[1] + bbox[3]) * img_size_targ[0])\n",
        "    # cv2.rectangle(img, (xmin_sc, ymin_sc), (xmax_sc, ymax_sc),\\\n",
        "    #               (255, 0, 0), 4) # Add BBOX around image\n",
        "    \n",
        "    # Plot image with BBOX\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(\"Class label is %d; Class is %s\"\\\n",
        "                 %(label, label_class_dict[label]), fontsize = 14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFGPcGaMJt9-"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVsOspzVaxlx"
      },
      "source": [
        "## Function - Define Model Core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQcwza8Taxlx"
      },
      "source": [
        "def model_core(model_dict):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function to define the model core.\n",
        "    \n",
        "    Arguments:\n",
        "    model_dict - Dictionary with list of keys / values needed to build the model\n",
        "      'model_arch' - Single alphabet string indicating what model architecture to use\n",
        "      'use_bnorm' - Boolean: If true, use BatchNormalization layer after each hidden layer\n",
        "      'dropout_rate' - Value of dropout rate to use.\n",
        "      'resnet_weights' - Set to either None or 'imagenet'\n",
        "      'resnet_train': Boolean, If True, train ResNet50 weights also.\n",
        "\n",
        "    Returns:\n",
        "    model - Model with all layers instantiated\n",
        " \n",
        "    \"\"\"    \n",
        "    # Retrieve model dict parameters\n",
        "    model_arch = model_dict['model_arch']\n",
        "\n",
        "    ##### Start Model Architecture A\n",
        "    if (model_arch == 'A'):\n",
        "        # Retrieve arch. specific model dict parameters\n",
        "        resnet_weights = model_dict['resnet_weights']\n",
        "        resnet_train = model_dict['resnet_train']\n",
        "        dropout_rate = model_dict['dropout_rate']\n",
        "        num_classes = model_dict['num_classes']\n",
        "        \n",
        "        base_model = ResNet50(weights = resnet_weights, input_shape = img_size_targ,\\\n",
        "                              pooling = 'avg', include_top = False)\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "            \n",
        "        # Retrieve output of pre-trained model\n",
        "        X = base_model.output\n",
        "        # Add Dropout\n",
        "        X = Dropout(rate = dropout_rate[0], name = 'DR0')(X)\n",
        "        # Add one Dense layer\n",
        "        X = Dense(200, activation = 'relu')(X)\n",
        "        # Add Batch Norm layer\n",
        "        X = BatchNormalization()(X)  \n",
        "        # Add output layer for label classification\n",
        "        label_output = Dense(num_classes, activation = 'softmax', name = 'class_op')(X)        \n",
        "        # # Add output layer for bounding box regression\n",
        "        # bbox_output = Dense(4, activation = 'sigmoid', name = 'reg_op')(X)        \n",
        "        \n",
        "        # Define overall model\n",
        "        # model = Model(inputs = base_model.input, outputs = [label_output, bbox_output])\n",
        "        model = Model(inputs = base_model.input, outputs = label_output)\n",
        "        \n",
        "    ##### End Model Architecture A    \n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVXicG2xKBoq",
        "scrolled": false
      },
      "source": [
        "# Verify model defined above\n",
        "model_dict = {'model_arch': 'A',\n",
        "              'resnet_weights': 'imagenet',\n",
        "              'resnet_train': False, \n",
        "              'dropout_rate': [0.0],\n",
        "              'num_classes': num_classes_train\n",
        "              }\n",
        "temp_model = model_core(model_dict)\n",
        "temp_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VknuAm5Vaxly"
      },
      "source": [
        "## Function - Define model compile, train and eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWmxPAjcaxly"
      },
      "source": [
        "def model_comp_fit_eval(model_dict, train_dict):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function to compile, fit and evaluate model. Use this function to start fitting a\n",
        "    model from initial randomized weights. For continuing an already fitted model, use\n",
        "    function model_fit_cont\n",
        "    \n",
        "    Arguments:\n",
        "    model_dict - Dictionary with list of keys / values needed to build the model\n",
        "               - See function model_core for more details\n",
        "    train_dict - Dictionary with list of keys / values needed to compile and train the model\n",
        "      'epochs': Number of epochs to train for\n",
        "      'steps_per_epoch': Number of steps per epoch\n",
        "      'val_steps': Number of steps before stopping validation\n",
        "      'early_stop': Boolean: If True, implement early stop\n",
        "      'redlr_plat': Boolean: If True, implement reduce learning rate plateau      \n",
        "      'ilr': Initial learning rate to use for learning rate decay scheduler\n",
        "      'dr': Decay rate to use for learning rate decay scheduler\n",
        "      'ds': Decay step to use for learning rate decay scheduler\n",
        "      'lrpl_fac': Factor to use for Reduce LR on Plateau callback\n",
        "      'lrpl_pat': Patience to use for Reduce LR on Plateau callback\n",
        "      'verb': Boolean: If True, print running summary during model fit.\n",
        "      'tb_path': Path to store Tensorboard callback information\n",
        "      'bm_path': File name to use for storing best model checkpoint\n",
        "      'fm_path': File name to use for storing final trained model\n",
        "      'hi_path': File name to use for storing training history\n",
        "\n",
        "    Returns:\n",
        "    model - Model instance with trained weights\n",
        "    hist - Training history object \n",
        "\n",
        "    \"\"\"      \n",
        "    # Retrieve train_dict parameters\n",
        "    epochs = train_dict['epochs'] # Number of epochs to train for\n",
        "    steps_per_epoch = train_dict['steps_per_epoch'] # Number of steps per epoch\n",
        "    val_steps = train_dict['val_steps'] # Number of steps before stopping validation\n",
        "    early_stop = train_dict['early_stop'] # Boolean: If True, implement early stop\n",
        "    ilr = train_dict['ilr'] # Initial learning rate to use for learning rate decay scheduler\n",
        "    redlr_plat = train_dict['redlr_plat'] # Boolean: If True, implement reduce learning rate plateau    \n",
        "    dr = train_dict['dr'] # Decay rate to use for learning rate decay scheduler\n",
        "    ds = train_dict['ds'] # Decay step to use for learning rate decay scheduler\n",
        "    lrpl_fac = train_dict['lrpl_fac'] # Factor to use for Reduce LR on Plateau callback\n",
        "    lrpl_pat = train_dict['lrpl_pat'] # Patience to use for Reduce LR on Plateau callback    \n",
        "    verb = train_dict['verb'] # Boolean: If True, print running summary during model fit.\n",
        "    tb_path = train_dict['tb_path'] # Path to store Tensorboard callback information\n",
        "    bm_path = train_dict['bm_path'] # File name to use for storing best model checkpoint\n",
        "    fm_path = train_dict['fm_path'] # File name to use for storing final trained model\n",
        "    hi_path = train_dict['hi_path'] # File name to use for storing training history\n",
        "\n",
        "    # Instantiate model\n",
        "    model = model_core(model_dict)\n",
        "    \n",
        "    # Define learning rate decay schedule\n",
        "    lr_sch = InverseTimeDecay(ilr, ds, dr)\n",
        "    # Define Optimizer\n",
        "    if (redlr_plat):\n",
        "      opt = optimizers.Adam(learning_rate = ilr) \n",
        "    else:\n",
        "      opt = optimizers.Adam(learning_rate = lr_sch)\n",
        "    # Define Loss:\n",
        "    # - CategoricalCrossEntropy for 'class_op' \n",
        "    # - MeanSquaredError for 'reg_op'\n",
        "    # loss_dict = {'reg_op': losses.MeanSquaredError(),\n",
        "    #              'class_op': losses.CategoricalCrossentropy()\n",
        "    #             }\n",
        "    # loss_weights_dict = {'reg_op': 1,\n",
        "    #                     'class_op': 1\n",
        "    #                    }\n",
        "    loss = losses.CategoricalCrossentropy()\n",
        "\n",
        "    # Define Metric = Categorical Accuracy\n",
        "    met = [metrics.CategoricalAccuracy()]\n",
        "\n",
        "    # Compile model\n",
        "    # model.compile(optimizer = opt, loss = loss_dict, loss_weights = loss_weights_dict,\\\n",
        "    #               metrics = met)\n",
        "    model.compile(optimizer = opt, loss = loss, metrics = met)   \n",
        "    \n",
        "    # Define path for tensorboard logs\n",
        "    logdir = os.path.join(tb_path, datetime.datetime.now().strftime(\"%d_%H_%M_%S\"))\n",
        "    # Define Tensorboard callback\n",
        "    tensorboard_callback = TensorBoard(logdir, histogram_freq = 0)\n",
        "    \n",
        "    # Define Model Checkpoint callback\n",
        "    mcp_callback = ModelCheckpoint(filepath = bm_path, monitor = \"val_loss\", save_best_only = True,\\\n",
        "                                   save_weights_only = False, mode = \"min\", save_freq = \"epoch\")\n",
        "\n",
        "    # Define Early Stopping callback\n",
        "    earlystopping_callback = EarlyStopping(monitor = \"loss\", min_delta = 1e-4, patience = 10,\\\n",
        "                                           mode = \"min\", verbose = 1)\n",
        "    \n",
        "    # Define 'Reduce learning rate on plateau' callback\n",
        "    redlr_plat_callback = ReduceLROnPlateau(monitor = \"val_loss\", factor = lrpl_fac, patience = lrpl_pat,\\\n",
        "                                            verbose = 1, mode = \"min\", min_delta = 0.0001)\n",
        "\n",
        "    # Define list of all callbacks\n",
        "    callback_list = []\n",
        "    if (redlr_plat):\n",
        "      callback_list.append(redlr_plat_callback)\n",
        "    if (early_stop):\n",
        "      callback_list.append(earlystopping_callback)\n",
        "    if (tb_path != 'None'):\n",
        "      callback_list.append(tensorboard_callback)\n",
        "    if (bm_path != 'None'):\n",
        "      callback_list.append(mcp_callback)\n",
        "\n",
        "    # Fit model\n",
        "    # hist = model.fit(x = train_generator, epochs = epochs, steps_per_epoch = steps_per_epoch,\\\n",
        "    #                  validation_data = test_generator, validation_steps = val_steps,\\\n",
        "    #                  verbose = verb, callbacks = callback_list)\n",
        "    hist = model.fit(x = train_generator, epochs = epochs, steps_per_epoch = steps_per_epoch,\\\n",
        "                     verbose = verb, callbacks = callback_list)    \n",
        "        \n",
        "    # Save final trained model to file\n",
        "    if (fm_path != 'None'):\n",
        "      # Save final trained model in Keras HDF5 format\n",
        "      model.save(fm_path, overwrite = True, save_format = 'h5') \n",
        "    if (hi_path != 'None'):\n",
        "      # Save training history to file\n",
        "      np.save(hi_path, hist.history)\n",
        "    \n",
        "    return model, hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KHshIKFaxlz"
      },
      "source": [
        "## Launch Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQd-pmz4axlz"
      },
      "source": [
        "%tensorboard --logdir {tb_logs_base_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faS7uhW-axlz"
      },
      "source": [
        "## Define train and test generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcnqac-Jaxl0"
      },
      "source": [
        "# Create train and test generator\n",
        "batch_size = 64\n",
        "train_generator = batch_generator(train_df, batch_size = batch_size,\\\n",
        "                                  img_size_targ = img_size_targ[:2],\\\n",
        "                                  num_classes_train = num_classes_train)\n",
        "# test_generator = batch_generator(test_df, batch_size = batch_size,\\\n",
        "#                                   img_size_targ = img_size_targ[:2],\\\n",
        "#                                   num_classes_train = num_classes_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB5gDobRaxl0"
      },
      "source": [
        "## Set all model, compile and training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8AfL95saxl1"
      },
      "source": [
        "### Define file paths\n",
        "# Prefix to use for naming files and paths\n",
        "mod_file_pref = \"MA\" \n",
        "# Tensorboard base path\n",
        "tb_path = os.path.join(tb_logs_base_dir, mod_file_pref) \n",
        "# Path for storing final trained model\n",
        "fm_path = os.path.join(out_base_path, mod_file_pref + \"_finalmodel.h5\") \n",
        "# Path for storing best model (model with lowest validation set loss)\n",
        "bm_path = os.path.join(out_base_path, mod_file_pref + \"_bestmodel.h5\")\n",
        "# Path for storing training history\n",
        "hi_path = os.path.join(out_base_path, mod_file_pref + \"_hist.npy\")\n",
        "\n",
        "# Define model_dict and train_dict\n",
        "model_dict = {'model_arch': 'A',\n",
        "              'resnet_weights': 'imagenet',\n",
        "              'resnet_train': False, \n",
        "              'dropout_rate': [0.0],\n",
        "              'num_classes': num_classes_train\n",
        "              }\n",
        "train_dict = {'epochs': 10, # Number of epochs to train for\n",
        "              'initial_epoch': 0, # Initial epoch to start from\n",
        "              'fit_resume': False, # Boolean: If True, resume fit from initial epoch\n",
        "              'steps_per_epoch': (train_df.shape[0] // batch_size), # No. of steps per epoch\n",
        "              'val_steps': (test_df.shape[0] // batch_size), # No. of steps before stopping val\n",
        "              'early_stop': False, # Boolean: If True, implement early stop\n",
        "              'redlr_plat': False, # Boolean: If True, implement reduce learning rate plateau\n",
        "              'ilr': 0.001, # Initial learning rate to use for learning rate decay scheduler\n",
        "              'dr': 0, # Decay rate to use for learning rate decay scheduler\n",
        "              'ds': ((train_df.shape[0] // batch_size) * 10), # Decay step to use for lr decay\n",
        "              'lrpl_fac': 0.5, # Factor to use for Reduce LR on Plateau callback\n",
        "              'lrpl_pat': 10, # Patience to use for Reduce LR on Plateau callback              \n",
        "              'verb': 1, # Boolean: If True, print running summary during model fit.\n",
        "              'tb_path': tb_path, # Path to store Tensorboard callback information\n",
        "              'bm_path': bm_path, # File name to use for storing best model checkpoint\n",
        "              'fm_path': fm_path, # File name to use for storing final trained model\n",
        "              'hi_path': hi_path, # File name to use for storing training history\n",
        "              }\n",
        "print(tb_path)\n",
        "print(bm_path)\n",
        "print(fm_path)\n",
        "print(hi_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "IpPyjfSwaxl1"
      },
      "source": [
        "# Verify model instantiation, loss and compile options\n",
        "train_dict_temp = {'epochs': 0, # Number of epochs to train for\n",
        "              'initial_epoch': 0, # Initial epoch to start from\n",
        "              'fit_resume': False, # Boolean: If True, resume fit from initial epoch\n",
        "              'steps_per_epoch': (train_df.shape[0] // batch_size), # No. of steps per epoch\n",
        "              'val_steps': (test_df.shape[0] // batch_size), # No. of steps before stopping val\n",
        "              'early_stop': False, # Boolean: If True, implement early stop\n",
        "              'redlr_plat': False, # Boolean: If True, implement reduce learning rate plateau\n",
        "              'ilr': 0.001, # Initial learning rate to use for learning rate decay scheduler\n",
        "              'dr': 0, # Decay rate to use for learning rate decay scheduler\n",
        "              'ds': ((train_df.shape[0] // batch_size) * 10), # Decay step to use for lr decay\n",
        "              'lrpl_fac': 0.5, # Factor to use for Reduce LR on Plateau callback\n",
        "              'lrpl_pat': 10, # Patience to use for Reduce LR on Plateau callback              \n",
        "              'verb': 1, # Boolean: If True, print running summary during model fit.\n",
        "              'tb_path': 'None', # Path to store Tensorboard callback information\n",
        "              'bm_path': 'None', # File name to use for storing best model checkpoint\n",
        "              'fm_path': 'None', # File name to use for storing final trained model\n",
        "              'hi_path': 'None', # File name to use for storing training history\n",
        "              }\n",
        "\n",
        "if (train_dict_temp['fit_resume']):\n",
        "  temp_model, _ = model_fit_cont(temp_model, train_dict_temp)\n",
        "else:\n",
        "  temp_model, _ = model_comp_fit_eval(model_dict, train_dict_temp)  \n",
        "\n",
        "display(temp_model.loss)\n",
        "print()\n",
        "display(temp_model.optimizer.get_config())\n",
        "print()\n",
        "display(temp_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "018jYgr1XaPg"
      },
      "source": [
        "# Start model fit\n",
        "if (train_dict['fit_resume']):\n",
        "  start_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
        "  print(\"Started at %s\" %(start_time.strftime(\"%H:%M:%S\")), end = '; ')\n",
        "  model, hist = model_comp_fit_eval(model_dict, train_dict)\n",
        "  end_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
        "  elap_time = ((end_time - start_time).total_seconds())/60\n",
        "  print(\"\\nCompleted at %s. Elapsed time = %0.2f minutes.\" %(end_time.strftime(\"%H:%M:%S\"), elap_time)) \n",
        "else:\n",
        "  start_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
        "  print(\"Started at %s\" %(start_time.strftime(\"%H:%M:%S\")), end = '; ')\n",
        "  model, hist = model_comp_fit_eval(model_dict, train_dict)\n",
        "  end_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
        "  elap_time = ((end_time - start_time).total_seconds())/60\n",
        "  print(\"\\nCompleted at %s. Elapsed time = %0.2f minutes.\" %(end_time.strftime(\"%H:%M:%S\"), elap_time)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ztEpE54axl1"
      },
      "source": [
        "# Backup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KpqhepoiAfe"
      },
      "source": [
        "Define function to calculate IoU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww0PFGg6ql3C"
      },
      "source": [
        "def calculate_iou(y_true, y_pred):\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    Input:\n",
        "    Keras provides the input as numpy arrays with shape (batch_size, num_columns).\n",
        "    \n",
        "    Arguments:\n",
        "    y_true -- first box, numpy array with format [x, y, width, height, conf_score]\n",
        "    y_pred -- second box, numpy array with format [x, y, width, height, conf_score]\n",
        "    x any y are the coordinates of the top left corner of each box.\n",
        "    \n",
        "    Output: IoU of type float32. (This is a ratio. Max is 1. Min is 0.)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for i in range(0,y_true.shape[0]):\n",
        "    \n",
        "        # set the types so we are sure what type we are using\n",
        "        y_true = np.array(y_true, dtype=np.float32)\n",
        "        y_pred = np.array(y_pred, dtype=np.float32)\n",
        "\n",
        "        #print(y_true.shape)\n",
        "        #print(y_pred.shape)\n",
        "        # boxTrue\n",
        "        x_boxTrue_tleft = y_true[i,0]  # numpy index selection\n",
        "        y_boxTrue_tleft = y_true[i,1]\n",
        "        boxTrue_width = y_true[i,2]\n",
        "        boxTrue_height = y_true[i,3]\n",
        "        area_boxTrue = (boxTrue_width * boxTrue_height)\n",
        "\n",
        "        # boxPred\n",
        "        x_boxPred_tleft = y_pred[i,0]\n",
        "        y_boxPred_tleft = y_pred[i,1]\n",
        "        boxPred_width = y_pred[i,2]\n",
        "        boxPred_height = y_pred[i,3]\n",
        "        area_boxPred = (boxPred_width * boxPred_height)\n",
        "\n",
        "        # calculate the bottom right coordinates for boxTrue and boxPred\n",
        "\n",
        "        # boxTrue\n",
        "        x_boxTrue_br = x_boxTrue_tleft + boxTrue_width\n",
        "        y_boxTrue_br = y_boxTrue_tleft + boxTrue_height # Version 2 revision\n",
        "\n",
        "        # boxPred\n",
        "        x_boxPred_br = x_boxPred_tleft + boxPred_width\n",
        "        y_boxPred_br = y_boxPred_tleft + boxPred_height # Version 2 revision\n",
        "\n",
        "\n",
        "        # calculate the top left and bottom right coordinates for the intersection box, boxInt\n",
        "\n",
        "        # boxInt - top left coords\n",
        "        x_boxInt_tleft = np.max([x_boxTrue_tleft,x_boxPred_tleft])\n",
        "        y_boxInt_tleft = np.max([y_boxTrue_tleft,y_boxPred_tleft]) # Version 2 revision\n",
        "\n",
        "        # boxInt - bottom right coords\n",
        "        x_boxInt_br = np.min([x_boxTrue_br,x_boxPred_br])\n",
        "        y_boxInt_br = np.min([y_boxTrue_br,y_boxPred_br]) \n",
        "\n",
        "        # Calculate the area of boxInt, i.e. the area of the intersection \n",
        "        # between boxTrue and boxPred.\n",
        "        # The np.max() function forces the intersection area to 0 if the boxes don't overlap.\n",
        "        \n",
        "        \n",
        "        # Version 2 revision\n",
        "        area_of_intersection = \\\n",
        "        np.max([0,(x_boxInt_br - x_boxInt_tleft)]) * np.max([0,(y_boxInt_br - y_boxInt_tleft)])\n",
        "\n",
        "        iou = area_of_intersection / ((area_boxTrue + area_boxPred) - area_of_intersection)\n",
        "\n",
        "\n",
        "        # This must match the type used in py_func\n",
        "        iou = np.array(iou, dtype=np.float32)\n",
        "        \n",
        "        # append the result to a list at the end of each loop\n",
        "        results.append(iou)\n",
        "    \n",
        "    # return the mean IoU score for the batch\n",
        "    return np.mean(results)\n",
        "\n",
        "\n",
        "\n",
        "def IoU(y_true, y_pred):\n",
        "    \n",
        "    # Note: the type float32 is very important. It must be the same type as the output from\n",
        "    # the python function above or you too may spend many late night hours \n",
        "    # trying to debug and almost give up.\n",
        "    \n",
        "    iou = tf.py_function(calculate_iou, [y_true, y_pred], tf.float32)\n",
        "\n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RQg_TeWL8CC"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmqypNf28WGS"
      },
      "source": [
        "final_model.compile(optimizer='adam', \n",
        "                    loss={'reg_op':'mse', 'class_op':'categorical_crossentropy'},\n",
        "                    loss_weights={'reg_op':20, 'class_op':1},\n",
        "                    metrics={'reg_op':[IoU], 'class_op':['accuracy']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT_TJaPWX2PK"
      },
      "source": [
        "## Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyrMXl9EdiSt"
      },
      "source": [
        "def predict_and_draw(image_num, df):\n",
        "\n",
        "    #Load image\n",
        "    img = tf.keras.preprocessing.image.load_img(df.loc[image_num, 'File'])\n",
        "    w, h = img.size\n",
        "\n",
        "    #Prepare input for model\n",
        "    #1. Resize image\n",
        "    img_resized = img.resize((img_size, img_size))\n",
        "    #2. Conver to array and make it a batch of 1\n",
        "    input_array = tf.keras.preprocessing.image.img_to_array(img_resized)\n",
        "    input_array = np.expand_dims(input_array, axis=0)\n",
        "\n",
        "    #3. Normalize image data\n",
        "    input_array = tf.keras.applications.resnet50.preprocess_input(input_array)\n",
        "\n",
        "    #Prediction\n",
        "    pred = final_model.predict(input_array)\n",
        "    #Get classification and regression predictions\n",
        "    label_pred, bbox_pred = pred[0][0], pred[1][0]\n",
        "    #Get Label with highest probability\n",
        "    pred_class = label_class_dict[np.argmax(label_pred)]\n",
        "\n",
        "    #Read actual label and bounding box\n",
        "    act_class = df.loc[image_num, 'Class']\n",
        "    xmin, ymin, xmax, ymax = df.loc[image_num, ['xmin', 'ymin', 'xmax', 'ymax']]\n",
        "\n",
        "    print('Real Label :', act_class, '\\nPredicted Label: ', pred_class)\n",
        "    \n",
        "    #Draw bounding boxes - Actual (Red) and Predicted(Green)\n",
        "    img = cv2.imread(df.loc[image_num, 'File'])\n",
        "    \n",
        "    #Draw actual bounding box\n",
        "    img = cv2.rectangle(img, (xmin, ymin), \n",
        "                        (xmax, ymax), (0,0,255), 3)\n",
        "    \n",
        "    #Draw predicted bounding box\n",
        "    img = cv2.rectangle(img, (int(bbox_pred[0]*w), int(bbox_pred[1]*h)), \n",
        "                        (int((bbox_pred[0]+bbox_pred[2])*w), int((bbox_pred[1]+bbox_pred[3])*h)), (0,255,0), 3)\n",
        "\n",
        "    #Display the picture\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH0bH4YiYZ4b"
      },
      "source": [
        "#Predict on Test Dataset\n",
        "image_num = np.random.randint(0, test_df.shape[0])\n",
        "predict_and_draw(image_num, test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoiHsbD5y3GP"
      },
      "source": [
        "img = tf.keras.preprocessing.image.load_img(test_df.loc[image_num, 'File'], target_size=(224,224))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq0tfsMpzBEU"
      },
      "source": [
        "img_array.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1eNVnlPzFRC"
      },
      "source": [
        "final_model.input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFZz1eZCzTeG"
      },
      "source": [
        "np.expand_dims(img_array, axis=0).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPwmXqgazOZ1"
      },
      "source": [
        "final_model.predict(np.expand_dims(img_array, axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}