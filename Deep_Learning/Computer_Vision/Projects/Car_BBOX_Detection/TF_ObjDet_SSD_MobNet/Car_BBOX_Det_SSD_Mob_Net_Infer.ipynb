{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TF_ObjDet_Inference_Only.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "256px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suresh-venkate/Code_Repositories/blob/main/Deep_Learning/Computer_Vision/Projects/Car_BBOX_Detection/TF_ObjDet_SSD_MobNet/Car_BBOX_Det_SSD_Mob_Net_Infer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjRJNNfAyie7"
      },
      "source": [
        "# Car Bounding Box Detection - SSD MobileNet Detector - Inference NB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOf1fntEavo2"
      },
      "source": [
        "# Copy model and complete other preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5POx_BtQaxiu"
      },
      "source": [
        "## Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaBz-JaNFuZ0"
      },
      "source": [
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbhaXg_IzFky"
      },
      "source": [
        "## Copy required files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11W2HCBwy0f2"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Copy dataset from Google Drive\n",
        "!cp /content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Datasets/Image_Datasets/Stanford_Car_Dataset/Consolidated_Dataset.zip .\n",
        "# Unzip dataset file\n",
        "!unzip Consolidated_Dataset.zip\n",
        "# Delete zip file\n",
        "!rm Consolidated_Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ1qCqogFn09"
      },
      "source": [
        "## Copy model and label class mapping from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drd9YX9eF0ge"
      },
      "source": [
        "# Copy model directory\n",
        "!cp -r /content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Car_BBOX_SSD_MobNet_Model/Trained_Models/M1/detection_model .\n",
        "# Copy label-class mapping pkl file\n",
        "!cp /content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Car_BBOX_SSD_MobNet_Model/Trained_Models/M1/car_dataset_label.pkl ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAKq6QAqyifN"
      },
      "source": [
        "## Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoIDG10ryifO"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import math\n",
        "import datetime\n",
        "import pytz\n",
        "import time\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxBaDP43yifP"
      },
      "source": [
        "## Extract label_class_dict from pkl file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t7Q8pd7yifQ",
        "scrolled": true
      },
      "source": [
        "# Pickle file where index to label mapping is stored\n",
        "fname = \"/content/car_dataset_label.pkl\" \n",
        "with open(fname, \"rb\") as file:\n",
        "    label_class_dict = pickle.load(file)\n",
        "    \n",
        "print(f\"Type of label_class_dict is {type(label_class_dict)}\")\n",
        "print()\n",
        "print(f\"Keys of label_class_dict are:\")\n",
        "print(\"--------------------------------\")\n",
        "print(label_class_dict.keys())\n",
        "print()\n",
        "print(\"First five elements of label_class_dict are:\")\n",
        "print(\"-----------------------------------------------\")\n",
        "for ind in range(1, 6, 1):\n",
        "    print(label_class_dict[ind])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENIOKjXPyifR"
      },
      "source": [
        "## Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huV6xRRvyifT"
      },
      "source": [
        "%%capture\n",
        "# Define path where model is stored\n",
        "model_path = '/content/detection_model/saved_model'\n",
        "# Load model from path\n",
        "model = tf.saved_model.load(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqJVtY0zd-DM"
      },
      "source": [
        "## Create train_df and test_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nV5DVnVd_BW"
      },
      "source": [
        "# Load train annotation file in a DataFrame\n",
        "ann_train_csv_path = '/content/annot_train_cons.csv'\n",
        "train_df = pd.read_csv(ann_train_csv_path)\n",
        "display(train_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCafAp10eEjd"
      },
      "source": [
        "# Load test annotation file in a DataFrame\n",
        "ann_test_csv_path = '/content/annot_test_cons.csv'\n",
        "test_df = pd.read_csv(ann_test_csv_path)\n",
        "display(test_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfoRttl9eLWB"
      },
      "source": [
        "# Get dataset size\n",
        "print(\"Number of images in training set is %d\" %train_df.shape[0])\n",
        "print(\"Number of images in test set is %d\" %test_df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf9kfZ6syifU"
      },
      "source": [
        "# Make predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH4jmljldlA7"
      },
      "source": [
        "## Function: predict_and_plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwLsTX50dqDt"
      },
      "source": [
        "def predict_and_plot(df, samp_indices, img_root_path, model, num_cols, col_size, row_size, fig_title,\\\n",
        "                     box_thickness):\n",
        "\n",
        "  '''\n",
        "  Function to make predictions on a subset of data and plot images with actual\n",
        "  and predicted labels\n",
        "\n",
        "  Arguments:\n",
        "    X: Input image array\n",
        "    y: Input label array\n",
        "    samp_indices: Indices from X to be plotted\n",
        "    model: Model instance to use for making predictions\n",
        "    num_cols: Number of columns to use for plotting\n",
        "    col_size: Size of columns to use for plotting\n",
        "    row_size: Size of rows to use for plotting\n",
        "    fig_title: Title to use for overall figure\n",
        "  ''' \n",
        "\n",
        "  num_rows = math.ceil(len(samp_indices) / num_cols) # Number of rows to use for plotting\n",
        "  fig = plt.figure(figsize = ((num_cols * col_size), (num_rows * row_size)))\n",
        "  fig.suptitle(fig_title, fontsize = 40)\n",
        "\n",
        "  for ind, samp_ind in enumerate(samp_indices): # Loop through samp_indices\n",
        "    img_file_name = df.loc[samp_ind, 'filename'] # Extract image filename from DataFrame\n",
        "    img_file_path = os.path.join(img_root_path, img_file_name) # Obtain image file path\n",
        "    img = cv2.cvtColor(cv2.imread(img_file_path), cv2.COLOR_BGR2RGB) # Load image\n",
        "    img_mod = np.expand_dims(img, axis = 0) # Add batch axis to feed to model\n",
        "    model_out = model(img_mod) # Pass input image through model\n",
        "\n",
        "    xmin, ymin, xmax, ymax = df.loc[samp_ind, ['xmin', 'ymin', 'xmax', 'ymax']] # Get ground-truth \n",
        "                                                                                # BBOX co-ords\n",
        "    img_h, img_w = df.loc[samp_ind, ['img_h', 'img_w']] # Extract image dimensions\n",
        "    act_class = df.loc[samp_ind, 'class'] # Get ground-truth class\n",
        "\n",
        "    score = 100 * model_out['detection_scores'][0].numpy()[0] # Extract best box score\n",
        "    bbox = model_out['detection_boxes'][0].numpy()[0] # Extract BBOX co-ordinates\n",
        "    label = model_out['detection_classes'][0].numpy().astype('int32')[0] # Extract class index\n",
        "    pred_class = label_class_dict[label] # Obtain class of car\n",
        "\n",
        "    # Scale BBOX co-ordinates to image dimensions\n",
        "    (bbox_ymin, bbox_xmin, bbox_ymax, bbox_xmax) = (int(bbox[0] * img_h), int(bbox[1] * img_w),\\\n",
        "                                                    int(bbox[2] * img_h), int(bbox[3] * img_w))  \n",
        "    \n",
        "    # Draw ground-truth BBOX in green\n",
        "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), box_thickness)\n",
        "    # Draw predicted BBOX in blue    \n",
        "    cv2.rectangle(img, (bbox_xmin, bbox_ymin), (bbox_xmax, bbox_ymax), (0, 0, 255), box_thickness)\n",
        "\n",
        "    ax = plt.subplot(num_rows, num_cols, (ind + 1))\n",
        "    ax.text(0, -40, f\"Actual class: {act_class}\", fontsize = 'xx-large')\n",
        "    ax.text(0, -10, f\"Predicted class: {pred_class} ({score:0.2f}%)\", fontsize = 'xx-large')\n",
        "    ax.imshow(img) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTunt5QP53vm"
      },
      "source": [
        "## Training Set Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlMoARxqyifV"
      },
      "source": [
        "train_img_root_path = \"/content/train_images\"\n",
        "fig_title = 'Random Images from Training Set'\n",
        "num_samp_to_plot = 8\n",
        "samp_indices = list(np.random.randint(low = 0, high = train_df.shape[0], size = num_samp_to_plot))\n",
        "\n",
        "predict_and_plot(train_df, samp_indices, train_img_root_path, model, 2, 8, 8, fig_title, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vev9nX-k57Kg"
      },
      "source": [
        "## Test Set Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96pAq1Cl5rTA"
      },
      "source": [
        "test_img_root_path = \"/content/test_images\"\n",
        "fig_title = 'Random Images from Testing Set'\n",
        "num_samp_to_plot = 8\n",
        "samp_indices = list(np.random.randint(low = 0, high = test_df.shape[0], size = num_samp_to_plot))\n",
        "predict_and_plot(test_df, samp_indices, test_img_root_path, model, 2, 8, 8, fig_title, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-2bFUrt5Yv0"
      },
      "source": [
        "# Evaluate Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xzuDPzSDCpt"
      },
      "source": [
        "## Function: iou computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW4XT7K3C-99"
      },
      "source": [
        "def iou(box1, box2):\n",
        "    \n",
        "    \"\"\"Implement the intersection over union (IoU) between box1 and box2\n",
        "    \n",
        "    Arguments:\n",
        "    box1 -- first box, list object with coordinates (box1_x1, box1_y1, box1_x2, box_1_y2)\n",
        "    box2 -- second box, list object with coordinates (box2_x1, box2_y1, box2_x2, box2_y2)\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract x, y co-ordinates of both boxes\n",
        "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
        "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
        "    \n",
        "    # Calculate the (xi1, yi1, xi2, yi2) coordinates of the intersection of box1 and box2. \n",
        "    # Calculate its Area.\n",
        "    xi1 = max(box1_x1, box2_x1)\n",
        "    yi1 = max(box1_y1, box2_y1)\n",
        "    xi2 = min(box1_x2, box2_x2)\n",
        "    yi2 = min(box1_y2, box2_y2)\n",
        "    inter_width = max((xi2 - xi1),0)\n",
        "    inter_height = max((yi2 - yi1),0)\n",
        "    inter_area = inter_width * inter_height\n",
        "\n",
        "    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
        "    box1_area = (box1_y2 - box1_y1) * (box1_x2 - box1_x1)\n",
        "    box2_area = (box2_y2 - box2_y1) * (box2_x2 - box2_x1)\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    \n",
        "    # compute the IoU\n",
        "    iou = inter_area / union_area\n",
        "    \n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFqz1I3-Pnhs"
      },
      "source": [
        "##Function: model_eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt428yHSPryo"
      },
      "source": [
        "def model_eval(df, img_root_path, num_samp):\n",
        "\n",
        "  '''\n",
        "  Function to evaluate the performance of the model given a certain set of images. \n",
        "  Classificaton accuracy and Mean IoU over all images will be computed and reported\n",
        "\n",
        "  Arguments:\n",
        "    df: Input Dataframe with image information\n",
        "    img_root_path: Root path of images\n",
        "    num_samp: Number of samples to use for evaluating model\n",
        "  '''\n",
        "  \n",
        "  # Create a dataframe placeholder to store evaluation results\n",
        "  df_cols = ['Act_Class', 'Pred_Class', 'Act_xmin', 'Act_ymin', 'Act_xmax', 'Act_ymax',\\\n",
        "           'Pred_xmin', 'Pred_ymin', 'Pred_xmax', 'Pred_ymax']\n",
        "  results_df = pd.DataFrame(columns = df_cols) # Placeholder to store results\n",
        "  corr_pred = 0 # counter to keep track of correct predictions\n",
        "  iou_list = [] # List to store IoU values (of Actual BBOX vs. Predicted BBOX) for each image\n",
        "\n",
        "  for samp_ind in tqdm(range(num_samp)): # Loop through num_samp\n",
        "    img_file_name = df.loc[samp_ind, 'filename'] # Extract image filename from DataFrame\n",
        "    img_file_path = os.path.join(img_root_path, img_file_name) # Obtain image file path\n",
        "    img = cv2.cvtColor(cv2.imread(img_file_path), cv2.COLOR_BGR2RGB) # Load image\n",
        "    img_mod = np.expand_dims(img, axis = 0) # Add batch axis to feed to model\n",
        "    model_out = model(img_mod) # Pass input image through model \n",
        "\n",
        "    act_class = df.loc[samp_ind, 'class'] # Get ground-truth class\n",
        "    label = model_out['detection_classes'][0].numpy().astype('int32')[0] # Extract class index\n",
        "    pred_class = label_class_dict[label] # Obtain class prediction\n",
        "    bbox = model_out['detection_boxes'][0].numpy()[0] # Extract BBOX co-ordinates\n",
        "    img_h, img_w = df.loc[samp_ind, ['img_h', 'img_w']] # Extract image dimensions\n",
        "\n",
        "    # Create entry_dict for updating dataframe\n",
        "    entry_dict = {'Act_Class': act_class,\n",
        "                  'Pred_Class': pred_class,\n",
        "                  'Act_xmin': df.loc[samp_ind, 'xmin'],\n",
        "                  'Act_ymin': df.loc[samp_ind, 'ymin'],\n",
        "                  'Act_xmax': df.loc[samp_ind, 'xmax'],\n",
        "                  'Act_ymax': df.loc[samp_ind, 'ymax'],\n",
        "                  'Pred_xmin': int(bbox[1] * img_w),\n",
        "                  'Pred_ymin': int(bbox[0] * img_h),\n",
        "                  'Pred_xmax': int(bbox[3] * img_w),\n",
        "                  'Pred_ymax': int(bbox[2] * img_h),\n",
        "                }\n",
        "    results_df = results_df.append(entry_dict, ignore_index = True) # Update dataframe\n",
        "\n",
        "    # Update corr_pred\n",
        "    corr_pred += int(entry_dict['Act_Class'] == entry_dict['Pred_Class'])\n",
        "\n",
        "    # Compute IoU\n",
        "    box1 = (entry_dict['Act_xmin'], entry_dict['Act_ymin'],\\\n",
        "            entry_dict['Act_xmax'], entry_dict['Act_ymax'])\n",
        "    box2 = (entry_dict['Pred_xmin'], entry_dict['Pred_ymin'],\\\n",
        "            entry_dict['Pred_xmax'], entry_dict['Pred_ymax'])\n",
        "    iou_list.append(iou(box1, box2))\n",
        "\n",
        "  tot_pred = results_df.shape[0]\n",
        "  print()\n",
        "  print()\n",
        "  print(\"Classification accuracy is %0.2f %%\" %(100 * (corr_pred / tot_pred)))\n",
        "  print(\"Mean IoU score is %0.4f\" %(np.mean(iou_list)))\n",
        "\n",
        "  return results_df, iou_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOl4nQTdR0Ad"
      },
      "source": [
        "## Evaluate model on training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7GXDDaBR3-a"
      },
      "source": [
        "train_img_root_path = \"/content/train_images\"\n",
        "train_results_df, train_iou_list = model_eval(train_df, train_img_root_path, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-ian7U9SSSl"
      },
      "source": [
        "## Evaluate model on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsp2m97vSSSm"
      },
      "source": [
        "test_img_root_path = \"/content/test_images\"\n",
        "test_results_df, test_iou_list = model_eval(test_df, test_img_root_path, 100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}