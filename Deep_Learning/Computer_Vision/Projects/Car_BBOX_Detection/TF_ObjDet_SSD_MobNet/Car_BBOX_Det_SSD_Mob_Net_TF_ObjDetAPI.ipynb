{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Object_Detection_E2E_TF2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suresh-venkate/Code_Repositories/blob/main/Deep_Learning/Computer_Vision/Projects/Car_BBOX_Detection/TF_ObjDet_SSD_MobNet/Car_BBOX_Det_SSD_Mob_Net_TF_ObjDetAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLrs0QG4OII_"
      },
      "source": [
        "# Car BBOX Detection - TensorFlow Object Detection API\n",
        "\n",
        "* Dataset - [Stanford Cars Dataset](https://www.kaggle.com/jutrera/stanford-car-dataset-by-classes-folder)\n",
        "* This notebook used the TensorFlow object detection API to perform classification and BBOX detection on the Stanford Car Dataset.\n",
        "* SSD Mobilnet model from TF2 model zoo is used as the reference model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzO2VUf8gK-s"
      },
      "source": [
        "# Complete setups and other preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhKCRgou8hXB"
      },
      "source": [
        "# gpu_info = !nvidia-smi\n",
        "# gpu_info = '\\n'.join(gpu_info)\n",
        "# if gpu_info.find('failed') >= 0:\n",
        "#   print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "#   print('and then re-execute this cell.')\n",
        "# else:\n",
        "#   print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh7ntJYemmta"
      },
      "source": [
        "## Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqSUo4G1moig"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2zIuU2I70fY"
      },
      "source": [
        "## Complete all installations and copy required files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj_ujSb4C_mB"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Clone TF models repository from GitHUb\n",
        "!git clone https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbe2su-APa7r"
      },
      "source": [
        "%%bash\n",
        "\n",
        "# Setup Object Detection API\n",
        "cd models/research\n",
        "# Compile protos.\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install --quiet ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-70ErwVhpCG4"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Create Dataset folder\n",
        "%cd /content/ \n",
        "!mkdir Dataset \n",
        "%cd Dataset \n",
        "\n",
        "# Copy utils.py and generate_tfrecord from GitHub\n",
        "!wget https://raw.githubusercontent.com/suresh-venkate/Code_Repositories/main/Deep_Learning/Computer_Vision/Projects/Car_BBOX_Detection/utils.py\n",
        "!wget https://raw.githubusercontent.com/suresh-venkate/Code_Repositories/main/Deep_Learning/Computer_Vision/Projects/Car_BBOX_Detection/generate_tfrecord.py\n",
        "\n",
        "# Copy dataset from Google Drive\n",
        "!cp /content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Datasets/Image_Datasets/Stanford_Car_Dataset/Consolidated_Dataset.zip .\n",
        "# Unzip dataset file\n",
        "!unzip Consolidated_Dataset.zip\n",
        "# Delete zip file\n",
        "!rm Consolidated_Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hfoMD39TJ0v"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA9ejat4TNKV"
      },
      "source": [
        "!ls -ltr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6UoR-CtZKuW"
      },
      "source": [
        "## Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4YXi_wPZMnn"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import pickle\n",
        "import datetime\n",
        "import pytz\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from utils import draw_boxes_and_labels\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTTo8kvtJvDg"
      },
      "source": [
        "## Define train and test image paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFBOWStNJ1sK"
      },
      "source": [
        "train_img_path = '/content/Dataset/train_images/'\n",
        "test_img_path = '/content/Dataset/test_images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCyipZzYZr_"
      },
      "source": [
        "## Create Label Mapping File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wna0FoqMZw2h"
      },
      "source": [
        "# Create a dictionary mapping from Label to Class. \n",
        "classes_path = '/content/Dataset/class_names.csv'\n",
        "classes = pd.read_csv(classes_path, header = None, names = ['class'])\n",
        "\n",
        "label_class_dict = {}\n",
        "for row in classes.iterrows():\n",
        "    label_class_dict[row[0] + 1] = row[1]['class']\n",
        "\n",
        "# Build a pbtxt label file using label and class name\n",
        "pbtxt_file_str = '' # Initialize pbtxt file string\n",
        "for label in sorted(label_class_dict.keys()):\n",
        "  pbtxt_file_str += \"item {\\n  id: \" + str(label) + \"\\n  name: '\" +  label_class_dict[label] + \"'\\n}\\n\\n\"\n",
        "with open('label_map.txt','w') as pbfile:\n",
        "    pbfile.write(pbtxt_file_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvgKci_BTVkQ"
      },
      "source": [
        "!ls -ltr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4S0wGC2TZIN"
      },
      "source": [
        "label_class_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh3vJcuzaiF0"
      },
      "source": [
        "## Create train_df and test_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv2EB98KakIW"
      },
      "source": [
        "# Load train annotation file in a DataFrame\n",
        "ann_train_csv_path = '/content/Dataset/annot_train_cons.csv'\n",
        "train_df = pd.read_csv(ann_train_csv_path)\n",
        "display(train_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iwaQnHLIAFE"
      },
      "source": [
        "# Load test annotation file in a DataFrame\n",
        "ann_test_csv_path = '/content/Dataset/annot_test_cons.csv'\n",
        "test_df = pd.read_csv(ann_test_csv_path)\n",
        "display(test_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7V_tPOfiMdc"
      },
      "source": [
        "# EDA on Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzesnIBiWhb"
      },
      "source": [
        "## Dataset size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbNXfK1FiZuN"
      },
      "source": [
        "print(\"Number of images in training set is %d\" %train_df.shape[0])\n",
        "print(\"Number of images in test set is %d\" %test_df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSh8v-MdiOtj"
      },
      "source": [
        "## Image Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiaUnJU-iTAS"
      },
      "source": [
        "# Training set\n",
        "print(\"Smallest height of images in training set is %d\" %(train_df['img_h'].min()))\n",
        "print(\"Largest height of images in training set is %d\" %(train_df['img_h'].max()))\n",
        "print()\n",
        "print(\"Smallest width of images in training set is %d\" %(train_df['img_w'].min()))\n",
        "print(\"Largest width of images in training set is %d\" %(train_df['img_w'].max()))\n",
        "print()\n",
        "print(\"Lowest aspect ratio of images in training set is %0.2f\"\\\n",
        "      %((train_df['img_w']/train_df['img_h']).min()))\n",
        "print(\"Highest aspect ratio of images in training set is %0.2f\"\\\n",
        "      %((train_df['img_w']/train_df['img_h']).max()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS4Au4SSil1L"
      },
      "source": [
        "# Test set\n",
        "print(\"Smallest height of images in test set is %d\" %(test_df['img_h'].min()))\n",
        "print(\"Largest height of images in test set is %d\" %(test_df['img_h'].max()))\n",
        "print()\n",
        "print(\"Smallest width of images in test set is %d\" %(test_df['img_w'].min()))\n",
        "print(\"Largest width of images in test set is %d\" %(test_df['img_w'].max()))\n",
        "print()\n",
        "print(\"Lowest aspect ratio of images in test set is %0.2f\"\\\n",
        "      %((test_df['img_w']/test_df['img_h']).min()))\n",
        "print(\"Highest aspect ratio of images in test set is %0.2f\"\\\n",
        "      %((test_df['img_w']/test_df['img_h']).max()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHimbiS1ioKi"
      },
      "source": [
        "## Class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmNfiBXsiqDS"
      },
      "source": [
        "# Class distribution of Training set\n",
        "plt.figure(figsize = (15, 8))\n",
        "plot_ = sns.countplot(x = train_df['class'])\n",
        "plt.title('Class Distrubution of Training_Set', fontsize = 20)\n",
        "plt.xlabel('Class Values', fontsize = 20)\n",
        "plt.ylabel('Class Count', fontsize = 20)\n",
        "plt.xticks(rotation = 90, fontsize = 12)\n",
        "for ind, label in enumerate(plot_.get_xticklabels()):\n",
        "  if (ind % 10) == 0:\n",
        "    label.set_visible(True)\n",
        "  else:\n",
        "    label.set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2UnTeUmiypZ"
      },
      "source": [
        "# Class distribution of Test set\n",
        "plt.figure(figsize = (15, 8))\n",
        "plot_ = sns.countplot(x = test_df['class'])\n",
        "plt.title('Class Distrubution of Test_Set', fontsize = 20)\n",
        "plt.xlabel('Class Values', fontsize = 20)\n",
        "plt.ylabel('Class Count', fontsize = 20)\n",
        "plt.xticks(rotation = 90, fontsize = 12)\n",
        "for ind, label in enumerate(plot_.get_xticklabels()):\n",
        "  if (ind % 10) == 0:\n",
        "    label.set_visible(True)\n",
        "  else:\n",
        "    label.set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq6BodSai4I7"
      },
      "source": [
        "## Visualize images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgi0W4KUi6Al"
      },
      "source": [
        "### Define Function: viz_images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwI8zZyAi8jy"
      },
      "source": [
        "def viz_images(name, df, img_path, num_images, num_cols, col_size, row_size):\n",
        "\n",
        "  '''\n",
        "  Function to plot images along with labels from different sets\n",
        "\n",
        "  Arguments:\n",
        "    name: Name to print in title (Training_Set, Test_Set etc.)\n",
        "    df: DataFrame from which information about image will be read\n",
        "    img_path: Root path of images\n",
        "    num_images: Number of images to plot\n",
        "    num_cols: Number of columns to use for plotting\n",
        "    col_size: Size of columns to use for plotting\n",
        "    row_size: Size of rows to use for plotting\n",
        "\n",
        "  '''\n",
        "\n",
        "  num_rows = math.ceil(num_images / num_cols) # Number of rows to use for plotting\n",
        "\n",
        "  fig = plt.figure(figsize = ((num_cols * col_size), (num_rows * row_size)))\n",
        "  fig.suptitle('Random sample images from ' + name, fontsize = 40)\n",
        "\n",
        "  # Generate random sample indices\n",
        "  samp_index = np.random.randint(low = 0, high = df.shape[0], size = num_images).tolist()\n",
        "\n",
        "  for ind, value in enumerate(samp_index): # Loop through samp_index\n",
        "    img_file = df.loc[value, 'filename']\n",
        "    img = cv2.imread(os.path.join(img_path, img_file)) # Read the image\n",
        "    xmin, ymin, xmax, ymax = df.loc[value, ['xmin', 'ymin', 'xmax', 'ymax']] # Get BBOX co-ords\n",
        "    obj_class = df.loc[value, 'class'] # Get Class of object\n",
        "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 4) # Draw BBox in green color\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert BGR to RGB\n",
        "    ax = plt.subplot(num_rows, num_cols, (ind + 1))\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(obj_class, fontsize = 20)\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hupfAwYjAg6"
      },
      "source": [
        "### Visualize images from training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQLTNzeDjDmI"
      },
      "source": [
        "viz_images('Training_Set', train_df, train_img_path, 8, 2, 8, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66PG2Bl1jJg-"
      },
      "source": [
        "viz_images('Test_Set', test_df, test_img_path, 8, 2, 8, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qml26TjsjVQj"
      },
      "source": [
        "# Complete setups required for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5_wHuLqVxb3"
      },
      "source": [
        "## Save training and test dataframes as csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5mKamauV0Je"
      },
      "source": [
        "train_df.to_csv('train.csv', index = False)\n",
        "test_df.to_csv('test.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VotlRSccTpzl"
      },
      "source": [
        "!ls -ltr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgYaNAGEQThJ"
      },
      "source": [
        "## Generate tfrecord from CSV\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AhiyJ3BRZVv"
      },
      "source": [
        "%%capture\n",
        "\n",
        "#Generate tfrecord for training data\n",
        "!python generate_tfrecord.py --csv_input=train.csv --img_path={train_img_path} --output_path=train.tfrecord\n",
        "#Generate tfrecord for test data\n",
        "!python generate_tfrecord.py --csv_input=test.csv --img_path={test_img_path} --output_path=test.tfrecord"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNCXl-etTs3c"
      },
      "source": [
        "!ls -ltr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjxG56jeeFXk"
      },
      "source": [
        "## Download a pre-trained model\n",
        "\n",
        "'SSD' with mobilnet base will be used for transfer learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNE5_ol7eJCE"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Download the model from zoo\n",
        "\n",
        "!wget -q http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
        "\n",
        "# Extract tar file\n",
        "!tar -xf ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
        "# Delete tar file\n",
        "!rm ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ4yvsb_TuNU"
      },
      "source": [
        "!ls -ltr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfu0k9k0e-CV"
      },
      "source": [
        "## Prepare Training configuration file\n",
        "\n",
        "A sample configuration for the chosen pre-trained model (ssd_mobilenet_v2_320x320_coco17_tpu-8) is copied from [Configs](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2) folder. The following updates have been made to 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config' file which is loaded from GitHub below:\n",
        "\n",
        "1. 'num_classes' parameter set to 196 (as we have 196 classes of cars in this dataset).\n",
        "2. For 'train_input_reader' 'input_path' set to 'train.tfrecord' (Location of train.tfrecord file).\n",
        "3. For 'train_input_reader' 'label_map_path' set to 'label_map.txt' (path of label_map.txt file).\n",
        "4. For 'eval_input_reader' 'input_path' set to 'test.tfrecord' (Location of test.tfrecord file).\n",
        "5. For 'eval_input_reader' 'label_map_path' set to 'label_map.txt' (path of label_map.txt file).\n",
        "5. 'fine_tune_checkpoint' set to \"ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint/ckpt-0\"  (filepath of pre-trained model checkpoint file).\n",
        "6. 'batch_size' set to 32. \n",
        "7. 'num_steps' set as per requirements of each run. \n",
        "8. 'use_matmul_crop_and_resize' set to False as it was causing memory issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd2oF4RATqCe"
      },
      "source": [
        "## Load training configuration file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKX_yViAwXIw"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!wget https://raw.githubusercontent.com/suresh-venkate/Code_Repositories/main/Deep_Learning/Computer_Vision/Projects/Car_BBOX_Detection/TF_ObjDet_SSD_MobNet/ssd_mobilenet.config\n",
        "config_file = 'ssd_mobilenet.config'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1INzk_NwL7d"
      },
      "source": [
        "!cat ssd_mobilenet.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbCourM9jMGd"
      },
      "source": [
        "## Copy model training script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1k412IGjP_d"
      },
      "source": [
        "# Copy training file from 'models/research/object_detection' folder to current folder\n",
        "!cp /content/models/research/object_detection/model_main_tf2.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loBFBiDHuxDc"
      },
      "source": [
        "## Create training folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZMSnhjJw1Nh"
      },
      "source": [
        "#!rm -rf training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYSZ3lU8jrlq"
      },
      "source": [
        "# Create a training folder to store model checkpoints/snapshots as training progresses\n",
        "root_path = \"/content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Car_BBOX_SSD_MobNet_Model\"\n",
        "train_path = os.path.join(root_path, \"Training_Files/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wXQ6RarRwNA"
      },
      "source": [
        "train_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWU775b3cYsL"
      },
      "source": [
        "## Launch Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEc2xP2fbCCQ"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#%reload_ext tensorboard\n",
        "#%tensorboard --logdir {train_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-aA5J6Ku6rm"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt3HDtFHzgbg"
      },
      "source": [
        "## Start training\n",
        "\n",
        "This section is commented out. The trained model is loaded from disk below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sNQzqpxjnB4"
      },
      "source": [
        "# Start training\n",
        "# model_dir=training/ (path where outputs from model will be stored)\n",
        "# pipeline_config_path={config_file} (config file that will be used for training and evaluation)\n",
        "# checkpoint_every_n=100 (Checkpoint every 100 steps)\n",
        "# !python model_main_tf2.py --model_dir={train_path} --pipeline_config_path={config_file} --checkpoint_every_n=1000 --alsologtostderr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1bNNQ2pzxW8"
      },
      "source": [
        "## Evaluate Model on Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiiARwj32t9y"
      },
      "source": [
        "# Start Evaluation\n",
        "# Setting checkpoint_dir=training will set the model to eval-only mode.\n",
        "# Results will be written to model_dir\n",
        "# !python model_main_tf2.py --model_dir=training/ --pipeline_config_path={config_file} --checkpoint_dir=training/ --alsologtostderr "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea3CVJqnGWg7"
      },
      "source": [
        "## Train and Evaluate in Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ust7kYHQ0mh6"
      },
      "source": [
        "If we want to evaluate our model on training data regularly, we have to run both training and evaluation script in parallel. Model evaluation on test data gets done everytime model checkpoint is saved during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOfR0g-30wEO"
      },
      "source": [
        "### Clear existing logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho9TjVhA0y_f"
      },
      "source": [
        "# !rm train.txt\n",
        "# !rm eval.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyhRqbCj0_wY"
      },
      "source": [
        "### Start train and eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dczrQx0OC4Ki"
      },
      "source": [
        "# Start training\n",
        "# !nohup /usr/bin/python3 model_main_tf2.py --model_dir={train_path} --pipeline_config_path={config_file} --checkpoint_every_n=1000 --alsologtostderr > train.txt 2>&1 &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJpRdLH3lGXP"
      },
      "source": [
        "# Start evaluation\n",
        "# !nohup /usr/bin/python3 model_main_tf2.py --model_dir={train_path} --pipeline_config_path={config_file} --checkpoint_dir={train_path} --alsologtostderr --sample_1_of_n_eval_examples=16 > eval.txt 2>&1 &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjPxAK0BzlWt"
      },
      "source": [
        "### Read output logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc444JgNDYzu"
      },
      "source": [
        "# !cat train.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvLi43NUDGX3"
      },
      "source": [
        "# !cat eval.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6j_TJP_0GEB"
      },
      "source": [
        "# !ps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_9jIOfmiCDW"
      },
      "source": [
        "# !kill -9 546\n",
        "# !kill -9 556"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxbue-P4kEvi"
      },
      "source": [
        "# Export trained model\n",
        "\n",
        "From the saved model checkpoints, we will create a frozen trained model. Frozen here means to remove model nodes which are no longer needed in prediction. This reduces model size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7MVmgSQkLov"
      },
      "source": [
        "# Copy export_inference_graph.py file from models/research/object_detection to current directory\n",
        "# !cp /content/models/research/object_detection/exporter_main_v2.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwKWqRcwkHz7"
      },
      "source": [
        "# Provide input name, config file location, training folder\n",
        "# input_type \"image_tensor\" => Input to model should be 4D tensor of shape [1, None, None, 3]\n",
        "# Model will be created in output_directory. Directory will be created if it doesn't exist\n",
        "# !python exporter_main_v2.py --input_type \"image_tensor\" --pipeline_config_path {config_file} --trained_checkpoint_dir {train_path} --output_directory detection_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G2ScbsvHrYT"
      },
      "source": [
        "# Copy the trained model to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vdUCyQq-IEc"
      },
      "source": [
        "## Save detection_model to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtyngLYIHvL_"
      },
      "source": [
        "# !cp -r detection_model '/content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Car_BBOX_SSD_MobNet_Model/Trained_Models/M3/'\n",
        "# !rm -rf detection_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PClWcHnB-K6X"
      },
      "source": [
        "## Save label class dictionary to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D5PhdlGJ9cG"
      },
      "source": [
        "# label_file_path = '/content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Car_BBOX_SSD_MobNet_Model/Trained_Models/M3/car_dataset_label.pkl'\n",
        "# with open(label_file_path,'wb') as file:\n",
        "#     pickle.dump(label_class_dict, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtZnLR1ckdbS"
      },
      "source": [
        "# Model Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ1qCqogFn09"
      },
      "source": [
        "## Copy trained model and label class mapping from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drd9YX9eF0ge"
      },
      "source": [
        "# Copy model directory\n",
        "!cp -r /content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Car_BBOX_SSD_MobNet_Model/Trained_Models/M3/detection_model .\n",
        "# Copy label-class mapping pkl file\n",
        "!cp /content/drive/MyDrive/AI_ML_Folder/Colab_Directory/Model_Outputs/Car_BBOX_SSD_MobNet_Model/Trained_Models/M3/car_dataset_label.pkl ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DrBkc9fUkES"
      },
      "source": [
        "!ls -ltr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl43aGFT8fRR"
      },
      "source": [
        "## Extract label_class_dict from pkl file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dogHBRxr8czr"
      },
      "source": [
        "# Pickle file where index to label mapping is stored\n",
        "fname = \"/content/Dataset/car_dataset_label.pkl\" \n",
        "with open(fname, \"rb\") as file:\n",
        "    label_class_dict = pickle.load(file)\n",
        "    \n",
        "print(f\"Type of label_class_dict is {type(label_class_dict)}\")\n",
        "print()\n",
        "print(f\"Keys of label_class_dict are:\")\n",
        "print(\"--------------------------------\")\n",
        "print(label_class_dict.keys())\n",
        "print()\n",
        "print(\"First five elements of label_class_dict are:\")\n",
        "print(\"-----------------------------------------------\")\n",
        "for ind in range(1, 6, 1):\n",
        "    print(label_class_dict[ind])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W9CfkGn9viy"
      },
      "source": [
        "## Load Saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huV6xRRvyifT"
      },
      "source": [
        "%%capture\n",
        "# Define path where model is stored\n",
        "model_path = '/content/Dataset/detection_model/saved_model'\n",
        "# Load model from path\n",
        "model = tf.saved_model.load(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsbGqfnzU_PW"
      },
      "source": [
        "## Function: predict_and_plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSca91b6VAZC"
      },
      "source": [
        "def predict_and_plot(df, samp_indices, img_root_path, model, num_cols, col_size, row_size, fig_title):\n",
        "\n",
        "  '''\n",
        "  Function to make predictions on a subset of data and plot images with actual\n",
        "  and predicted labels\n",
        "\n",
        "  Arguments:\n",
        "    X: Input image array\n",
        "    y: Input label array\n",
        "    samp_indices: Indices from X to be plotted\n",
        "    model: Model instance to use for making predictions\n",
        "    num_cols: Number of columns to use for plotting\n",
        "    col_size: Size of columns to use for plotting\n",
        "    row_size: Size of rows to use for plotting\n",
        "    fig_title: Title to use for overall figure\n",
        "  ''' \n",
        "\n",
        "  num_rows = math.ceil(len(samp_indices) / num_cols) # Number of rows to use for plotting\n",
        "  fig = plt.figure(figsize = ((num_cols * col_size), (num_rows * row_size)))\n",
        "  fig.suptitle(fig_title, fontsize = 40)\n",
        "\n",
        "  for ind, samp_ind in enumerate(samp_indices): # Loop through samp_indices\n",
        "    img_file_name = df.loc[samp_ind, 'filename'] # Extract image filename from DataFrame\n",
        "    img_file_path = os.path.join(img_root_path, img_file_name) # Obtain image file path\n",
        "    img = cv2.cvtColor(cv2.imread(img_file_path), cv2.COLOR_BGR2RGB) # Load image\n",
        "    img_mod = np.expand_dims(img, axis = 0) # Add batch axis to feed to model\n",
        "    model_out = model(img_mod) # Pass input image through model\n",
        "\n",
        "    xmin, ymin, xmax, ymax = df.loc[samp_ind, ['xmin', 'ymin', 'xmax', 'ymax']] # Get ground-truth \n",
        "                                                                                # BBOX co-ords\n",
        "    img_h, img_w = df.loc[samp_ind, ['img_h', 'img_w']] # Extract image dimensions\n",
        "    act_class = df.loc[samp_ind, 'class'] # Get ground-truth class\n",
        "\n",
        "    score = 100 * model_out['detection_scores'][0].numpy()[0] # Extract best box score\n",
        "    bbox = model_out['detection_boxes'][0].numpy()[0] # Extract BBOX co-ordinates\n",
        "    label = model_out['detection_classes'][0].numpy().astype('int32')[0] # Extract class index\n",
        "    pred_class = label_class_dict[label] # Obtain class of car\n",
        "\n",
        "    # Scale BBOX co-ordinates to image dimensions\n",
        "    (bbox_ymin, bbox_xmin, bbox_ymax, bbox_xmax) = (int(bbox[0] * img_h), int(bbox[1] * img_w),\\\n",
        "                                                    int(bbox[2] * img_h), int(bbox[3] * img_w))  \n",
        "    # Set box_thickness based on image area  \n",
        "    box_thickness = int(np.ceil(((img_h) * (img_w)) / (100000)))\n",
        "    # Draw ground-truth BBOX in green\n",
        "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), box_thickness)\n",
        "    # Draw predicted BBOX in blue    \n",
        "    cv2.rectangle(img, (bbox_xmin, bbox_ymin), (bbox_xmax, bbox_ymax), (0, 0, 255), box_thickness)\n",
        "\n",
        "    ax = plt.subplot(num_rows, num_cols, (ind + 1))\n",
        "    ax.text(0.5, 1.23, f\"Actual class: {act_class}\", transform = ax.transAxes,\\\n",
        "            horizontalalignment = 'center', verticalalignment = 'center',\\\n",
        "            color = 'b', fontfamily = 'sans-serif', fontsize = '15')\n",
        "    ax.text(0.5, 1.14, f\"Pred. class: {pred_class} ({score:0.1f}%)\", transform = ax.transAxes,\\\n",
        "            horizontalalignment = 'center', verticalalignment = 'center',\\\n",
        "            color = 'b', fontfamily = 'sans-serif', fontsize = '15')\n",
        "    ax.text(0.5, 1.05, f\"Green: GT BBOX, Blue: Predicted BBOX\", transform = ax.transAxes,\\\n",
        "            horizontalalignment = 'center', verticalalignment = 'center',\\\n",
        "            color = 'r', fontfamily = 'sans-serif', fontsize = '13')\n",
        "    ax.imshow(img) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM5goFuTVFm7"
      },
      "source": [
        "## Training Set Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blkygO09VEV3"
      },
      "source": [
        "train_img_root_path = \"/content/Dataset/train_images\"\n",
        "fig_title = 'Random Images from Training Set'\n",
        "num_samp_to_plot = 8\n",
        "samp_indices = list(np.random.randint(low = 0, high = train_df.shape[0], size = num_samp_to_plot))\n",
        "predict_and_plot(train_df, samp_indices, train_img_root_path, model, 2, 9, 9, fig_title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWCA4Dn7VhDG"
      },
      "source": [
        "## Test Set Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy5vdH4qVkbB"
      },
      "source": [
        "test_img_root_path = \"/content/Dataset/test_images\"\n",
        "fig_title = 'Random Images from Testing Set'\n",
        "num_samp_to_plot = 8\n",
        "samp_indices = list(np.random.randint(low = 0, high = test_df.shape[0], size = num_samp_to_plot))\n",
        "predict_and_plot(test_df, samp_indices, test_img_root_path, model, 2, 8, 8, fig_title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPMVZXlSVuhK"
      },
      "source": [
        "# Evaluate Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWjrsPPJVyTE"
      },
      "source": [
        "## Function: iou computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-CYnGedV3LX"
      },
      "source": [
        "def iou(box1, box2):\n",
        "    \n",
        "    \"\"\"Implement the intersection over union (IoU) between box1 and box2\n",
        "    \n",
        "    Arguments:\n",
        "    box1 -- first box, list object with coordinates (box1_x1, box1_y1, box1_x2, box_1_y2)\n",
        "    box2 -- second box, list object with coordinates (box2_x1, box2_y1, box2_x2, box2_y2)\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract x, y co-ordinates of both boxes\n",
        "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
        "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
        "    \n",
        "    # Calculate the (xi1, yi1, xi2, yi2) coordinates of the intersection of box1 and box2. \n",
        "    # Calculate its Area.\n",
        "    xi1 = max(box1_x1, box2_x1)\n",
        "    yi1 = max(box1_y1, box2_y1)\n",
        "    xi2 = min(box1_x2, box2_x2)\n",
        "    yi2 = min(box1_y2, box2_y2)\n",
        "    inter_width = max((xi2 - xi1),0)\n",
        "    inter_height = max((yi2 - yi1),0)\n",
        "    inter_area = inter_width * inter_height\n",
        "\n",
        "    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
        "    box1_area = (box1_y2 - box1_y1) * (box1_x2 - box1_x1)\n",
        "    box2_area = (box2_y2 - box2_y1) * (box2_x2 - box2_x1)\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    \n",
        "    # compute the IoU\n",
        "    iou = inter_area / union_area\n",
        "    \n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfi-sSRpV6GY"
      },
      "source": [
        "## Function: model_eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdtRSPVsV8fV"
      },
      "source": [
        "def model_eval(df, img_root_path, num_samp):\n",
        "\n",
        "  '''\n",
        "  Function to evaluate the performance of the model given a certain set of images. \n",
        "  Classificaton accuracy and Mean IoU over all images will be computed and reported\n",
        "\n",
        "  Arguments:\n",
        "    df: Input Dataframe with image information\n",
        "    img_root_path: Root path of images\n",
        "    num_samp: Number of samples to use for evaluating model\n",
        "  '''\n",
        "  \n",
        "  # Create a dataframe placeholder to store evaluation results\n",
        "  df_cols = ['Act_Class', 'Pred_Class', 'Act_xmin', 'Act_ymin', 'Act_xmax', 'Act_ymax',\\\n",
        "           'Pred_xmin', 'Pred_ymin', 'Pred_xmax', 'Pred_ymax']\n",
        "  results_df = pd.DataFrame(columns = df_cols) # Placeholder to store results\n",
        "  corr_pred = 0 # counter to keep track of correct predictions\n",
        "  iou_list = [] # List to store IoU values (of Actual BBOX vs. Predicted BBOX) for each image\n",
        "\n",
        "  for samp_ind in tqdm(range(num_samp)): # Loop through num_samp\n",
        "    img_file_name = df.loc[samp_ind, 'filename'] # Extract image filename from DataFrame\n",
        "    img_file_path = os.path.join(img_root_path, img_file_name) # Obtain image file path\n",
        "    img = cv2.cvtColor(cv2.imread(img_file_path), cv2.COLOR_BGR2RGB) # Load image\n",
        "    img_mod = np.expand_dims(img, axis = 0) # Add batch axis to feed to model\n",
        "    model_out = model(img_mod) # Pass input image through model \n",
        "\n",
        "    act_class = df.loc[samp_ind, 'class'] # Get ground-truth class\n",
        "    label = model_out['detection_classes'][0].numpy().astype('int32')[0] # Extract class index\n",
        "    pred_class = label_class_dict[label] # Obtain class prediction\n",
        "    bbox = model_out['detection_boxes'][0].numpy()[0] # Extract BBOX co-ordinates\n",
        "    img_h, img_w = df.loc[samp_ind, ['img_h', 'img_w']] # Extract image dimensions\n",
        "\n",
        "    # Create entry_dict for updating dataframe\n",
        "    entry_dict = {'Act_Class': act_class,\n",
        "                  'Pred_Class': pred_class,\n",
        "                  'Act_xmin': df.loc[samp_ind, 'xmin'],\n",
        "                  'Act_ymin': df.loc[samp_ind, 'ymin'],\n",
        "                  'Act_xmax': df.loc[samp_ind, 'xmax'],\n",
        "                  'Act_ymax': df.loc[samp_ind, 'ymax'],\n",
        "                  'Pred_xmin': int(bbox[1] * img_w),\n",
        "                  'Pred_ymin': int(bbox[0] * img_h),\n",
        "                  'Pred_xmax': int(bbox[3] * img_w),\n",
        "                  'Pred_ymax': int(bbox[2] * img_h),\n",
        "                }\n",
        "    results_df = results_df.append(entry_dict, ignore_index = True) # Update dataframe\n",
        "\n",
        "    # Update corr_pred\n",
        "    corr_pred += int(entry_dict['Act_Class'] == entry_dict['Pred_Class'])\n",
        "\n",
        "    # Compute IoU\n",
        "    box1 = (entry_dict['Act_xmin'], entry_dict['Act_ymin'],\\\n",
        "            entry_dict['Act_xmax'], entry_dict['Act_ymax'])\n",
        "    box2 = (entry_dict['Pred_xmin'], entry_dict['Pred_ymin'],\\\n",
        "            entry_dict['Pred_xmax'], entry_dict['Pred_ymax'])\n",
        "    iou_list.append(iou(box1, box2))\n",
        "\n",
        "  tot_pred = results_df.shape[0]\n",
        "  print()\n",
        "  print()\n",
        "  print(\"Classification accuracy is %0.2f %%\" %(100 * (corr_pred / tot_pred)))\n",
        "  print(\"Mean IoU score is %0.4f\" %(np.mean(iou_list)))\n",
        "\n",
        "  return results_df, iou_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbA_AmYiV_7F"
      },
      "source": [
        "## Evaluate model on training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQRuzcR2WCdE"
      },
      "source": [
        "train_img_root_path = \"/content/Dataset/train_images\"\n",
        "train_results_df, train_iou_list = model_eval(train_df, train_img_root_path, train_df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EEdFq3sWENY"
      },
      "source": [
        "## Evaluate model on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU3WsqyEWG3Q"
      },
      "source": [
        "test_img_root_path = \"/content/Dataset/test_images\"\n",
        "test_results_df, test_iou_list = model_eval(test_df, test_img_root_path, test_df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X2mdxCUVWRm"
      },
      "source": [
        "# Backup - Please ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4QfC1XR7wGN"
      },
      "source": [
        "## Function: plt_img_w_bboxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqSmZGDfyifY"
      },
      "source": [
        "def plt_img_w_bboxes(inp_img_path, score_threshold = 0.4, norm_coords = True, box_thickness = 3,\\\n",
        "                     font_size = 25):\n",
        "\n",
        "    '''\n",
        "    Take an input image path, extract the image, run inference on the image to get bounding boxes\n",
        "    Plot bounding boxes and labels on top of the image\n",
        "    '''\n",
        "    \n",
        "    inp_img_pil = Image.open(inp_img_path) # Load image as a PIL object\n",
        "    inp_img_arr = np.array(inp_img_pil) # Convert PIL object to numpy array\n",
        "    inp_img_arr = np.expand_dims(inp_img_arr, axis = 0) # Add batch axis\n",
        "    model_out = model(inp_img_arr) # Pass input image through model\n",
        "    \n",
        "    scores = model_out['detection_scores'][0].numpy() # Extract scores for each box\n",
        "    boxes = model_out['detection_boxes'][0].numpy() # Extract box co-ordinates\n",
        "    class_ind = model_out['detection_classes'][0].numpy().astype('int32') # Extract class indices\n",
        "    \n",
        "    # Draw box and labels on image\n",
        "    inp_img_pil_w_bbox = draw_boxes_and_labels(inp_img_pil, scores, boxes, class_ind,\\\n",
        "                                               label_class_dict,\\\n",
        "                                               score_threshold = score_threshold,\\\n",
        "                                               norm_coords = norm_coords,\\\n",
        "                                               box_thickness = box_thickness, font_size = font_size)\n",
        "    \n",
        "    return inp_img_pil_w_bbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omdXuveI0xlU"
      },
      "source": [
        "inp_img_path = \"/content/Dataset/test_images/08037.jpg\"\n",
        "plt_img_w_bboxes(inp_img_path, score_threshold = 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIYMkT7djB7i"
      },
      "source": [
        "inp_img_path = \"/content/Dataset/test_images/00003.jpg\"\n",
        "inp_img_pil = Image.open(inp_img_path) # Load image as a PIL object\n",
        "inp_img_arr = np.array(inp_img_pil) # Convert PIL object to numpy array\n",
        "inp_img_arr = np.expand_dims(inp_img_arr, axis = 0) # Add batch axis\n",
        "model_out = model(inp_img_arr) # Pass input image through model\n",
        "\n",
        "scores = model_out['detection_scores'][0].numpy() # Extract scores for each box\n",
        "boxes = model_out['detection_boxes'][0].numpy() # Extract box co-ordinates\n",
        "class_ind = model_out['detection_classes'][0].numpy().astype('int32') # Extract class indices\n",
        "print(scores[0:5])\n",
        "print()\n",
        "print([label_class_dict[ind] for ind in class_ind[0:5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq_3EKBf3WHM"
      },
      "source": [
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVsb-ComZvr0"
      },
      "source": [
        "## Evaluate Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na3Oc34sZtRg"
      },
      "source": [
        "## Function: iou computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1rDtRdLZ1KA"
      },
      "source": [
        "def iou(box1, box2):\n",
        "    \n",
        "    \"\"\"Implement the intersection over union (IoU) between box1 and box2\n",
        "    \n",
        "    Arguments:\n",
        "    box1 -- first box, list object with coordinates (box1_x1, box1_y1, box1_x2, box_1_y2)\n",
        "    box2 -- second box, list object with coordinates (box2_x1, box2_y1, box2_x2, box2_y2)\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract x, y co-ordinates of both boxes\n",
        "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
        "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
        "    \n",
        "    # Calculate the (xi1, yi1, xi2, yi2) coordinates of the intersection of box1 and box2. \n",
        "    # Calculate its Area.\n",
        "    xi1 = max(box1_x1, box2_x1)\n",
        "    yi1 = max(box1_y1, box2_y1)\n",
        "    xi2 = min(box1_x2, box2_x2)\n",
        "    yi2 = min(box1_y2, box2_y2)\n",
        "    inter_width = max((xi2 - xi1),0)\n",
        "    inter_height = max((yi2 - yi1),0)\n",
        "    inter_area = inter_width * inter_height\n",
        "\n",
        "    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
        "    box1_area = (box1_y2 - box1_y1) * (box1_x2 - box1_x1)\n",
        "    box2_area = (box2_y2 - box2_y1) * (box2_x2 - box2_x1)\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    \n",
        "    # compute the IoU\n",
        "    iou = inter_area / union_area\n",
        "    \n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p9szq_sZ7hG"
      },
      "source": [
        "## Function: model_eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc4J_E1GZ8jD"
      },
      "source": [
        "def model_eval(df, img_root_path, num_samp):\n",
        "\n",
        "  '''\n",
        "  Function to evaluate the performance of the model given a certain set of images. \n",
        "  Classificaton accuracy and Mean IoU over all images will be computed and reported\n",
        "\n",
        "  Arguments:\n",
        "    df: Input Dataframe with image information\n",
        "    img_root_path: Root path of images\n",
        "    num_samp: Number of samples to use for evaluating model\n",
        "  '''\n",
        "  \n",
        "  # Create a dataframe placeholder to store evaluation results\n",
        "  df_cols = ['Act_Class', 'Pred_Class', 'Act_xmin', 'Act_ymin', 'Act_xmax', 'Act_ymax',\\\n",
        "           'Pred_xmin', 'Pred_ymin', 'Pred_xmax', 'Pred_ymax']\n",
        "  results_df = pd.DataFrame(columns = df_cols) # Placeholder to store results\n",
        "  corr_pred = 0 # counter to keep track of correct predictions\n",
        "  iou_list = [] # List to store IoU values (of Actual BBOX vs. Predicted BBOX) for each image\n",
        "\n",
        "  for samp_ind in tqdm(range(num_samp)): # Loop through num_samp\n",
        "    img_file_name = df.loc[samp_ind, 'filename'] # Extract image filename from DataFrame\n",
        "    img_file_path = os.path.join(img_root_path, img_file_name) # Obtain image file path\n",
        "    img = cv2.cvtColor(cv2.imread(img_file_path), cv2.COLOR_BGR2RGB) # Load image\n",
        "    img_mod = np.expand_dims(img, axis = 0) # Add batch axis to feed to model\n",
        "    model_out = model(img_mod) # Pass input image through model \n",
        "\n",
        "    act_class = df.loc[samp_ind, 'class'] # Get ground-truth class\n",
        "    label = model_out['detection_classes'][0].numpy().astype('int32')[0] # Extract class index\n",
        "    pred_class = label_class_dict[label] # Obtain class prediction\n",
        "    bbox = model_out['detection_boxes'][0].numpy()[0] # Extract BBOX co-ordinates\n",
        "    img_h, img_w = df.loc[samp_ind, ['img_h', 'img_w']] # Extract image dimensions\n",
        "\n",
        "    # Create entry_dict for updating dataframe\n",
        "    entry_dict = {'Act_Class': act_class,\n",
        "                  'Pred_Class': pred_class,\n",
        "                  'Act_xmin': df.loc[samp_ind, 'xmin'],\n",
        "                  'Act_ymin': df.loc[samp_ind, 'ymin'],\n",
        "                  'Act_xmax': df.loc[samp_ind, 'xmax'],\n",
        "                  'Act_ymax': df.loc[samp_ind, 'ymax'],\n",
        "                  'Pred_xmin': int(bbox[1] * img_w),\n",
        "                  'Pred_ymin': int(bbox[0] * img_h),\n",
        "                  'Pred_xmax': int(bbox[3] * img_w),\n",
        "                  'Pred_ymax': int(bbox[2] * img_h),\n",
        "                }\n",
        "    results_df = results_df.append(entry_dict, ignore_index = True) # Update dataframe\n",
        "\n",
        "    # Update corr_pred\n",
        "    corr_pred += int(entry_dict['Act_Class'] == entry_dict['Pred_Class'])\n",
        "\n",
        "    # Compute IoU\n",
        "    box1 = (entry_dict['Act_xmin'], entry_dict['Act_ymin'],\\\n",
        "            entry_dict['Act_xmax'], entry_dict['Act_ymax'])\n",
        "    box2 = (entry_dict['Pred_xmin'], entry_dict['Pred_ymin'],\\\n",
        "            entry_dict['Pred_xmax'], entry_dict['Pred_ymax'])\n",
        "    iou_list.append(iou(box1, box2))\n",
        "\n",
        "  tot_pred = results_df.shape[0]\n",
        "  print()\n",
        "  print()\n",
        "  print(\"Classification accuracy is %0.2f %%\" %(100 * (corr_pred / tot_pred)))\n",
        "  print(\"Mean IoU score is %0.4f\" %(np.mean(iou_list)))\n",
        "\n",
        "  return results_df, iou_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0sYzfJdaDsi"
      },
      "source": [
        "## Evaluate model on training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPmR883yaEsT"
      },
      "source": [
        "train_img_root_path = \"/content/Dataset/train_images\"\n",
        "train_results_df, train_iou_list = model_eval(train_df, train_img_root_path, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQuS6v8naIPS"
      },
      "source": [
        "## Evaluate model on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI0dbsh5aKOY"
      },
      "source": [
        "test_img_root_path = \"/content/Dataset/test_images\"\n",
        "test_results_df, test_iou_list = model_eval(test_df, test_img_root_path, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}