{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Transformer_From_Scratch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suresh-venkate/Code_Repositories/blob/main/Deep_Learning/Natural_Language_Processing/Transformer_Models/Transformer_From_Scratch/Transformer_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI075CzzZS35"
      },
      "source": [
        "# Transformer from scratch\n",
        "\n",
        "* Reference: Attention is all you need, NIPS 2017\n",
        "* Authors: Ashish Vaswani et.al.\n",
        "* Link to paper: [Link](https://arxiv.org/abs/1706.03762)\n",
        "* All references in the code below refer to this paper unless stated otherwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWbH-n-mYZzA"
      },
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lDHMlknmKxK"
      },
      "source": [
        "%%capture \n",
        "!wget https://raw.githubusercontent.com/suresh-venkate/Code_Repositories/main/Deep_Learning/Natural_Language_Processing/Transformer_Models/Transformer_From_Scratch/transformer_utils.py\n",
        "!wget https://raw.githubusercontent.com/suresh-venkate/Code_Repositories/main/Deep_Learning/Natural_Language_Processing/Transformer_Models/Transformer_From_Scratch/transformer_utils_orig.py"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MThcSvYYcig"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math, copy, time\n",
        "import seaborn\n",
        "seaborn.set_context(context=\"talk\")\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchsummary import summary as ts_summary\n",
        "from torch.autograd import Variable\n",
        "\n",
        "#from transformer_utils_orig import *\n",
        "from transformer_utils import clones, Embeddings, PositionalEncoding\n",
        "from transformer_utils import Generator\n",
        "from transformer_utils import PositionwiseFeedForward\n",
        "from transformer_utils import ScaledDotProductAttention\n",
        "\n",
        "from transformer_utils_orig import EncoderDecoder\n",
        "from transformer_utils_orig import Encoder\n",
        "from transformer_utils_orig import SublayerConnection, EncoderLayer, Decoder, DecoderLayer\n",
        "from transformer_utils_orig import MultiHeadedAttention\n",
        "from transformer_utils_orig import make_model\n",
        "\n",
        "#from transformer_utils_orig import LayerNorm\n",
        "#from transformer_utils_orig import Generator\n",
        "#from transformer_utils_orig import clones\n",
        "#from transformer_utils_orig import Embeddings, PositionalEncoding\n",
        "#from transformer_utils_orig import PositionwiseFeedForward\n",
        "#from transformer_utils_orig import attention"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3ru3h5Q-5hN"
      },
      "source": [
        "# Backup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwJnfYQeIQGp"
      },
      "source": [
        "## Verify Function: clones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXw8VvRl9Mxm"
      },
      "source": [
        "# class TempModel(nn.Module):\n",
        "#   def __init__(self, layer, N):\n",
        "#     super(TempModel, self).__init__()\n",
        "#     self.layers = clones(layer, N)\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     for layer in self.layers:\n",
        "#       x = layer(x)\n",
        "#     return x\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# lin_layer = nn.Linear(128, 128)\n",
        "# temp_model = TempModel(lin_layer, 4).to(device) # Clone linear layer 4 times\n",
        "# ts_summary(temp_model, input_size = (128,))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R8ANPCHRyy9"
      },
      "source": [
        "## Verify Class: ScaledDotProductAttention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMYg-_GduO1R"
      },
      "source": [
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# temp_model = ScaledDotProductAttention(4).to(device) # Clone linear layer 4 times\n",
        "\n",
        "# Q = torch.randint(0, 10, (2, 3, 5, 16), dtype = torch.float32)\n",
        "# K = torch.clone(Q)\n",
        "# V = torch.clone(Q)\n",
        "\n",
        "# attn, probs = temp_model(Q, K, V)\n",
        "# attn = torch.ceil(attn)\n",
        "\n",
        "# print(Q.shape, attn.shape, probs.shape)\n",
        "# print()\n",
        "# print(Q[0, 0])\n",
        "# print()\n",
        "# print(probs[0, 0])\n",
        "# print()\n",
        "# print(attn[0, 0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTxaYcNQc6xN"
      },
      "source": [
        "## Verify Class: MultiHeadAttention\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67X-WPO3dBl_"
      },
      "source": [
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# temp_model = MultiHeadAttention(h = 8, d_model = 512, attn_dropout = 0.0).to(device)\n",
        "\n",
        "# Q = torch.randint(0, 10, (2, 5, 512), dtype = torch.float32).to(device)\n",
        "# K = torch.clone(Q)\n",
        "# V = torch.clone(Q)\n",
        "\n",
        "# x = temp_model(Q, K, V, mask = None)\n",
        "# print(x.shape, temp_model.attn.shape)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrzNUSB33Z6S"
      },
      "source": [
        "## Verify Class: Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvcLFj463cZC"
      },
      "source": [
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# src_vocab = 11 # 0 to 10\n",
        "# d_model = 512\n",
        "# temp_model = Embeddings(d_model, src_vocab).to(device)\n",
        "\n",
        "# # Generate 5 input samples of length 10 each\n",
        "# input = torch.randint(0, 10, (5, 10)).to(device)\n",
        "# output = temp_model(input)\n",
        "\n",
        "# print(input.shape, output.shape)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV4dQw7_6RDw"
      },
      "source": [
        "## Verify Class: PositionalEncoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RR2dxTMAgmO"
      },
      "source": [
        "# d_model = 20\n",
        "# pe = PositionalEncoding(d_model, dropout = 0)\n",
        "# input = torch.zeros(1, 100, 20)\n",
        "# output = pe.forward(input)\n",
        "\n",
        "# plt.figure(figsize=(15, 5))\n",
        "# plt.plot(np.arange(100), output[0, :, 4:8].numpy())\n",
        "# plt.legend([\"dim %d\" %p for p in [4, 5, 6, 7]])\n",
        "# plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ugLO6-o8oRdZ"
      },
      "source": [
        "# class AddAndNormDec(nn.Module):\n",
        "#   \"\"\"\n",
        "#   Add a residual connection followed by a layer norm.\n",
        "#   \"\"\"\n",
        "#   def __init__(self, size):\n",
        "#     super(AddAndNormDec, self).__init__()\n",
        "#     self.norm = nn.LayerNorm(size, eps = 1e-6)\n",
        "    \n",
        "#   def forward(self, x, sublayer):\n",
        "#     #return self.norm(x + sublayer(x))\n",
        "#     return x + sublayer(self.norm(x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QKTNMa9uWcE"
      },
      "source": [
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# attn = MultiHeadAttention(8, 512).to(device)\n",
        "# addandnorm = AddAndNorm(512).to(device)\n",
        "\n",
        "# # # Generate 5 input samples of length 10 each\n",
        "# # input = torch.randint(0, 10, (5, 10)).to(device)\n",
        "# # output = temp_model(input)\n",
        "\n",
        "# # print(input.shape, output.shape)\n",
        "# #ts_summary(temp_model, input_size = (10, 512))\n",
        "# Q = torch.randint(0, 10, (2, 5, 512), dtype = torch.float32).to(device)\n",
        "# K = torch.clone(Q)\n",
        "# V = torch.clone(Q)\n",
        "\n",
        "# x = attn(Q, K, V, mask = None)\n",
        "# y = addandnorm"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUlOoGM4XtlT"
      },
      "source": [
        "# Backup_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma7LmcBBDayM"
      },
      "source": [
        "## Define classes and Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5u07_veQXq9B"
      },
      "source": [
        "# class EncoderDecoder(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Overall Encode Decoder module\n",
        "#     \"\"\"\n",
        "#     def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "#         super(EncoderDecoder, self).__init__()\n",
        "#         self.encoder = encoder\n",
        "#         self.decoder = decoder\n",
        "#         self.src_embed = src_embed\n",
        "#         self.tgt_embed = tgt_embed\n",
        "#         self.generator = generator\n",
        "        \n",
        "#     def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "#         \"Take in and process masked src and target sequences.\"\n",
        "#         return self.decode(self.encode(src, src_mask), src_mask,\n",
        "#                             tgt, tgt_mask)\n",
        "    \n",
        "#     def encode(self, src, src_mask):\n",
        "#         return self.encoder(self.src_embed(src), src_mask)\n",
        "    \n",
        "#     def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "#         return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_9Oz1BqQXq9B"
      },
      "source": [
        "# class Generator(nn.Module):\n",
        "#   \"\"\"\n",
        "#   Final output layer (linear + softmax) to be added after the decoder output\n",
        "#   \"\"\"\n",
        "#   def __init__(self, d_model, vocab):\n",
        "#     \"\"\"\n",
        "#     Arguments: \n",
        "#       d_model: Size of the embedding vector\n",
        "#       vocab: Size of input vocabulary\n",
        "#     \"\"\"\n",
        "#     super(Generator, self).__init__()\n",
        "#     self.proj = nn.Linear(d_model, vocab)\n",
        "#     self.smax = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     # x = self.proj(x)\n",
        "#     # x = self.smax(x)\n",
        "#     return self.smax(self.proj(x))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3YxN1jjXXq9O"
      },
      "source": [
        "# def make_model(src_vocab, tgt_vocab, N=6, \n",
        "#                d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "#     \"Helper: Construct a model from hyperparameters.\"\n",
        "#     c = copy.deepcopy\n",
        "#     position = PositionalEncoding(d_model, dropout)\n",
        "#     model = EncoderDecoder(\n",
        "#         Encoder(d_model, h, dropout, d_ff, dropout, N),\n",
        "#         Decoder(d_model, h, dropout, d_ff, dropout, N),\n",
        "#         nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "#         nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "#         Generator(d_model, tgt_vocab))    \n",
        "    \n",
        "#     # This was important from their code. \n",
        "#     # Initialize parameters with Glorot / fan_avg.\n",
        "#     for p in model.parameters():\n",
        "#         if p.dim() > 1:\n",
        "#             nn.init.xavier_uniform(p)\n",
        "#     return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "aFIfv_2RXq9P",
        "outputId": "99b86275-1eb3-44a7-983c-7f89facd310a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Small example model.\n",
        "tmp_model = make_model(10, 10, 2)\n",
        "tmp_model"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformer_utils_orig.py:222: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(p)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoder(\n",
              "  (encoder): Encoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn): MultiHeadedAttention(\n",
              "          (linears): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): ScaledDotProductAttention(\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (feed_forward): PositionwiseFeedForward(\n",
              "          (fc_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn): MultiHeadedAttention(\n",
              "          (linears): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): ScaledDotProductAttention(\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (feed_forward): PositionwiseFeedForward(\n",
              "          (fc_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attn): MultiHeadedAttention(\n",
              "          (linears): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): ScaledDotProductAttention(\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (src_attn): MultiHeadedAttention(\n",
              "          (linears): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): ScaledDotProductAttention(\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (feed_forward): PositionwiseFeedForward(\n",
              "          (fc_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SublayerConnection(\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attn): MultiHeadedAttention(\n",
              "          (linears): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): ScaledDotProductAttention(\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (src_attn): MultiHeadedAttention(\n",
              "          (linears): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): ScaledDotProductAttention(\n",
              "            (softmax): Softmax(dim=-1)\n",
              "          )\n",
              "        )\n",
              "        (feed_forward): PositionwiseFeedForward(\n",
              "          (fc_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (sublayer): ModuleList(\n",
              "          (0): SublayerConnection(\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SublayerConnection(\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SublayerConnection(\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (src_embed): Sequential(\n",
              "    (0): Embeddings(\n",
              "      (emb): Embedding(10, 512)\n",
              "    )\n",
              "    (1): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (tgt_embed): Sequential(\n",
              "    (0): Embeddings(\n",
              "      (emb): Embedding(10, 512)\n",
              "    )\n",
              "    (1): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (generator): Generator(\n",
              "    (proj): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (smax): LogSoftmax(dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "BruCIK5kXq9J"
      },
      "source": [
        "def subsequent_mask(size):\n",
        "    \"Mask out subsequent positions.\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "    return torch.from_numpy(subsequent_mask) == 0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cw-bWMGXq9K",
        "outputId": "d7027b46-3c18-45c1-e2eb-353a979a47bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(subsequent_mask(20)[0])\n",
        "None"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "C_hrhDpSXq9P"
      },
      "source": [
        "class Batch:\n",
        "    \"Object for holding a batch of data with mask during training.\"\n",
        "    def __init__(self, src, trg=None, pad=0):\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2)\n",
        "        if trg is not None:\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = \\\n",
        "                self.make_std_mask(self.trg, pad)\n",
        "            self.ntokens = (self.trg_y != pad).data.sum()\n",
        "    \n",
        "    @staticmethod\n",
        "    def make_std_mask(tgt, pad):\n",
        "        \"Create a mask to hide padding and future words.\"\n",
        "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "        tgt_mask = tgt_mask & Variable(\n",
        "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
        "        return tgt_mask"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yDpJ74V1Xq9Q"
      },
      "source": [
        "def run_epoch(data_iter, model, loss_compute):\n",
        "    \"Standard Training and Logging Function\"\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    tokens = 0\n",
        "    for i, batch in enumerate(data_iter):\n",
        "        out = model.forward(batch.src, batch.trg, \n",
        "                            batch.src_mask, batch.trg_mask)\n",
        "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        tokens += batch.ntokens\n",
        "        if i % 50 == 1:\n",
        "            elapsed = time.time() - start\n",
        "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
        "                    (i, loss / batch.ntokens, tokens / elapsed))\n",
        "            start = time.time()\n",
        "            tokens = 0\n",
        "    return total_loss / total_tokens"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "XxlRc2ooXq9Q"
      },
      "source": [
        "global max_src_in_batch, max_tgt_in_batch\n",
        "def batch_size_fn(new, count, sofar):\n",
        "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
        "    global max_src_in_batch, max_tgt_in_batch\n",
        "    if count == 1:\n",
        "        max_src_in_batch = 0\n",
        "        max_tgt_in_batch = 0\n",
        "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
        "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
        "    src_elements = count * max_src_in_batch\n",
        "    tgt_elements = count * max_tgt_in_batch\n",
        "    return max(src_elements, tgt_elements)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZSMNBwjzXq9R"
      },
      "source": [
        "class NoamOpt:\n",
        "    \"Optim wrapper that implements rate.\"\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "        \n",
        "    def step(self):\n",
        "        \"Update parameters and rate\"\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def rate(self, step = None):\n",
        "        \"Implement `lrate` above\"\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return self.factor * \\\n",
        "            (self.model_size ** (-0.5) *\n",
        "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
        "        \n",
        "def get_std_opt(model):\n",
        "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
        "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkTG4VoeXq9R",
        "outputId": "3daf0060-89b8-4e71-b05b-1343da90459c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Three settings of the lrate hyperparameters.\n",
        "opts = [NoamOpt(512, 1, 4000, None), \n",
        "        NoamOpt(512, 1, 8000, None),\n",
        "        NoamOpt(256, 1, 4000, None)]\n",
        "plt.plot(np.arange(1, 20000), [[opt.rate(i) for opt in opts] for i in range(1, 20000)])\n",
        "plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\n",
        "None"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_cwDcAbQXq9S"
      },
      "source": [
        "class LabelSmoothing(nn.Module):\n",
        "    \"Implement label smoothing.\"\n",
        "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.criterion = nn.KLDivLoss(size_average=False)\n",
        "        self.padding_idx = padding_idx\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.size = size\n",
        "        self.true_dist = None\n",
        "        \n",
        "    def forward(self, x, target):\n",
        "        assert x.size(1) == self.size\n",
        "        true_dist = x.data.clone()\n",
        "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
        "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        true_dist[:, self.padding_idx] = 0\n",
        "        mask = torch.nonzero(target.data == self.padding_idx)\n",
        "        if mask.dim() > 0:\n",
        "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "        self.true_dist = true_dist\n",
        "        return self.criterion(x, Variable(true_dist, requires_grad=False))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Gk4m0NXq9T",
        "outputId": "fec769c4-867f-48cb-ec0d-f856928bd56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "#Example of label smoothing.\n",
        "crit = LabelSmoothing(5, 0, 0.4)\n",
        "predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n",
        "                             [0, 0.2, 0.7, 0.1, 0], \n",
        "                             [0, 0.2, 0.7, 0.1, 0]])\n",
        "v = crit(Variable(predict.log()), \n",
        "         Variable(torch.LongTensor([2, 1, 0])))\n",
        "\n",
        "# Show the target distributions expected by the system.\n",
        "plt.imshow(crit.true_dist)\n",
        "None"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic5GcDWEXq9T",
        "outputId": "3e218ad7-ca7d-4b24-bf54-1a9a8ff701ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "crit = LabelSmoothing(5, 0, 0.1)\n",
        "def loss(x):\n",
        "    d = x + 3 * 1\n",
        "    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d],\n",
        "                                 ])\n",
        "    #print(predict)\n",
        "    return crit(Variable(predict.log()),\n",
        "                 Variable(torch.LongTensor([1]))).item()\n",
        "plt.plot(np.arange(1, 100), [loss(x) for x in range(1, 100)])\n",
        "None"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DOg6L-rXq9U"
      },
      "source": [
        "## Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "S0aXeGP0Xq9U"
      },
      "source": [
        "def data_gen(V, batch, nbatches):\n",
        "    \"Generate random data for a src-tgt copy task.\"\n",
        "    for i in range(nbatches):\n",
        "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n",
        "        data[:, 0] = 1\n",
        "        src = Variable(data, requires_grad=False)\n",
        "        tgt = Variable(data, requires_grad=False)\n",
        "        yield Batch(src, tgt, 0)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULRFkGb8Xq9U"
      },
      "source": [
        "## Loss Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7Ae8ht1RXq9V"
      },
      "source": [
        "class SimpleLossCompute:\n",
        "    \"A simple loss compute and train function.\"\n",
        "    def __init__(self, generator, criterion, opt=None):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "        self.opt = opt\n",
        "        \n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
        "                              y.contiguous().view(-1)) / norm\n",
        "        loss.backward()\n",
        "        if self.opt is not None:\n",
        "            self.opt.step()\n",
        "            self.opt.optimizer.zero_grad()\n",
        "        #return loss.data[0] * norm\n",
        "        return loss.item() * norm"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_5N7srEXq9V"
      },
      "source": [
        "## Greedy Decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fANlh8SzXq9V",
        "outputId": "98244712-a1b5-43d3-d2d3-5744ee58e8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train the simple copy task.\n",
        "V = 11\n",
        "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
        "model = make_model(V, V, N=2)\n",
        "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
        "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    run_epoch(data_gen(V, 30, 20), model, \n",
        "              SimpleLossCompute(model.generator, criterion, model_opt))\n",
        "    model.eval()\n",
        "    print(run_epoch(data_gen(V, 30, 5), model, \n",
        "                    SimpleLossCompute(model.generator, criterion, None)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/content/transformer_utils_orig.py:222: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  nn.init.xavier_uniform(p)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Step: 1 Loss: 3.042938 Tokens per Sec: 461.221619\n",
            "Epoch Step: 1 Loss: 1.922031 Tokens per Sec: 804.966919\n",
            "tensor(1.9303)\n",
            "Epoch Step: 1 Loss: 1.989041 Tokens per Sec: 637.673584\n",
            "Epoch Step: 1 Loss: 1.724341 Tokens per Sec: 848.396118\n",
            "tensor(1.6674)\n",
            "Epoch Step: 1 Loss: 2.033901 Tokens per Sec: 666.857300\n",
            "Epoch Step: 1 Loss: 1.417689 Tokens per Sec: 860.021484\n",
            "tensor(1.4231)\n",
            "Epoch Step: 1 Loss: 1.722259 Tokens per Sec: 659.370972\n",
            "Epoch Step: 1 Loss: 1.105606 Tokens per Sec: 873.086426\n",
            "tensor(1.1714)\n",
            "Epoch Step: 1 Loss: 1.254820 Tokens per Sec: 668.414795\n",
            "Epoch Step: 1 Loss: 0.956480 Tokens per Sec: 866.369995\n",
            "tensor(0.9529)\n",
            "Epoch Step: 1 Loss: 1.088670 Tokens per Sec: 656.028564\n",
            "Epoch Step: 1 Loss: 0.640562 Tokens per Sec: 881.458740\n",
            "tensor(0.5787)\n",
            "Epoch Step: 1 Loss: 0.750848 Tokens per Sec: 650.478760\n",
            "Epoch Step: 1 Loss: 0.500509 Tokens per Sec: 827.319702\n",
            "tensor(0.4829)\n",
            "Epoch Step: 1 Loss: 0.708939 Tokens per Sec: 623.286560\n",
            "Epoch Step: 1 Loss: 0.221647 Tokens per Sec: 816.976440\n",
            "tensor(0.2665)\n",
            "Epoch Step: 1 Loss: 0.363781 Tokens per Sec: 632.313477\n",
            "Epoch Step: 1 Loss: 0.233817 Tokens per Sec: 861.872803\n",
            "tensor(0.2514)\n",
            "Epoch Step: 1 Loss: 0.664591 Tokens per Sec: 675.670776\n",
            "Epoch Step: 1 Loss: 0.208773 Tokens per Sec: 881.178589\n",
            "tensor(0.2711)\n",
            "Epoch Step: 1 Loss: 0.535842 Tokens per Sec: 669.392273\n",
            "Epoch Step: 1 Loss: 0.231514 Tokens per Sec: 858.708069\n",
            "tensor(0.2707)\n",
            "Epoch Step: 1 Loss: 0.234353 Tokens per Sec: 672.169861\n",
            "Epoch Step: 1 Loss: 0.174761 Tokens per Sec: 897.584045\n",
            "tensor(0.1934)\n",
            "Epoch Step: 1 Loss: 0.368223 Tokens per Sec: 662.029358\n",
            "Epoch Step: 1 Loss: 0.339304 Tokens per Sec: 810.840271\n",
            "tensor(0.2965)\n",
            "Epoch Step: 1 Loss: 1.343850 Tokens per Sec: 633.451111\n",
            "Epoch Step: 1 Loss: 0.246885 Tokens per Sec: 806.417725\n",
            "tensor(0.2003)\n",
            "Epoch Step: 1 Loss: 0.328617 Tokens per Sec: 625.437134\n",
            "Epoch Step: 1 Loss: 0.100399 Tokens per Sec: 802.947327\n",
            "tensor(0.1123)\n",
            "Epoch Step: 1 Loss: 0.167119 Tokens per Sec: 629.749634\n",
            "Epoch Step: 1 Loss: 0.431693 Tokens per Sec: 836.575073\n",
            "tensor(0.3274)\n",
            "Epoch Step: 1 Loss: 0.232910 Tokens per Sec: 653.790588\n",
            "Epoch Step: 1 Loss: 0.594076 Tokens per Sec: 841.262756\n",
            "tensor(0.4887)\n",
            "Epoch Step: 1 Loss: 0.661691 Tokens per Sec: 659.125366\n",
            "Epoch Step: 1 Loss: 0.616867 Tokens per Sec: 805.974670\n",
            "tensor(0.6088)\n",
            "Epoch Step: 1 Loss: 0.625380 Tokens per Sec: 649.392761\n",
            "Epoch Step: 1 Loss: 0.573527 Tokens per Sec: 786.438538\n",
            "tensor(0.6657)\n",
            "Epoch Step: 1 Loss: 0.702918 Tokens per Sec: 631.597229\n",
            "Epoch Step: 1 Loss: 0.864070 Tokens per Sec: 693.516418\n",
            "tensor(0.8380)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcVpHCSZXq9V"
      },
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
        "    for i in range(max_len-1):\n",
        "        out = model.decode(memory, src_mask, \n",
        "                           Variable(ys), \n",
        "                           Variable(subsequent_mask(ys.size(1))\n",
        "                                    .type_as(src.data)))\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim = 1)\n",
        "        next_word = next_word.data[0]\n",
        "        ys = torch.cat([ys, \n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
        "    return ys"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZM2or8QEE2P",
        "outputId": "6472e88c-6f34-414f-9f22-a0b9bb5b5889",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.eval()\n",
        "src = Variable(torch.LongTensor([[1,8,5,7,3,6,7,8,9,10]]))\n",
        "#src = Variable(torch.LongTensor([[1,8,5,7,3,6,7,8,9,10]]))\n",
        "src_mask = Variable(torch.ones(1, 1, 10))\n",
        "print(greedy_decode(model, src, src_mask, max_len=10, start_symbol=1))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  8,  5,  5,  3,  6,  7,  8,  9, 10]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RynFrZjDJln"
      },
      "source": [
        "# Backup_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmkUG3JYXq9W"
      },
      "source": [
        "# A Real World Example\n",
        "\n",
        "> Now we consider a real-world example using the IWSLT German-English Translation task. This task is much smaller than the WMT task considered in the paper, but it illustrates the whole system. We also show how to use multi-gpu processing to make it really fast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rLFMHnFqXq9W"
      },
      "source": [
        "#!pip install torchtext spacy\n",
        "#!python -m spacy download en\n",
        "#!python -m spacy download de"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG4pUsT7Xq9W"
      },
      "source": [
        "## Data Loading\n",
        "> We will load the dataset using torchtext and spacy for tokenization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "df4hc1trXq9W"
      },
      "source": [
        "# For data loading.\n",
        "from torchtext import data, datasets\n",
        "\n",
        "if True:\n",
        "    import spacy\n",
        "    spacy_de = spacy.load('de')\n",
        "    spacy_en = spacy.load('en')\n",
        "\n",
        "    def tokenize_de(text):\n",
        "        return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "    def tokenize_en(text):\n",
        "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "    BOS_WORD = '<s>'\n",
        "    EOS_WORD = '</s>'\n",
        "    BLANK_WORD = \"<blank>\"\n",
        "    SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD)\n",
        "    TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, \n",
        "                     eos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
        "\n",
        "    MAX_LEN = 100\n",
        "    train, val, test = datasets.IWSLT.splits(\n",
        "        exts=('.de', '.en'), fields=(SRC, TGT), \n",
        "        filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
        "            len(vars(x)['trg']) <= MAX_LEN)\n",
        "    MIN_FREQ = 2\n",
        "    SRC.build_vocab(train.src, min_freq=MIN_FREQ)\n",
        "    TGT.build_vocab(train.trg, min_freq=MIN_FREQ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG5hcjj9Xq9W"
      },
      "source": [
        "> Batching matters a ton for speed. We want to have very evenly divided batches, with absolutely minimal padding. To do this we have to hack a bit around the default torchtext batching. This code patches their default batching to make sure we search over enough sentences to find tight batches. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkPpP95_Xq9W"
      },
      "source": [
        "## Iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FBlqMAiTXq9X"
      },
      "source": [
        "class MyIterator(data.Iterator):\n",
        "    def create_batches(self):\n",
        "        if self.train:\n",
        "            def pool(d, random_shuffler):\n",
        "                for p in data.batch(d, self.batch_size * 100):\n",
        "                    p_batch = data.batch(\n",
        "                        sorted(p, key=self.sort_key),\n",
        "                        self.batch_size, self.batch_size_fn)\n",
        "                    for b in random_shuffler(list(p_batch)):\n",
        "                        yield b\n",
        "            self.batches = pool(self.data(), self.random_shuffler)\n",
        "            \n",
        "        else:\n",
        "            self.batches = []\n",
        "            for b in data.batch(self.data(), self.batch_size,\n",
        "                                          self.batch_size_fn):\n",
        "                self.batches.append(sorted(b, key=self.sort_key))\n",
        "\n",
        "def rebatch(pad_idx, batch):\n",
        "    \"Fix order in torchtext to match ours\"\n",
        "    src, trg = batch.src.transpose(0, 1), batch.trg.transpose(0, 1)\n",
        "    return Batch(src, trg, pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "k4IXY8BgXq9X"
      },
      "source": [
        "## Multi-GPU Training\n",
        "\n",
        "> Finally to really target fast training, we will use multi-gpu. This code implements multi-gpu word generation. It is not specific to transformer so I won't go into too much detail. The idea is to split up word generation at training time into chunks to be processed in parallel across many different gpus. We do this using pytorch parallel primitives:\n",
        "\n",
        "* replicate - split modules onto different gpus.\n",
        "* scatter - split batches onto different gpus\n",
        "* parallel_apply - apply module to batches on different gpus\n",
        "* gather - pull scattered data back onto one gpu. \n",
        "* nn.DataParallel - a special module wrapper that calls these all before evaluating. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "cAvWWpBhXq9X"
      },
      "source": [
        "# Skip if not interested in multigpu.\n",
        "class MultiGPULossCompute:\n",
        "    \"A multi-gpu loss compute and train function.\"\n",
        "    def __init__(self, generator, criterion, devices, opt=None, chunk_size=5):\n",
        "        # Send out to different gpus.\n",
        "        self.generator = generator\n",
        "        self.criterion = nn.parallel.replicate(criterion, \n",
        "                                               devices=devices)\n",
        "        self.opt = opt\n",
        "        self.devices = devices\n",
        "        self.chunk_size = chunk_size\n",
        "        \n",
        "    def __call__(self, out, targets, normalize):\n",
        "        total = 0.0\n",
        "        generator = nn.parallel.replicate(self.generator, \n",
        "                                                devices=self.devices)\n",
        "        out_scatter = nn.parallel.scatter(out, \n",
        "                                          target_gpus=self.devices)\n",
        "        out_grad = [[] for _ in out_scatter]\n",
        "        targets = nn.parallel.scatter(targets, \n",
        "                                      target_gpus=self.devices)\n",
        "\n",
        "        # Divide generating into chunks.\n",
        "        chunk_size = self.chunk_size\n",
        "        for i in range(0, out_scatter[0].size(1), chunk_size):\n",
        "            # Predict distributions\n",
        "            out_column = [[Variable(o[:, i:i+chunk_size].data, \n",
        "                                    requires_grad=self.opt is not None)] \n",
        "                           for o in out_scatter]\n",
        "            gen = nn.parallel.parallel_apply(generator, out_column)\n",
        "\n",
        "            # Compute loss. \n",
        "            y = [(g.contiguous().view(-1, g.size(-1)), \n",
        "                  t[:, i:i+chunk_size].contiguous().view(-1)) \n",
        "                 for g, t in zip(gen, targets)]\n",
        "            loss = nn.parallel.parallel_apply(self.criterion, y)\n",
        "\n",
        "            # Sum and normalize loss\n",
        "            l = nn.parallel.gather(loss, \n",
        "                                   target_device=self.devices[0])\n",
        "            l = l.sum()[0] / normalize\n",
        "            total += l.data[0]\n",
        "\n",
        "            # Backprop loss to output of transformer\n",
        "            if self.opt is not None:\n",
        "                l.backward()\n",
        "                for j, l in enumerate(loss):\n",
        "                    out_grad[j].append(out_column[j][0].grad.data.clone())\n",
        "\n",
        "        # Backprop all loss through transformer.            \n",
        "        if self.opt is not None:\n",
        "            out_grad = [Variable(torch.cat(og, dim=1)) for og in out_grad]\n",
        "            o1 = out\n",
        "            o2 = nn.parallel.gather(out_grad, \n",
        "                                    target_device=self.devices[0])\n",
        "            o1.backward(gradient=o2)\n",
        "            self.opt.step()\n",
        "            self.opt.optimizer.zero_grad()\n",
        "        return total * normalize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJO1OfStXq9X"
      },
      "source": [
        "> Now we create our model, criterion, optimizer, data iterators, and paralelization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "sDzqwkH6Xq9X"
      },
      "source": [
        "# GPUs to use\n",
        "devices = [0, 1, 2, 3]\n",
        "if True:\n",
        "    pad_idx = TGT.vocab.stoi[\"<blank>\"]\n",
        "    model = make_model(len(SRC.vocab), len(TGT.vocab), N=6)\n",
        "    model.cuda()\n",
        "    criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=0.1)\n",
        "    criterion.cuda()\n",
        "    BATCH_SIZE = 12000\n",
        "    train_iter = MyIterator(train, batch_size=BATCH_SIZE, device=0,\n",
        "                            repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
        "                            batch_size_fn=batch_size_fn, train=True)\n",
        "    valid_iter = MyIterator(val, batch_size=BATCH_SIZE, device=0,\n",
        "                            repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
        "                            batch_size_fn=batch_size_fn, train=False)\n",
        "    model_par = nn.DataParallel(model, device_ids=devices)\n",
        "None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOXBIVZ-Xq9Y"
      },
      "source": [
        "> Now we train the model. I will play with the warmup steps a bit, but everything else uses the default parameters.  On an AWS p3.8xlarge with 4 Tesla V100s, this runs at ~27,000 tokens per second with a batch size of 12,000 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVTYJe4UXq9Y"
      },
      "source": [
        "## Training the System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bDezrLqnXq9Y"
      },
      "source": [
        "#!wget https://s3.amazonaws.com/opennmt-models/iwslt.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fGpcKDDiXq9Y"
      },
      "source": [
        "if False:\n",
        "    model_opt = NoamOpt(model.src_embed[0].d_model, 1, 2000,\n",
        "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "    for epoch in range(10):\n",
        "        model_par.train()\n",
        "        run_epoch((rebatch(pad_idx, b) for b in train_iter), \n",
        "                  model_par, \n",
        "                  MultiGPULossCompute(model.generator, criterion, \n",
        "                                      devices=devices, opt=model_opt))\n",
        "        model_par.eval()\n",
        "        loss = run_epoch((rebatch(pad_idx, b) for b in valid_iter), \n",
        "                          model_par, \n",
        "                          MultiGPULossCompute(model.generator, criterion, \n",
        "                          devices=devices, opt=None))\n",
        "        print(loss)\n",
        "else:\n",
        "    model = torch.load(\"iwslt.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gascy-8zXq9Y"
      },
      "source": [
        "> Once trained we can decode the model to produce a set of translations. Here we simply translate the first sentence in the validation set. This dataset is pretty small so the translations with greedy search are reasonably accurate. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2VLz8iMXq9Y"
      },
      "source": [
        "for i, batch in enumerate(valid_iter):\n",
        "    src = batch.src.transpose(0, 1)[:1]\n",
        "    src_mask = (src != SRC.vocab.stoi[\"<blank>\"]).unsqueeze(-2)\n",
        "    out = greedy_decode(model, src, src_mask, \n",
        "                        max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n",
        "    print(\"Translation:\", end=\"\\t\")\n",
        "    for i in range(1, out.size(1)):\n",
        "        sym = TGT.vocab.itos[out[0, i]]\n",
        "        if sym == \"</s>\": break\n",
        "        print(sym, end =\" \")\n",
        "    print()\n",
        "    print(\"Target:\", end=\"\\t\")\n",
        "    for i in range(1, batch.trg.size(0)):\n",
        "        sym = TGT.vocab.itos[batch.trg.data[i, 0]]\n",
        "        if sym == \"</s>\": break\n",
        "        print(sym, end =\" \")\n",
        "    print()\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "R3J-zwLXXq9Z"
      },
      "source": [
        "# Additional Components: BPE, Search, Averaging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7d2mzrlXq9Z"
      },
      "source": [
        "> So this mostly covers the transformer model itself. There are four aspects that we didn't cover explicitly. We also have all these additional features implemented in [OpenNMT-py](https://github.com/opennmt/opennmt-py).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUxdLmPkXq9Z"
      },
      "source": [
        "> 1) BPE/ Word-piece: We can use a library to first preprocess the data into subword units. See Rico Sennrich's [subword-nmt](https://github.com/rsennrich/subword-nmt) implementation. These models will transform the training data to look like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doE_CQ_LXq9Z"
      },
      "source": [
        "▁Die ▁Protokoll datei ▁kann ▁ heimlich ▁per ▁E - Mail ▁oder ▁FTP ▁an ▁einen ▁bestimmte n ▁Empfänger ▁gesendet ▁werden ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8JSATiSXq9Z"
      },
      "source": [
        "> 2) Shared Embeddings: When using BPE with shared vocabulary we can share the same weight vectors between the source / target / generator. See the [(cite)](https://arxiv.org/abs/1608.05859) for details. To add this to the model simply do this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gqJZgf2TXq9Z"
      },
      "source": [
        "if False:\n",
        "    model.src_embed[0].lut.weight = model.tgt_embeddings[0].lut.weight\n",
        "    model.generator.lut.weight = model.tgt_embed[0].lut.weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuhaIOX9Xq9a"
      },
      "source": [
        "> 3) Beam Search: This is a bit too complicated to cover here. See the [OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/translate/Beam.py) for a pytorch implementation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiiXO-M6Xq9a"
      },
      "source": [
        "> 4) Model Averaging: The paper averages the last k checkpoints to create an ensembling effect. We can do this after the fact if we have a bunch of models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "iZeCLDtvXq9a"
      },
      "source": [
        "def average(model, models):\n",
        "    \"Average models into model\"\n",
        "    for ps in zip(*[m.params() for m in [model] + models]):\n",
        "        p[0].copy_(torch.sum(*ps[1:]) / len(ps[1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OsT2OfFXq9a"
      },
      "source": [
        "# Results\n",
        "\n",
        "On the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\n",
        "in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\n",
        "BLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\n",
        "listed in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\n",
        "surpasses all previously published models and ensembles, at a fraction of the training cost of any of\n",
        "the competitive models.\n",
        "\n",
        "On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\n",
        "outperforming all of the previously published single models, at less than 1/4 the training cost of the\n",
        "previous state-of-the-art model. The Transformer (big) model trained for English-to-French used\n",
        "dropout rate Pdrop = 0.1, instead of 0.3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icUdn2VfXq9a"
      },
      "source": [
        "Image(filename=\"images/results.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4JNgHe4Xq9b"
      },
      "source": [
        "> The code we have written here is a version of the base model. There are fully trained version of this system available here  [(Example Models)](http://opennmt.net/Models-py/).\n",
        ">\n",
        "> With the addtional extensions in the last section, the OpenNMT-py replication gets to 26.9 on EN-DE WMT. Here I have loaded in those parameters to our reimplemenation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ENGPLODDXq9b"
      },
      "source": [
        "!wget https://s3.amazonaws.com/opennmt-models/en-de-model.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_-0aCFrkXq9b"
      },
      "source": [
        "model, SRC, TGT = torch.load(\"en-de-model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Y30xCLShXq9b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOWY9S1VXq9b"
      },
      "source": [
        "model.eval()\n",
        "sent = \"▁The ▁log ▁file ▁can ▁be ▁sent ▁secret ly ▁with ▁email ▁or ▁FTP ▁to ▁a ▁specified ▁receiver\".split()\n",
        "src = torch.LongTensor([[SRC.stoi[w] for w in sent]])\n",
        "src = Variable(src)\n",
        "src_mask = (src != SRC.stoi[\"<blank>\"]).unsqueeze(-2)\n",
        "out = greedy_decode(model, src, src_mask, \n",
        "                    max_len=60, start_symbol=TGT.stoi[\"<s>\"])\n",
        "print(\"Translation:\", end=\"\\t\")\n",
        "trans = \"<s> \"\n",
        "for i in range(1, out.size(1)):\n",
        "    sym = TGT.itos[out[0, i]]\n",
        "    if sym == \"</s>\": break\n",
        "    trans += sym + \" \"\n",
        "print(trans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cgclZwFXq9b"
      },
      "source": [
        "## Attention Visualization\n",
        "\n",
        "> Even with a greedy decoder the translation looks pretty good. We can further visualize it to see what is happening at each layer of the attention "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_TXuzFFXq9c"
      },
      "source": [
        "tgt_sent = trans.split()\n",
        "def draw(data, x, y, ax):\n",
        "    seaborn.heatmap(data, \n",
        "                    xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, \n",
        "                    cbar=False, ax=ax)\n",
        "    \n",
        "for layer in range(1, 6, 2):\n",
        "    fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
        "    print(\"Encoder Layer\", layer+1)\n",
        "    for h in range(4):\n",
        "        draw(model.encoder.layers[layer].self_attn.attn[0, h].data, \n",
        "            sent, sent if h ==0 else [], ax=axs[h])\n",
        "    plt.show()\n",
        "    \n",
        "for layer in range(1, 6, 2):\n",
        "    fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
        "    print(\"Decoder Self Layer\", layer+1)\n",
        "    for h in range(4):\n",
        "        draw(model.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(tgt_sent)], \n",
        "            tgt_sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
        "    plt.show()\n",
        "    print(\"Decoder Src Layer\", layer+1)\n",
        "    fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
        "    for h in range(4):\n",
        "        draw(model.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(sent)], \n",
        "            sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MhlgGUqXq9c"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "> Hopefully this code is useful for future research. Please reach out if you have any issues. If you find this code helpful, also check out our other OpenNMT tools.\n",
        "\n",
        "```\n",
        "@inproceedings{opennmt,\n",
        "  author    = {Guillaume Klein and\n",
        "               Yoon Kim and\n",
        "               Yuntian Deng and\n",
        "               Jean Senellart and\n",
        "               Alexander M. Rush},\n",
        "  title     = {OpenNMT: Open-Source Toolkit for Neural Machine Translation},\n",
        "  booktitle = {Proc. ACL},\n",
        "  year      = {2017},\n",
        "  url       = {https://doi.org/10.18653/v1/P17-4012},\n",
        "  doi       = {10.18653/v1/P17-4012}\n",
        "}\n",
        "```\n",
        "\n",
        "> Cheers,\n",
        "> srush"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1-u5nm5Xq9c"
      },
      "source": [
        "{::options parse_block_html=\"true\" /}\n",
        "<div id=\"disqus_thread\"></div>\n",
        "<script>\n",
        "\n",
        "/**\n",
        "*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.\n",
        "*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/\n",
        "/*\n",
        "var disqus_config = function () {\n",
        "this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable\n",
        "this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable\n",
        "};\n",
        "*/\n",
        "(function() { // DON'T EDIT BELOW THIS LINE\n",
        "var d = document, s = d.createElement('script');\n",
        "s.src = 'https://harvard-nlp.disqus.com/embed.js';\n",
        "s.setAttribute('data-timestamp', +new Date());\n",
        "(d.head || d.body).appendChild(s);\n",
        "})();\n",
        "</script>\n",
        "<noscript>Please enable JavaScript to view the <a href=\"https://disqus.com/?ref_noscript\">comments powered by Disqus.</a></noscript>\n",
        "                            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8WJUdrFXq9c"
      },
      "source": [
        "<div id=\"disqus_thread\"></div>\n",
        "<script>\n",
        "    /**\n",
        "     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.\n",
        "     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables\n",
        "     */\n",
        "    /*\n",
        "    var disqus_config = function () {\n",
        "        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable\n",
        "        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable\n",
        "    };\n",
        "    */\n",
        "    (function() {  // REQUIRED CONFIGURATION VARIABLE: EDIT THE SHORTNAME BELOW\n",
        "        var d = document, s = d.createElement('script');\n",
        "        \n",
        "        s.src = 'https://EXAMPLE.disqus.com/embed.js';  // IMPORTANT: Replace EXAMPLE with your forum shortname!\n",
        "        \n",
        "        s.setAttribute('data-timestamp', +new Date());\n",
        "        (d.head || d.body).appendChild(s);\n",
        "    })();\n",
        "</script>\n",
        "<noscript>Please enable JavaScript to view the <a href=\"https://disqus.com/?ref_noscript\" rel=\"nofollow\">comments powered by Disqus.</a></noscript>"
      ]
    }
  ]
}