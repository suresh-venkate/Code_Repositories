{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV - Getting started with Videos Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture video from camera\n",
    "\n",
    "To capture a video, we need to create a VideoCapture object. Its argument can be either the device index or the name of a video file. Device index is just the number to specify which camera to use. Normally one camera will be connected. So we simply pass 0 (or -1). We can select the second camera by passing 1 and so on. After that, you can capture frame-by-frame. At the end, we need to release the capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # Open VideoCapture object\n",
    "\n",
    "while(True): # Keep capturing and displaying video till key 'q' is pressed\n",
    "    \n",
    "    ret, frame = cap.read() # Capture frame-by-frame\n",
    "\n",
    "    # Convert image from color to gray\n",
    "    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', img_gray)\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "# Release the capture at the end\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cap.read() returns a bool (True/False). If frame is read correctly, it will be True. So we can check end of the video by checking this return value.\n",
    "* Sometimes, cap may not have initialized the capture. In that case, this code shows error. We can check whether it is initialized or not by the method cap.isOpened(). If it is True, OK. Otherwise open it using cap.open().\n",
    "* We can also access some of the features of this video using cap.get(propId) method where propId is a number from 0 to 18. Each number denotes a property of the video (if it is applicable to that video) and full details can be seen here: [Property Identifier](https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get). Some of these values can be modified using cap.set(propId, value). Value is the new value we want.\n",
    "* For example, we can check the frame width and height by cap.get(3) and cap.get(4). If we read in a 640 x 480 image, and we want to modify it to 320 x 240, then we can just use `ret = cap.set(3, 320)` and `ret = cap.set(4, 240)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of available properties\n",
    "\n",
    "* CAP_PROP_POS_MSEC: Current position of the video file in milliseconds.\n",
    "* CAP_PROP_POS_FRAMES: 0-based index of the frame to be decoded/captured next.\n",
    "* CAP_PROP_POS_AVI_RATIO: Relative position of the video file: 0 - start of the film, 1 - end of the film.\n",
    "* CAP_PROP_FRAME_WIDTH: Width of the frames in the video stream.\n",
    "* CAP_PROP_FRAME_HEIGHT: Height of the frames in the video stream.\n",
    "* CAP_PROP_FPS: Frame rate.\n",
    "* CAP_PROP_FOURCC: 4-character code of codec.\n",
    "* CAP_PROP_FRAME_COUNT: Number of frames in the video file.\n",
    "* CAP_PROP_FORMAT: Format of the Mat objects returned by retrieve() .\n",
    "* CAP_PROP_MODE: Backend-specific value indicating the current capture mode.\n",
    "* CAP_PROP_BRIGHTNESS: Brightness of the image (only for cameras).\n",
    "* CAP_PROP_CONTRAST: Contrast of the image (only for cameras).\n",
    "* CAP_PROP_SATURATION: Saturation of the image (only for cameras).\n",
    "* CAP_PROP_HUE: Hue of the image (only for cameras).\n",
    "* CAP_PROP_GAIN: Gain of the image (only for cameras).\n",
    "* CAP_PROP_EXPOSURE: Exposure (only for cameras).\n",
    "* CAP_PROP_CONVERT_RGB: Boolean flags indicating whether images should be converted to RGB.\n",
    "* CAP_PROP_WHITE_BALANCE_U: The U value of the whitebalance setting (note: only supported by DC1394 v 2.x backend currently)\n",
    "* CAP_PROP_WHITE_BALANCE_V: The V value of the whitebalance setting (note: only supported by DC1394 v 2.x backend currently)\n",
    "* CAP_PROP_RECTIFICATION: Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)\n",
    "* CAP_PROP_ISO_SPEED: The ISO speed of the camera (note: only supported by DC1394 v 2.x backend currently)\n",
    "* CAP_PROP_BUFFERSIZE: Amount of frames stored in internal buffer memory (note: only supported by DC1394 v 2.x backend currently)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display some properties of captured video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of ret is True\n",
      "Type of frame is <class 'numpy.ndarray'>\n",
      "Shape of frame is (480, 640, 3)\n",
      "\n",
      "FPS of video is 30.0 fps\n",
      "Frame Width is 640.0\n",
      "Frame Height is 480.0\n",
      "FOURCC of codec is 20.0\n",
      "Brightness of camera is 50.0\n",
      "Contrast of camera is 50.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0) # Open VideoCapture object\n",
    "\n",
    "# Capture just a single frame and return multiple properties\n",
    "ret, frame = cap.read() # Capture single frame\n",
    "\n",
    "print(f\"Value of ret is {ret}\")\n",
    "print(f\"Type of frame is {type(frame)}\")\n",
    "print(f\"Shape of frame is {frame.shape}\")\n",
    "print()\n",
    "print(f\"FPS of video is {cap.get(cv2.CAP_PROP_FPS)} fps\")\n",
    "print(f\"Frame Width is {cap.get(cv2.CAP_PROP_FRAME_WIDTH)}\")\n",
    "print(f\"Frame Height is {cap.get(cv2.CAP_PROP_FRAME_HEIGHT)}\")\n",
    "print(f\"FOURCC of codec is {cap.get(cv2.CAP_PROP_FOURCC)}\")\n",
    "print(f\"Brightness of camera is {cap.get(cv2.CAP_PROP_BRIGHTNESS)}\")\n",
    "print(f\"Contrast of camera is {cap.get(cv2.CAP_PROP_CONTRAST)}\")\n",
    "\n",
    "cap.release() # Release the capture at the end\n",
    "cv2.destroyAllWindows() # Destroy all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a video file stored in disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: decode_fourcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_fourcc(fourcc):\n",
    "    \"\"\"Decodes the fourcc value to get the four chars identifying it\"\"\"\n",
    "\n",
    "    # Convert to int:\n",
    "    fourcc_int = int(fourcc)\n",
    "\n",
    "    # We print the int value of fourcc\n",
    "    # print(\"int value of fourcc: '{}'\".format(fourcc_int))\n",
    "\n",
    "    fourcc_decode = \"\"\n",
    "    for i in range(4):\n",
    "        int_value = fourcc_int >> 8 * i & 0xFF\n",
    "        # print(\"int_value: '{}'\".format(int_value))\n",
    "        fourcc_decode += chr(int_value)\n",
    "    return fourcc_decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some information about the video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS of video is 29.97 FPS\n",
      "Current position of the video file in milliseconds is 0.000 msec\n",
      "0-based index of the frame to be decoded/captured next is 0\n",
      "Relative position of the video file is 1.67e-05\n",
      "\n",
      "Width of the frames in the video stream is 640\n",
      "Height of the frames in the video stream is 360\n",
      "\n",
      "FOURCC of codec is avc1\n",
      "Number of frames in the video file is 3407\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./Videos/Video_1.mp4') # Define VideoCapture object\n",
    "# Frames-per-Second of Video\n",
    "print(\"FPS of video is %0.2f FPS\" %(cap.get(cv2.CAP_PROP_FPS)))\n",
    "print(\"Current position of the video file in milliseconds is %0.3f msec\"\\\n",
    "      %(cap.get(cv2.CAP_PROP_POS_MSEC)))\n",
    "print(\"0-based index of the frame to be decoded/captured next is %d\"\\\n",
    "      %cap.get(cv2.CAP_PROP_POS_FRAMES))  \n",
    "print(\"Relative position of the video file is %0.2e\"\\\n",
    "      %(cap.get(cv2.CAP_PROP_POS_AVI_RATIO))) # 0 - start of the film, 1 - end of the film.\n",
    "print()\n",
    "print(\"Width of the frames in the video stream is %d\" %(cap.get(cv2.CAP_PROP_FRAME_WIDTH)))\n",
    "print(\"Height of the frames in the video stream is %d\" %(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "print()\n",
    "print(f\"FOURCC of codec is {decode_fourcc(cap.get(cv2.CAP_PROP_FOURCC))}\")\n",
    "print(\"Number of frames in the video file is %d\" %(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "cap.release()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file and play it till it ends of key 'q' is pressed\n",
    "\n",
    "cap = cv2.VideoCapture('./Videos/Video_1.mp4') # Define VideoCapture object\n",
    "while(cap.isOpened()): # Iterate till cap object is open\n",
    "    \n",
    "    ret, frame = cap.read() # Read current frame\n",
    "    if (ret): # If ret = True, display frame, else break\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'): # Wait 20msec for key press\n",
    "                                               # and then move to next frame\n",
    "            break\n",
    "    else: # Break if end of video is reached\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
